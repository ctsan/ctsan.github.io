
[{"content":" Google Scholar Profile\nChristos Tsanikidis, Javad Ghaderi, Scheduling Stochastic Traffic With End-to-End Deadlines in Multi-hop Wireless Networks, IEEE INFOCOM 2024, Apr 2024, pp. 651-660 — Best Paper Award.\nChristos Tsanikidis, Javad Ghaderi, Near-optimal Packet Scheduling in Multihop Networks with End-to-End Deadline Constraints, ACM SIGMETRICS Performance Evaluation Review 52 (1), 33-34, 2024. (Extended version of PACMPL MACS 7 (3), 2023.)\nChristos Tsanikidis, Javad Ghaderi, Near-optimal Packet Scheduling in Multihop Networks with End-to-End Deadline Constraints, Proceedings of the ACM on Measurement and Analysis of Computing Systems 7 (3), 2023.\nChristos Tsanikidis, Javad Ghaderi, Online Scheduling and Routing with End-to-End Deadline Constraints in Multihop Wireless Networks, Proc. ACM MobiHoc 2022, Oct 2022.\nChristos Tsanikidis, Javad Ghaderi, Randomized Scheduling of Real-Time Traffic in Wireless Networks Over Fading Channels, IEEE INFOCOM 2021, May 2021. Full version in IEEE/ACM Transactions on Networking 31 (4), Nov 2022. [arXiv:2101.04815]\nChristos Tsanikidis, Javad Ghaderi, On the Power of Randomization for Scheduling Real-Time Traffic in Wireless Networks, IEEE INFOCOM 2020, July 2020 — Best Paper Award. Full version in IEEE/ACM Transactions on Networking 29 (4), Aug 2021. [arXiv:2001.05146]\nChristos Tsanikidis, Margarita Vitoropoulou, Vasileios Karyotis, Symeon Papavassiliou, On the Energy-Efficient Coverage of Network Regions with Convex Opaque Obstacles, IEEE PIMRC 2018, Sept 2018.\nChristos Tsanikidis, Theory and Algorithms for Scheduling Deadline-Constrained Packets in Single-Hop and Multi-Hop Wireless Networks, Ph.D. Dissertation, Columbia University, 2024.\n","date":"11 October 2025","externalUrl":null,"permalink":"/research/","section":"Christos Tsanikidis, PhD","summary":"","title":"Research","type":"page"},{"content":" Google Scholar Profile\nChristos Tsanikidis, Javad Ghaderi, Scheduling Stochastic Traffic With End-to-End Deadlines in Multi-hop Wireless Networks, IEEE INFOCOM 2024, Apr 2024, pp. 651-660 — Best Paper Award.\nChristos Tsanikidis, Javad Ghaderi, Near-optimal Packet Scheduling in Multihop Networks with End-to-End Deadline Constraints, ACM SIGMETRICS Performance Evaluation Review 52 (1), 33-34, 2024. (Extended version of PACMPL MACS 7 (3), 2023.)\nChristos Tsanikidis, Javad Ghaderi, Near-optimal Packet Scheduling in Multihop Networks with End-to-End Deadline Constraints, Proceedings of the ACM on Measurement and Analysis of Computing Systems 7 (3), 2023.\nChristos Tsanikidis, Javad Ghaderi, Online Scheduling and Routing with End-to-End Deadline Constraints in Multihop Wireless Networks, Proc. ACM MobiHoc 2022, Oct 2022.\nChristos Tsanikidis, Javad Ghaderi, Randomized Scheduling of Real-Time Traffic in Wireless Networks Over Fading Channels, IEEE INFOCOM 2021, May 2021. Full version in IEEE/ACM Transactions on Networking 31 (4), Nov 2022. [arXiv:2101.04815]\nChristos Tsanikidis, Javad Ghaderi, On the Power of Randomization for Scheduling Real-Time Traffic in Wireless Networks, IEEE INFOCOM 2020, July 2020 — Best Paper Award. Full version in IEEE/ACM Transactions on Networking 29 (4), Aug 2021. [arXiv:2001.05146]\nChristos Tsanikidis, Margarita Vitoropoulou, Vasileios Karyotis, Symeon Papavassiliou, On the Energy-Efficient Coverage of Network Regions with Convex Opaque Obstacles, IEEE PIMRC 2018, Sept 2018.\nChristos Tsanikidis, Theory and Algorithms for Scheduling Deadline-Constrained Packets in Single-Hop and Multi-Hop Wireless Networks, Ph.D. Dissertation, Columbia University, 2024.\n","date":"20 August 2017","externalUrl":null,"permalink":"/research-2/","section":"Christos Tsanikidis, PhD","summary":"","title":"Research","type":"page"},{"content":" I am Christos, an applied researcher working on AI at Google. Previously, I worked as a quantitative researcher at the Automated Market Making desk at Morgan Stanley (2023 – 2025), where I designed trading-flow alphas using modern machine-learning methods.\nDuring my time at Columbia, I worked on online, often stochastic, optimization problems for networks. My research received two Best Paper Awards at IEEE INFOCOM (each time awarded to 3 papers out of ~1,300 submissions). During my time at Columbia I interned at Microsoft (Turing group) optimizing large language models.\nI am always eager to meet high signal-to-noise ratio people with corrolated or even more so, orthogonal thinking to mine. Please do not hesitate to reach out.\n$c . t s a n i k i d i s [AT] \\text{c} \\text{o} l u m b i a. e d u$, or $c t s a n i k i d i s \\text{[AT]} \\text{g} m a i l \\text{.} c o m$\n","date":"11 October 2025","externalUrl":null,"permalink":"/about/","section":"Christos Tsanikidis, PhD","summary":"","title":"About","type":"page"},{"content":" I am Christos, an applied researcher working on AI at Google. Previously, I worked as a quantitative researcher at the Automated Market Making desk at Morgan Stanley (2023 – 2025), where I designed trading-flow alphas using modern machine-learning methods.\nDuring my time at Columbia, I worked on online, often stochastic, optimization problems for networks. My research received two Best Paper Awards at IEEE INFOCOM (each time awarded to 3 papers out of ~1,300 submissions). During my time at Columbia I interned at Microsoft (Turing group) optimizing large language models.\nI am always eager to meet high signal-to-noise ratio people with corrolated or even more so, orthogonal thinking to mine. Please do not hesitate to reach out.\n$c . t s a n i k i d i s [AT] \\text{c} \\text{o} l u m b i a. e d u$, or $c t s a n i k i d i s \\text{[AT]} \\text{g} m a i l \\text{.} c o m$\n","date":"20 August 2017","externalUrl":null,"permalink":"/about-2/","section":"Christos Tsanikidis, PhD","summary":"","title":"About","type":"page"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"AI","type":"tags"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/","section":"Christos Tsanikidis, PhD","summary":"","title":"Christos Tsanikidis, PhD","type":"page"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/tags/communication/","section":"Tags","summary":"","title":"Communication","type":"tags"},{"content":"“I would have written a shorter letter, but I did not have the time.”\nMost writing used to pre-expand ideas for every possible reader or was imperfectly verbose. Given recent AI advances, we can publish a compact core and let AI expand it per reader on demand.\nCompress verbose text, audience-conditioned decompression. Human nature and audience uncertainty has historically created verbosity in final write ups. In this new era, humans can express their idea with minimal energy. AI compresses drafts to a core while preserving intent. The same core decompresses differently for background, purpose, and context.\nMathematically: traditional writing optimizes $\\max_y E_X[\\text{Comprehension}(X; y)]$, one expression $y$ for all readers $X$. AI enables $E_X[\\max_y \\text{Comprehension}(X; y)]$, optimal expansion per reader. By Jensen\u0026rsquo;s inequality, $$E_X[\\max_y \\text{Comprehension}(X; y)] \\geq \\max_y E_X[\\text{Comprehension}(X; y)].$$Longform remains relevant for style, persuasion, and art.\nHumans as novelty injectors Humans supply the new bits. Fresh observations, opinions, and creative leaps. AI filters redundancy against the historical record, keeping only the novel core and reattaching shared context during expansion.\n","date":"11 October 2025","externalUrl":null,"permalink":"/posts/the-era-of-minimal-writing/","section":"Posts","summary":"","title":"Era of minimal writing","type":"posts"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/tags/information-theory/","section":"Tags","summary":"","title":"Information Theory","type":"tags"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/categories/life/","section":"Categories","summary":"","title":"Life","type":"categories"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/tags/writing/","section":"Tags","summary":"","title":"Writing","type":"tags"},{"content":"","date":"27 July 2025","externalUrl":null,"permalink":"/tags/greece/","section":"Tags","summary":"","title":"Greece","type":"tags"},{"content":"","date":"27 July 2025","externalUrl":null,"permalink":"/tags/interactive-simulation/","section":"Tags","summary":"","title":"Interactive-Simulation","type":"tags"},{"content":"","date":"27 July 2025","externalUrl":null,"permalink":"/tags/manhattan/","section":"Tags","summary":"","title":"Manhattan","type":"tags"},{"content":"","date":"27 July 2025","externalUrl":null,"permalink":"/categories/math/","section":"Categories","summary":"","title":"Math","type":"categories"},{"content":"","date":"27 July 2025","externalUrl":null,"permalink":"/tags/mcmc/","section":"Tags","summary":"","title":"Mcmc","type":"tags"},{"content":"","date":"27 July 2025","externalUrl":null,"permalink":"/tags/metropolis-hastings/","section":"Tags","summary":"","title":"Metropolis-Hastings","type":"tags"},{"content":"A trading game where you bet on particle-bubble collisions. Click bubbles once to go Long (bet on hit), twice for Short (bet against), three times to clear. Market prices shown inside bubbles—profit when you spot mispricing.\nDifficulty: Easy Medium Hard Mode: Barriers Digitals Knock-Ins Random Start Round Restart Game Round: 1/10 | Total Profit: 0 Select difficulty and game mode to begin. Click bubbles to trade: 1× = Long (Green), 2× = Short (Red), 3× = Clear (Grey). Market price = % shown inside.\nSelect your bets... Score: N/A Interaction Mechanisms Three derivative structures are implemented:\nBarriers: Knockout options. Observe particle behavior near domain boundaries versus central regions.\nDigitals: Binary options dependent on terminal particle positions. Note the relationship between obstacle size and hit probability.\nKnock-Ins: Path-dependent activation. Watch how particle trajectories create correlation between spatially proximate obstacles.\nRun each mode to observe how geometric configuration affects pricing accuracy.\nMarket Structure Parallels After experimenting with the simulation, several market phenomena become apparent:\nInformation Asymmetry: The difficulty parameter controls pricing noise, analogous to varying information quality across market participants.\nSpatial Correlation: Observe clustering effects in knock-in mode - similar to sector rotation in equity markets or yield curve movements in fixed income.\nPath Dependence: Barrier and knock-in mechanisms mirror exotic derivatives where payout depends on the asset\u0026rsquo;s trajectory, not just terminal value.\nRelative Value: Compare pricing across spatially similar obstacles. Systematic deviations suggest arbitrage opportunities.\nThe mathematical framework underlying both particle interactions and financial derivatives pricing exhibits identical structural properties: stochastic processes, boundary conditions, and payoff functions determined by path-dependent events.\n","date":"27 July 2025","externalUrl":null,"permalink":"/posts/trading-bubbles/","section":"Posts","summary":"","title":"Shorting bubbles [a trading game]","type":"posts"},{"content":"","date":"27 July 2025","externalUrl":null,"permalink":"/categories/simulation/","section":"Categories","summary":"","title":"Simulation","type":"categories"},{"content":"","date":"27 July 2025","externalUrl":null,"permalink":"/tags/usa/","section":"Tags","summary":"","title":"USA","type":"tags"},{"content":" In this post we explore Markov Chain Monte Carlo Methods (MCMC), and specifically Metropolis-Hastings.\nUSA Heatmap Ring Distribution Bimodal Distribution Long-tailed Distribution Intersecting Circles Disjoint Circles Triangle Wiggly Ring Sierpinski Triangle Greece Manhattan Greece-Turkey Nearby Pairs 500 1000 1500 2000 3000 5000 10000 Slowest Very Slow Slow Medium Fast Very Fast Small Jumps Medium Jumps Normal Jumps Large Jumps Extra Large Jumps Toggle Opacity Change Colors MCMC Methods allow us to sample from a distribution, if all we know is $\\phi(x)=c\\times f(x)$, where $f(x)$ is the density at point $x$ of the distribution we wish to sample from, and $c$ is any fixed constant. This allows us to sample from the distribution without knowing the normalization term of the distribution. Recall that all density functions technically need to integrate to $1$, i.e., $\\int f(x) dx=1$. However, often we do not know exactly $f(x)$ but we know $\\phi(x)$ for some $c$. Notice that $\\phi$ then is not technically a distribution, but through metropolis hastings we can convert it to a distribution.\nRunning Metropolis-Hastings (MH) over several distributions Through the MH algorithm, in the following, we simulate the evolution of 2-dimensional carefully designed Markov chains, many times in parallel. MH gives us a way to make these Markov chains have as a stationary distribution the distribution of interest. In the following, you can try different distributions, some of which are constant over some particular shape, e.g. uniform over the map of Greece or the streets of Manhattan. We also include distributions that are non-uniform, such as a population heatmap of the USA or mixtures of Gaussians. You can try the wiggly ring distribution, which is a changing distribution with time. Finally we include a 4-dimensional Markov chain, which assigns uniform probability over all the pairs of points in Greece and Turkey that are not too far from each other.\nChallenges and Details Points outside the support of the distribution In the above implementation, points outside the support of the distribution are assigned very low weight in $\\phi$ (rather than $0$). Therefore points are engaging in essentially a random walk for sometime, until they stumble at a point within the support. There is positive but very low probability that they exit the support again. This has some benefits, for example, if the support consists of disjoint sets, then unless the step is sufficiently big, we will never be able to exit a particular subset of the support (therefore the Markov chain will be essentially trapped in a subset of all the states).\nIf we start from a point outside the support, the Markov chain might take a while until it stumbles on a point in the support. This might be mitigated if we know roughly where the support is or if we can instead sample from a distribution with density proportional to the inverse of the distance from the support or some other approach along these lines. Notice that in particular in the case of Greece-Turkey nearby points, chains take quite a while until they end up in a point within the distribution. One could initiate the chains from a point within the support if such a point is known. Notice that the marginal distribution of the points in Turkey or the points in Greece are not uniform, even though the pairs of points are uniform.\n","date":"7 April 2023","externalUrl":null,"permalink":"/posts/mcmc/","section":"Posts","summary":"","title":"Drawing with Markov chain Monte Carlo","type":"posts"},{"content":" I prompted GPT4 to help me create a cheatsheet for areas spanning AI, Computer Science, Finance, Operations Research, and Mathematics. Then, asked to grade the importance of each relationship for different people, and in some cases, to explain its answers. Each Relationship might contain some explanation Click to expand 📊 Quants ⭐ Not Very Relevant for Quants :-) 🤖 AI Researchers ⭐ Not very relevant for AI Reseachers 📈 Data Scientists ⭐ Not very relevant for Data Science Researchers Tags: explanation, functionality Click me to see how it works. From a content\u0026#39;s perspective, the goal is for this to serve as an expanding brainstorming hub and a point of reference. From a concept perspective, this post will hopefully convince you that there is incredible brainstorming potential by AI, and this is just a first taste. Click to expand 📊 Quants ⭐ Not Very Relevant for Quants :-) 🤖 AI Researchers ⭐ Not very relevant for AI Reseachers 📈 Data Scientists ⭐ Not very relevant for Data Science Researchers Click to see the purpose. Due to hallucination issues, there are some errors. Goal is to improve the page by making it more comprehensive, correcting errors, and explaining all grades as well as explaining all relationships in a tooltip. Furthermore, ideally, a user can grade with an arbitrary query all equations, however this requires an API call to ChatGPT, which, the author, at the time of the writing did not have access to. Other issues include some inconsistency in grading and some redundancy or non ideal classification. Finally in terms of performance, this page can be optimized significantly. Contact me if you wish to contribute or would like access to the list of equations (c[lastname] at gmail). Click to expand 📊 Quants ⭐ Not Very Relevant for Quants :-) 🤖 AI Researchers ⭐ Not very relevant for AI Reseachers 📈 Data Scientists ⭐ Not very relevant for Data Science Researchers Limitations \u0026 Disclaimers, Future Work. Loading might take some time. Alpha Version. Last Update: 06/24/2023. Select an Option:\nNo Grading Grade Publicity Relevance to Quants Relevance to AI Researchers Relevance to Data Science Interview Exploration Mode Grade Cutoff : Hide Subcategories Hide Categories Add Colors Enable Dark Mode\nZen Mode ••• Linear regression models the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data, minimizing the sum of squared residuals. Example: predicting house prices based on the number of rooms and area. Click to expand 📊 Quants Linear regression is a fundamental statistical and machine learning method used extensively in quantitative research. 🤖 AI Researchers Linear regression is a foundational technique in AI, but it is often overshadowed by more advanced methods. 📈 Data Scientists Linear regression is a must-know topic for data science interviews. Tags: least squares, multivariate regression Linear Regression: $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_p x_p + \\epsilon$ Logistic regression is a generalized linear model used for binary classification, estimating the probability of an event occurring based on input features. Example: predicting whether a customer will make a purchase based on their browsing history. Click to expand 📊 Quants Logistic regression is a popular method in quantitative research, especially for binary outcomes. 🤖 AI Researchers Logistic regression is fundamental in AI, but more advanced techniques may be used for complex tasks. 📈 Data Scientists Logistic regression is a common topic in data science interviews. Tags: binary classification, odds ratio Logistic Regression: $P(y|x) = \\sigma(w^Tx)$ Support Vector Machine (SVM) is a supervised learning method used for classification and regression by finding the optimal hyperplane that maximizes the margin between two classes. Example: classifying handwritten digits. Click to expand 📊 Quants SVMs are popular in quantitative research due to their ability to handle high-dimensional data and find complex decision boundaries. 🤖 AI Researchers SVMs are powerful and versatile techniques used in AI research for various classification and regression tasks. 📈 Data Scientists SVMs are a popular topic in data science interviews due to their effectiveness and versatility. Tags: kernel trick, margin Support Vector Machine: $\\min_{w,b} \\frac{1}{2} ||w||^2 + C \\sum_{i=1}^{n} \\max(0, 1 - y_i(w^Tx_i + b))$ Perceptron is a simple binary classification algorithm that learns weights for input features to make a linear decision boundary. Example: classifying whether a fruit is an apple or an orange based on its color and shape. Click to expand 📊 Quants Perceptrons are simple and interpretable, making them useful for some quantitative research tasks. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Perceptrons are foundational in AI but have limited application due to their simplicity and inability to learn complex patterns. 📈 Data Scientists Perceptrons may come up in data science interviews as an introductory topic to neural networks. Tags: linear classifier, threshold Perceptron: $y = \\mathbf{1}(w^Tx + b \u003e 0)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Adaline: $y = \\phi(w^Tx + b)$, where $\\phi$ is a linear activation function. Naive Bayes\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Naive Bayes Classifier: $p(y|x) = p(y)\\prod_{i=1}^{n}p(x_i|y)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Gaussian Naive Bayes: $p(x_i|y) = \\mathcal{N}(x_i|\\mu_{iy},\\sigma_{iy}^2)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Multinomial Naive Bayes: $p(x_i|y) = \\frac{(\\sum_{j=1}^{n} x_{ij})!}{\\prod_{j=1}^{n} x_{ij}!} \\prod_{j=1}^{n} \\theta_{yj}^{x_{ij}}$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐ Bernoulli Naive Bayes: $p(x_i|y) = \\theta_{iy}^{x_i} (1-\\theta_{iy})^{1-x_i}$ Tree-Based Models\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Decision Tree: $h(x) = \\sum_{i=1}^{m} y_i \\mathbf{1}(x \\in R_i)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Random Forest: $h(x) = \\frac{1}{T} \\sum_{t=1}^{T} h_t(x)$ Clustering\nClick to expand 📊 Quants 🤖 AI Researchers ⭐⭐⭐⭐ 📈 Data Scientists k-Means Clustering: $J = \\sum_{i=1}^{n} \\min_{j=1}^{k} ||x_i - \\mu_j||^2$, where $\\mu_j$ is the mean of the $j$-th cluster. Click to expand 📊 Quants 🤖 AI Researchers ⭐⭐⭐ 📈 Data Scientists ⭐⭐⭐⭐⭐ Hierarchical Clustering: $D_{ij} = ||x_i - x_j||$, $\\min$ or $\\max$ linkage between clusters. Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Gaussian Mixture Model (GMM): $p(x) = \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists DBSCAN: $\\text{Cluster}(x) = \\text{Density}(x, \\epsilon, minPts)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Isolation Forest: $\\text{Cluster}(x) = \\text{Splits}(x)$ Neural Networks\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Artificial Neural Network: $a^{(1)}=x,a^{(l)}=\\sigma(z^{(l)}),z^{(l)}=w^{(l)} a^{(l-1)} + b^{(l)}$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Convolutional Neural Network: $y_{i,j} = \\sigma(\\sum_{m=1}^{M} \\sum_{k=1}^{K} w_{m,k} x_{i+k-1,j+m-1} + b_m)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Recurrent Neural Network (RNN): $h_t = f(h_{t-1}, x_t)$, where $f$ is a recurrent function. Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Long Short-Term Memory (LSTM) RNN: $f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f)$, $i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i)$, $o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o)$, $c_t = f_t \\odot c_{t-1} + i_t \\odot g(W_c x_t + U_c h_{t-1} + b_c)$, $h_t = o_t \\odot \\sigma(c_t)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Autoencoder: $\\mathrm{encoder}: h = f(x;\\theta), \\mathrm{decoder}: r = g(h;\\theta')$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Artificial Neural Network Backpropagation: $\\delta^{(L)} = \\nabla_a J \\odot \\sigma'(z^{(L)})$, $\\delta^{(l)} = ((w^{(l+1)})^T \\delta^{(l+1)}) \\odot \\sigma'(z^{(l)})$ Gradient Boosting and Ensemble\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Gradient Boosting: $F(x) = \\sum_{m=1}^{M} \\gamma_m f_m(x)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Gradient Boosting Decision Tree: $y = \\sum_{m=1}^{M} \\gamma_m f_m(x)$, where $f_m$ is a decision tree and $\\gamma_m$ is the learning rate for the $m$-th tree. Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists XGBoost: $\\text{obj}(\\theta) = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i^{(t)}) + \\sum_{i=1}^{t} \\Omega(f_i)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists LightGBM: $\\text{obj}(\\theta) = \\sum_{i=1}^{n} l(y_i, \\hat{y}_i) + \\sum_{j=1}^{T} \\Omega(f_j)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists AdaBoost: $H(x) = \\text{sign}\\left(\\sum_{t=1}^T \\alpha_t h_t(x)\\right)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Bagging: $h(x) = \\frac{1}{T} \\sum_{t=1}^T h_t(x)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Stacking: $\\text{Meta-model}(M_1(x), M_2(x), ..., M_n(x))$ Dimensionality Reduction\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Principal Component Analysis (PCA): $z = U^T(x-\\mu)$, where $U$ is the eigenvector matrix. Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Independent Component Analysis (ICA): $x = As$, where $A$ is the mixing matrix and $s$ is the independent source signals. Classification Metrics\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Receiver Operating Characteristic (ROC) Curve: $\\text{TPR} = \\frac{TP}{TP+FN}$, $\\text{FPR} = \\frac{FP}{FP+TN}$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Precision-Recall Curve: $Precision = \\frac{TP}{TP+FP}$, $Recall = \\frac{TP}{TP+FN}$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Confusion Matrix: $\\begin{pmatrix}TN \u0026 FP\\\\FN \u0026 TP\\end{pmatrix}$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists F1 Score: $F1 = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Area Under Curve (AUC): $\\text{AUC} = \\int \\text{ROC}(\\text{FPR}(t), \\text{TPR}(t)) dt$ Regression Metrics\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Mean Absolute Error (MAE): $\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Mean Squared Error (MSE): $\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Root Mean Squared Error (RMSE): $\\text{RMSE} = \\sqrt{\\text{MSE}}$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists R2 Score: $R^2 = 1 - \\frac{\\text{MSE}}{\\text{Var}(y)}$ Regularization Techniques\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists L1 Regularization (Lasso): $J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} L(y^{(i)}, \\hat{y}^{(i)}) + \\lambda \\sum_{j=1}^{n} |\\theta_j|$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists L2 Regularization (Ridge): $J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} L(y^{(i)}, \\hat{y}^{(i)}) + \\frac{\\lambda}{2} \\sum_{j=1}^{n} \\theta_j^2$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Elastic Net Regularization: $J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} L(y^{(i)}, \\hat{y}^{(i)}) + \\lambda_1 \\sum_{j=1}^{n} |\\theta_j| + \\frac{\\lambda_2}{2} \\sum_{j=1}^{n} \\theta_j^2$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Dropout: $y = \\frac{1}{1-p} x \\odot m$, where $m \\in \\{0,1\\}$ is a binary mask with probability $p$ of being $1$. Overfitting Control\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Early Stopping: Stop training when the validation loss stops decreasing, Kernel methods are a family of techniques that use kernel functions to transform data in order to improve the performance of machine learning algorithms. The kernel trick is a technique that allows for efficient computation of high-dimensional feature spaces without explicitly mapping the data points. Radial Basis Function (RBF) is a popular kernel used in SVM and other algorithms. Kernel methods are important because they enable learning complex decision boundaries in high-dimensional spaces, allowing for better performance in tasks such as image classification, text analysis, and bioinformatics. Kernel Methods Click to expand Kernel methods are a family of techniques that use kernel functions to transform data in order to improve the performance of machine learning algorithms. The kernel trick is a technique that allows for efficient computation of high-dimensional feature spaces without explicitly mapping the data points. Radial Basis Function (RBF) is a popular kernel used in SVM and other algorithms. Kernel methods are important because they enable learning complex decision boundaries in high-dimensional spaces, allowing for better performance in tasks such as image classification, text analysis, and bioinformatics. Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Radial Basis Function (RBF): $K(x, x') = \\exp \\left(-\\frac{\\|x - x'\\|^2}{2\\sigma^2} \\right)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Polynomial Kernel: $K(x, x') = (x^T x' + c)^d$, Regression Models\nClick to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Locally Weighted Linear Regression (LWLR): $\\min_{w \\in \\mathbb{R}^d} \\sum_{i=1}^N w(x_i) (y_i - w^T x_i)^2$, Classification Models\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists K-Nearest Neighbors: $y = \\mathrm{mode}(\\{y_i : x_i \\in \\mathcal{N}_k(x)\\})$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Softmax Regression: $P(y|x) = \\frac{\\exp(w_y^T x + b_y)}{\\sum_{j=1}^k \\exp(w_j^T x + b_j)}$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Sigmoid Kernel: $K(x, x') = \\tanh (\\kappa x^T x' + c)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Kernel SVM: $f(x) = \\sum_{i=1}^N \\alpha_i y_i K(x, x_i) + b$, Unsupervised Learning Models\nClick to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Gaussian Process: $p(f(x)|X, y, x) = \\mathcal{N}(m(x), \\sigma^2(x))$, Click to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Latent Dirichlet Allocation (LDA): $p(w|\\theta, \\beta) = \\sum_{z=1}^K p(w|z, \\beta)p(z|\\theta)$, Click to expand 📊 Quants ⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐ t-Distributed Stochastic Neighbor Embedding (t-SNE): $p_{j|i} = \\frac{\\exp(-||x_i - x_j||^2 / 2\\sigma_i^2)}{\\sum_{k \\neq i} \\exp(-||x_i - x_k||^2 / 2\\sigma_i^2)}$, Click to expand 📊 Quants ⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐ Spectral Clustering: $L = D - W$, where $D$ is the degree matrix and $W$ is the adjacency matrix, Click to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Collaborative Filtering: $R \\approx U^TV$, where $R$ is the rating matrix, $U$ is the user matrix, and $V$ is the item matrix, Click to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Matrix Factorization: $R \\approx \\sum_{k=1}^K u_{ik}v_{kj}$, Collaborative Filtering\nTime Series Analysis\nRecommendation Systems\nGenerative Models\nNatural Language Processing\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Word2Vec: $f(w) = \\text{Embedding}(w)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists GloVe: $F(w_i, w_j, \\tilde{w}_k) = w_i^T \\tilde{w}_k + b_i + \\tilde{b}_k - \\log X_{ij}$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists FastText: $f(w) = \\sum_{g \\in ngrams(w)} \\text{Embedding}(g)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ELMo: $h(x) = \\sum_{j=1}^L \\gamma_j h_j(x)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Attention Mechanism: $\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k=1}^T \\exp(e_{ik})}$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Self-Attention: $e_{ij} = a(s_i, s_j)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists BERT: $\\text{MaskedLM}(\\text{Transformer}(x))$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists GPT: $p(x) = \\prod_{t=1}^T p(x_t | x_{\\le t})$, Cluster Evaluation\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Silhouette Score: $s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}$, Feature engineering is the process of creating new features or transforming existing features to improve the performance of machine learning models. This is important because it can help uncover hidden patterns in the data, reduce dimensionality, and improve model interpretability. Feature engineering can involve techniques such as normalization, scaling, one-hot encoding, and feature selection. Examples include creating interaction terms in linear regression or using word embeddings in natural language processing tasks. Feature Engineering Click to expand Feature engineering is the process of creating new features or transforming existing features to improve the performance of machine learning models. This is important because it can help uncover hidden patterns in the data, reduce dimensionality, and improve model interpretability. Feature engineering can involve techniques such as normalization, scaling, one-hot encoding, and feature selection. Examples include creating interaction terms in linear regression or using word embeddings in natural language processing tasks. Click to expand 📊 Quants 🤖 AI Researchers ⭐⭐⭐⭐⭐ 📈 Data Scientists One-hot Encoding: $x_i = \\begin{cases} 1 \u0026 \\text{if } c = c_i, \\\\ 0 \u0026 \\text{otherwise} \\end{cases}$, Click to expand 📊 Quants 🤖 AI Researchers ⭐⭐⭐⭐⭐ 📈 Data Scientists Feature Standardization: $x' = \\frac{x - \\mu}{\\sigma}$, Click to expand 📊 Quants 🤖 AI Researchers ⭐⭐⭐⭐ 📈 Data Scientists Label Encoding: Convert categorical variables into integer labels. Model evaluation is the process of measuring the performance of a machine learning model to determine its effectiveness and generalization capabilities. Techniques such as cross-validation, hold-out validation, and bootstrapping help in estimating the model\u0026#39;s performance on unseen data. Model evaluation is crucial for selecting the best model, understanding its limitations, and fine-tuning hyperparameters. Metrics like accuracy, F1-score, AUC-ROC, and mean squared error are used to quantify model performance. Model Evaluation Click to expand Model evaluation is the process of measuring the performance of a machine learning model to determine its effectiveness and generalization capabilities. Techniques such as cross-validation, hold-out validation, and bootstrapping help in estimating the model\u0026#39;s performance on unseen data. Model evaluation is crucial for selecting the best model, understanding its limitations, and fine-tuning hyperparameters. Metrics like accuracy, F1-score, AUC-ROC, and mean squared error are used to quantify model performance. Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Cross-Validation: $\\text{CV} = \\frac{1}{k} \\sum_{i=1}^k L_{test}^{(i)}$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists K-Fold Cross-Validation: $\\text{CV} = \\frac{1}{k} \\sum_{i=1}^k L_{test}^{(i)}$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Stratified K-Fold Cross-Validation: $\\text{CV}_{\\text{stratified}} = \\frac{1}{k} \\sum_{i=1}^k L_{test}^{(i)}(\\text{same class distribution})$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Time Series Cross-Validation: $\\text{CV}_{\\text{time}} = \\frac{1}{k} \\sum_{i=1}^k L_{test}^{(i)}(\\text{time order})$ Activation Functions\nClick to expand 📊 Quants ⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists Leaky ReLU: $f(x) = \\begin{cases} x \u0026 \\text{if } x \u003e 0, \\\\ \\alpha x \u0026 \\text{otherwise} \\end{cases}$, Click to expand 📊 Quants ⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists Parametric ReLU (PReLU): $f(x) = \\begin{cases} x \u0026 \\text{if } x \u003e 0, \\\\ \\alpha_i x \u0026 \\text{otherwise} \\end{cases}$, Feature Importance\nClick to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists Permutation Importance: $\\text{importance} = \\frac{\\text{error} - \\text{permuted error}}{\\text{error}}$ Sequence Models\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Hidden Markov Model (HMM): $\\alpha_t(j) = p(o_1,o_2,...,o_t, q_t = j|\\lambda)$, $\\beta_t(j) = p(o_{t+1}, o_{t+2}, ..., o_T |q_t = j, \\lambda)$, $\\gamma_t(j) = p(q_t = j|O,\\lambda)$, $\\epsilon_t(i,j) = p(q_t = i,q_{t+1} = j|O,\\lambda)$ Loss functions are used to measure the difference between a machine learning model\u0026#39;s predictions and the actual values. They are essential for evaluating and optimizing models during the training process. Different loss functions, such as mean squared error, mean squared logarithmic error, Kullback-Leibler divergence, and categorical cross-entropy, are used depending on the problem type (e.g., regression, classification, or generative tasks). Selecting an appropriate loss function is crucial for achieving good model performance and convergence during training. Loss Functions Click to expand Loss functions are used to measure the difference between a machine learning model\u0026#39;s predictions and the actual values. They are essential for evaluating and optimizing models during the training process. Different loss functions, such as mean squared error, mean squared logarithmic error, Kullback-Leibler divergence, and categorical cross-entropy, are used depending on the problem type (e.g., regression, classification, or generative tasks). Selecting an appropriate loss function is crucial for achieving good model performance and convergence during training. Click to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers ⭐⭐⭐⭐ 📈 Data Scientists Mean Squared Logarithmic Error (MSLE): $L(y, \\hat{y}) = \\frac{1}{N} \\sum_{i=1}^N (\\log(1 + y_i) - \\log(1 + \\hat{y}_i))^2$, Click to expand 📊 Quants ⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists Huber Loss: $L(y, \\hat{y}) = \\begin{cases} \\frac{1}{2}(y - \\hat{y})^2 \u0026 \\text{for } |y - \\hat{y}| \\le \\delta, \\ \\delta (|y - \\hat{y}| - \\frac{1}{2}\\delta) \u0026 \\text{otherwise} \\end{cases}$, Click to expand 📊 Quants ⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists Hinge Loss: $L(y, \\hat{y}) = \\max(0, 1 - y \\cdot \\hat{y})$, Click to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists KL Divergence: $D_{KL}(P || Q) = \\sum_{i=1}^N P(i) \\log \\frac{P(i)}{Q(i)}$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Categorical Cross-Entropy Loss: $L(y, \\hat{y}) = -\\sum_{i=1}^C y_i \\log \\hat{y}_i$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Binary Cross-Entropy Loss: $L(y, \\hat{y}) = -\\sum_{i=1}^N [y_i \\log \\hat{y}_i + (1 - y_i)\\log (1 - \\hat{y}_i)]$, Graph Embeddings\nClick to expand 📊 Quants ⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ DeepWalk: $f(v) = \\text{SkipGram}(v, v_1, \\dots, v_{2k})$, Click to expand 📊 Quants ⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Node2Vec: $f(v) = \\text{SkipGram}(v, v_1, \\dots, v_{2k})$ with biased random walks, Click to expand 📊 Quants ⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ GraphSAGE: $f(v) = \\text{SAGE}(v, N(v))$, Common ML optimizers are algorithms used to update model parameters during the training process, with the goal of minimizing the loss function. Examples include AdaGrad, Adam, and RMSProp. Optimizers are essential for efficient training of machine learning models, as they determine the convergence rate and can help avoid local minima. Choosing the right optimizer can significantly affect the performance of a model, and researchers often experiment with different optimizers to achieve the best results. Common ML Optimizers Click to expand Common ML optimizers are algorithms used to update model parameters during the training process, with the goal of minimizing the loss function. Examples include AdaGrad, Adam, and RMSProp. Optimizers are essential for efficient training of machine learning models, as they determine the convergence rate and can help avoid local minima. Choosing the right optimizer can significantly affect the performance of a model, and researchers often experiment with different optimizers to achieve the best results. Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Stochastic Gradient Descent with Momentum: $v_t = \\gamma v_{t-1} + \\eta \\nabla f(x_t)$, $x_{t+1} = x_t - v_t$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists AdaGrad: $g_t = g_{t-1} + (\\nabla f(x_t))^2$, $x_{t+1} = x_t - \\frac{\\eta}{\\sqrt{g_t + \\epsilon}} \\nabla f(x_t)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Adam: $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla f(x_t)$, $v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla f(x_t))^2$, $\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$, $\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$, $x_{t+1} = x_t - \\frac{\\eta \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$, Click to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists AdaMax: $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla f(x_t)$, $v_t = \\max(\\beta_2 v_{t-1}, |\\nabla f(x_t)|)$, $x_{t+1} = x_t - \\frac{\\eta m_t}{v_t}$, Click to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists Nadam: $m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla f(x_t)$, $v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla f(x_t))^2$, $\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t} + \\frac{(1 - \\beta_1) \\nabla f(x_t)}{1 - \\beta_1^t}$, $\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$, $x_{t+1} = x_t - \\frac{\\eta \\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$, Evaluation Metrics\nClick to expand 📊 Quants ⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐ ROUGE: $R = \\frac{\\sum_{s \\in \\text{reference}} \\sum_{n \\in \\text{grams}} \\min \\left(c_n(s), c_n(\\text{candidate}) \\right)}{\\sum_{s \\in \\text{reference}} \\sum_{n \\in \\text{grams}} c_n(s)}$, Click to expand 📊 Quants ⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐ BLEU: $BP \\cdot \\exp \\left(\\sum_{n=1}^N w_n \\log p_n \\right)$, Normalization\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Batch Normalization: $\\hat{x}_i = \\frac{x_i - E[x_i]}{\\sqrt{Var[x_i] + \\epsilon}}$, $y_i = \\gamma \\hat{x}_i + \\beta$ Data augmentation is the process of creating new training samples by applying various transformations to the original dataset. This can include techniques such as rotation, scaling, flipping, or adding noise. Data augmentation is important because it helps improve the performance and generalization capabilities of machine learning models, particularly in cases with limited training data. It is widely used in image classification, speech recognition, and natural language processing tasks to increase the diversity of the training set and reduce overfitting. Data Augmentation Click to expand Data augmentation is the process of creating new training samples by applying various transformations to the original dataset. This can include techniques such as rotation, scaling, flipping, or adding noise. Data augmentation is important because it helps improve the performance and generalization capabilities of machine learning models, particularly in cases with limited training data. It is widely used in image classification, speech recognition, and natural language processing tasks to increase the diversity of the training set and reduce overfitting. Hyperparameter tuning is the process of optimizing the configuration parameters of a machine learning model to improve its performance. Hyperparameters control aspects such as the learning rate, regularization strength, and model architecture. Hyperparameter tuning is important because it can significantly affect the performance of a model and help prevent overfitting or underfitting. Techniques for hyperparameter tuning include grid search, random search, and Bayesian optimization. By carefully tuning hyperparameters, researchers can achieve better model performance and generalization capabilities on unseen data. Hyperparameter Tuning Click to expand Hyperparameter tuning is the process of optimizing the configuration parameters of a machine learning model to improve its performance. Hyperparameters control aspects such as the learning rate, regularization strength, and model architecture. Hyperparameter tuning is important because it can significantly affect the performance of a model and help prevent overfitting or underfitting. Techniques for hyperparameter tuning include grid search, random search, and Bayesian optimization. By carefully tuning hyperparameters, researchers can achieve better model performance and generalization capabilities on unseen data. Others\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists EM Algorithm: $Q(\\theta, \\theta^{(t)}) = E_{Z|X,\\theta^{(t)}}[\\log p(X, Z|\\theta)]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Bias-Variance Tradeoff: $\\text{Error} = \\text{Bias}^2 + \\text{Variance} + \\text{Noise}$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Transfer Learning: $\\text{Performance}(\\text{new}) = \\text{Pretrained Model}(\\text{similar}) + \\Delta \\text{Performance}$ Click to expand 📊 Quants 🤖 AI Researchers ⭐⭐⭐⭐⭐ 📈 Data Scientists Stratified Sampling: $\\text{Sampled Data} = \\text{Sample}(\\text{Class}_1, \\dots, \\text{Class}_n)$ explanation here Value Functions and Bellman Equations Click to expand explanation here where $S$ is the state space, $A$ is the action space, $P$ is the state transition function, $R$ is the reward function, and $\\gamma$ is the discount factor Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Markov Decision Process: $\\mathcal{M} = (S, A, P, R, \\gamma)$ The state transition function, represented by $P(s\u0026#39;|s, a)$, describes the probability of transitioning from the current state $s$ to the next state $s\u0026#39;$ given the action $a$ is taken. Click to expand 📊 Quants The state transition function is important for modeling stochastic processes and dynamic systems in quantitative research. 🤖 AI Researchers Understanding state transitions is crucial for AI researchers working on reinforcement learning or dynamic systems. 📈 Data Scientists The state transition function is relevant for data science interviews when discussing stochastic processes or reinforcement learning. Tags: Transition Function, Probability, Dynamic Systems, Stochastic Processes State transition function: $P(s'|s, a)$ The reward function, $R(s, a, s\u0026#39;)$ or $R(s, a)$, is used to define the immediate reward received when transitioning from state $s$ to state $s\u0026#39;$ after taking action $a$. It can be state-action or state-action-next state dependent. Click to expand 📊 Quants Reward functions are critical in quantitative research for defining the objective of an optimization problem. 🤖 AI Researchers Reward functions are essential in AI, particularly in reinforcement learning, for guiding agent behavior. 📈 Data Scientists Reward functions are relevant in data science interviews when discussing reinforcement learning or optimization problems. Tags: Reward Function, Optimization, Objective, Reinforcement Learning Reward function: $R(s, a, s')$ or $R(s, a)$, The state-value function, $V^\\pi(s)$, represents the expected cumulative reward starting from state $s$ and following policy $\\pi$. The expectation is taken over the random rewards $R_t$ and initial state $S_0 = s$. Click to expand 📊 Quants The state-value function is used in quantitative research to evaluate policies in stochastic systems. 🤖 AI Researchers The state-value function is important in AI research, especially for reinforcement learning, where it is used to evaluate policies. 📈 Data Scientists Understanding the state-value function is relevant for data science interviews when discussing reinforcement learning or policy evaluation. Tags: State-Value Function, Policy Evaluation, Reinforcement Learning, Expected Reward State-value function: $V^\\pi(s) = E[\\sum_{t=0}^\\infty \\gamma^t R_t | S_0 = s, \\pi]$, The action-value function, $Q^\\pi(s, a)$, represents the expected cumulative reward starting from state $s$, taking action $a$, and then following policy $\\pi$. The expectation is taken over the random rewards $R_t$, initial state $S_0 = s$, and initial action $A_0 = a$. Click to expand 📊 Quants The action-value function is used in quantitative research to evaluate policies in stochastic systems, considering both state and action. 🤖 AI Researchers The action-value function is important in AI research, especially for reinforcement learning, where it is used to evaluate and improve policies. 📈 Data Scientists Understanding the action-value function is relevant for data science interviews when discussing reinforcement learning or policy improvement. Tags: Action-Value Function, Policy Improvement, Reinforcement Learning, Expected Reward Action-value function: $Q^\\pi(s, a) = E[\\sum_{t=0}^\\infty \\gamma^t R_t | S_0 = s, A_0 = a, \\pi]$, The Bellman equation for $V^\\pi$ expresses the state-value function recursively in terms of the expected immediate reward and the expected future value. It emphasizes the relationship between the value of a state and the values of its successor states under policy $\\pi$. Click to expand 📊 Quants The Bellman equation is used in quantitative research to solve dynamic programming problems, including policy evaluation. 🤖 AI Researchers The Bellman equation is foundational in AI research, particularly in reinforcement learning, for solving value functions. 📈 Data Scientists Understanding the Bellman equation is relevant for data science interviews when discussing dynamic programming or policy evaluation. Tags: Bellman Equation, Dynamic Programming, Policy Evaluation, Reinforcement Learning Bellman equation for $V^\\pi$: $V^\\pi(s) = \\sum_a \\pi(a|s) \\sum_{s'} P(s'|s, a) \\left[ R(s, a, s') + \\gamma V^\\pi(s') \\right]$, The Bellman equation for $Q^\\pi$ expresses the action-value function recursively in terms of the expected immediate reward and the expected future value. It emphasizes the relationship between the value of taking an action in a state and the values of the successor states under policy $\\pi$. Click to expand 📊 Quants The Bellman equation is used in quantitative research to solve dynamic programming problems, including policy improvement. 🤖 AI Researchers The Bellman equation is foundational in AI research, particularly in reinforcement learning, for solving action-value functions and improving policies. 📈 Data Scientists Understanding the Bellman equation is relevant for data science interviews when discussing dynamic programming or policy improvement. Tags: Bellman Equation, Dynamic Programming, Policy Improvement, Reinforcement Learning Bellman equation for $Q^\\pi$: $Q^\\pi(s, a) = \\sum_{s'} P(s'|s, a) \\left[ R(s, a, s') + \\gamma \\sum_{a'} \\pi(a'|s') Q^\\pi(s', a') \\right]$, Optimal state-value function: In Reinforcement Learning (RL), the optimal state-value function, denoted as V*(s), represents the highest expected cumulative reward an agent can achieve from a given state s, considering all possible actions. This relation demonstrates that the optimal value of a state is equal to the maximum value over all possible actions of the optimal action-value function, Q*(s, a). It is important because it helps in finding the best policy, which guides an agent in maximizing the expected cumulative reward. Click to expand 📊 Quants ⭐⭐⭐⭐ In quantitative finance, optimal state-value function can be used in portfolio management to determine the best possible allocation of assets or trading strategies given the current market conditions. 🤖 AI Researchers For AI researchers, V*(s) can be used in various applications, such as path planning, game playing, or robotics, to find the best strategy given a particular state of the environment. 📈 Data Scientists Optimal state-value function is relevant to someone preparing for a Data Science interview, as it demonstrates their understanding of how RL can be used to optimize decision-making problems in various domains, including finance, logistics, and transportation. Tags: RL, state-value function, optimal policy, expected reward, decision-making Optimal state-value function: $V^\\star(s) = \\max_a Q^\\star(s, a)$ Optimal action-value function: In RL, the optimal action-value function, denoted as Q*(s, a), represents the highest expected cumulative reward an agent can achieve from a given state s, taking a particular action a and following the best policy thereafter. This relation demonstrates how to compute Q*(s, a) by considering the probability of transitioning to a new state s\u0026#39;, the immediate reward R(s, a, s\u0026#39;), and the discounted future rewards. It is crucial in finding the best policy to guide the agent\u0026#39;s decisions. Click to expand 📊 Quants ⭐⭐⭐⭐⭐ In quantitative finance, optimal action-value function can be applied to various problems, such as option pricing, where it helps to determine the best possible action to take at each step of the decision process to maximize the expected return on investment. 🤖 AI Researchers For AI researchers, Q*(s, a) can be utilized in applications such as robotics, game playing, or natural language processing, to guide agents in making optimal decisions. 📈 Data Scientists Optimal action-value function is relevant to someone preparing for a Data Science interview, as it demonstrates their understanding of how RL can be used to optimize decision-making problems in various domains, including finance, logistics, and transportation. Tags: RL, action-value function, optimal policy, expected reward, decision-making Optimal action-value function: $Q^\\star(s, a) = \\sum_{s'} P(s'|s, a) \\left[ R(s, a, s') + \\gamma \\max_{a'} Q^(s', a') \\right]$ Policy Improvement\nPolicy improvement: π\u0026#39;(s) = argmax_a Q^π(s, a) is the process of finding the best action for each state according to the current value function Q^π(s, a). It is important as it helps to improve the policy by selecting actions that lead to the highest expected return. For example, in a maze-solving task, policy improvement would choose the action that maximizes the probability of reaching the goal in the shortest number of steps. Click to expand 📊 Quants ⭐⭐⭐⭐ In quantitative finance, policy improvement can be used to find optimal trading strategies by selecting actions that maximize expected returns or minimize risks. For example, it can be applied to portfolio management or algorithmic trading to make better decisions in real-time. 🤖 AI Researchers Policy improvement is relevant for AI researchers in general as it is a key component in reinforcement learning algorithms, which are used in a wide range of applications such as robotics, game playing, and recommendation systems. 📈 Data Scientists Understanding policy improvement is essential for data science interviews, as reinforcement learning is an important topic in data science and machine learning. Candidates may be asked to explain policy improvement or solve problems using this concept. Tags: reinforcement learning, policy improvement, value function, argmax, expected return Policy improvement: $\\pi'(s) = \\arg\\max_a Q^\\pi(s, a)$, Policy iteration: (1) Policy Evaluation → (2) Policy Improvement → (3) Repeat until convergence is a two-step process in reinforcement learning used to find the optimal policy. It alternates between evaluating the current policy and improving it. This process is important because it guarantees convergence to the optimal policy. For example, in a chess game, policy iteration can be used to train an agent that learns to play better over time by refining its policy. Click to expand 📊 Quants In quantitative finance, policy iteration can be applied to problems such as option pricing, risk management, and asset allocation. By iteratively evaluating and improving policies, researchers can develop models that adapt to changing market conditions. 🤖 AI Researchers Policy iteration is relevant for AI researchers in general, as it is a widely-used method in reinforcement learning for solving Markov decision processes and other decision-making problems. It has applications in areas such as robotics, game playing, and traffic control. 📈 Data Scientists Policy iteration is an important concept for data science interviews, as reinforcement learning is a key area in data science and machine learning. Candidates may be asked to explain the policy iteration algorithm or its convergence properties. Tags: reinforcement learning, policy iteration, policy evaluation, policy improvement, convergence Policy iteration: $(1) \\text{Policy Evaluation} \\rightarrow (2) \\text{Policy Improvement} \\rightarrow (3) \\text{Repeat until convergence}$, Value-based Algorithms\nValue iteration calculates the optimal state-value function by iteratively updating the values of all states. It\u0026#39;s important because it converges to the optimal policy when given a perfect model of the environment. Max function ensures the agent selects the best action for each state. Click to expand 📊 Quants Value iteration is relevant to quantitative finance researchers when solving MDPs in areas like portfolio optimization or trading. 🤖 AI Researchers Value iteration is a core concept in reinforcement learning, thus essential for AI researchers. 📈 Data Scientists Value iteration is a fundamental RL concept often asked about in data science interviews to gauge understanding of MDPs. Tags: Value iteration; Optimal policy Value iteration: $V_{t+1}(s) = \\max_a \\sum_{s'} P(s'|s, a) \\left[ R(s, a, s') + \\gamma V_t(s') \\right]$, Temporal Difference (TD) learning updates state-value estimates using the difference between actual and expected rewards. It combines ideas of Monte Carlo and Dynamic Programming, making it suitable for learning online and without a complete model of the environment. Click to expand 📊 Quants TD learning is used in finance when a complete model is unavailable or when online learning is required, such as in algorithmic trading. 🤖 AI Researchers TD learning is a fundamental RL concept, important for AI researchers to understand various learning algorithms. 📈 Data Scientists Temporal Difference learning is often discussed in data science interviews to evaluate understanding of online RL algorithms. Tags: Temporal Difference; TD learning Temporal Difference (TD) learning: $V(S_t) \\leftarrow V(S_t) + \\alpha \\left[ R_{t+1} + \\gamma V(S_{t+1}) - V(S_t) \\right]$, Q-learning is an off-policy TD learning method for estimating action-value functions. It converges to the optimal policy even when following an exploratory policy. It\u0026#39;s widely used in RL since it doesn\u0026#39;t require a model of the environment and learns online. Click to expand 📊 Quants Q-learning is relevant in finance for solving problems like portfolio optimization or trading strategies without complete environment models. 🤖 AI Researchers Q-learning is a fundamental RL algorithm, essential knowledge for AI researchers. 📈 Data Scientists Q-learning is a popular RL algorithm, frequently asked about in data science interviews to assess RL knowledge. Tags: Q-learning; Off-policy learning Q-learning: $Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a) - Q(S_t, A_t) \\right]$, SARSA is an on-policy TD learning method for estimating action-value functions. It updates the Q-values using the next state-action pair, making it sensitive to the policy being followed. It\u0026#39;s useful when the agent needs to learn an optimal policy while acting in the environment. Click to expand 📊 Quants SARSA is relevant in finance when the agent needs to learn and act simultaneously, such as in adaptive trading strategies. 🤖 AI Researchers SARSA is a fundamental on-policy RL algorithm and important for AI researchers to understand various learning approaches. 📈 Data Scientists SARSA is often discussed in data science interviews to evaluate understanding of on-policy RL algorithms. Tags: SARSA; On-policy learning SARSA: $Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} + \\gamma Q(S_{t+1}, A_{t+1}) - Q(S_t, A_t) \\right]$, Deep RL Algorithms\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ Markov Decision Process: $\\mathcal{M} = (S, A, P, R, \\gamma)$ Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Deep Q-Network (DQN) loss: $\\min_\\theta \\sum_{(s, a, r, s', d) \\in \\mathcal{D}} \\left[ r + (1 - d)\\gamma \\max_{a'} Q(s', a'; \\theta^-) - Q(s, a; \\theta) \\right]^2$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Experience replay buffer: $\\mathcal{D}$, a collection of tuples $(s, a, r, s', d)$ used to train the DQN, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Target network: $Q(s, a; \\theta^-)$, a separate network with parameters $\\theta^-$ that are periodically updated from the main network, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Double DQN (DDQN) loss: $\\min_\\theta \\sum_{(s, a, r, s', d) \\in \\mathcal{D}} \\left[ r + (1 - d)\\gamma Q(s', \\arg\\max_{a'} Q(s', a'; \\theta); \\theta^-) - Q(s, a; \\theta) \\right]^2$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Distributed DQN (DDQN): $Q(S_t, A_t; \\theta) \\leftarrow Q(S_t, A_t; \\theta) + \\alpha \\left[ R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a; \\theta') - Q(S_t, A_t; \\theta) \\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Dueling DQN: $Q(s, a; \\theta, \\alpha, \\beta) = V(s; \\theta) + A(s, a; \\alpha) - \\frac{1}{|A|} \\sum_{a'} A(s, a'; \\beta)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Prioritized Experience Replay: $p_i = \\left| r + \\gamma \\max_{a'} Q(s', a'; \\theta^-) - Q(s, a; \\theta) \\right| + \\epsilon$, Policy Gradient Algorithms\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Actor-Critic loss: $L(\\theta, \\phi) = -E_{\\tau \\sim \\pi_{\\theta}}[\\sum_{t=0}^T \\gamma^t (r(s_t, a_t) - V_{\\phi}(s_t)) \\nabla_\\theta \\log \\pi_{\\theta}(a_t|s_t)]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Advantage Actor-Critic (A2C): $L(\\theta, \\phi) = -E_{\\tau \\sim \\pi_{\\theta}}[\\sum_{t=0}^T \\gamma^t A_{\\phi}(s_t, a_t)]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Proximal Policy Optimization (PPO): $L^{\\text{CLIP}}(\\theta) = E_t \\left[ \\min \\left( \\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_\\text{old}}(a_t|s_t)} A^\\text{adv}t, \\text{clip} \\left( \\frac{\\pi\\theta(a_t|s_t)}{\\pi_{\\theta_\\text{old}}(a_t|s_t)}, 1 - \\epsilon, 1 + \\epsilon \\right) A^\\text{adv}_t \\right) \\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Soft Actor-Critic (SAC): $J(\\theta, \\phi) = E_{\\tau \\sim \\pi_{\\theta}} \\left[ \\sum_{t=0}^T \\gamma^t \\left( r(s_t, a_t) - \\alpha \\log \\pi_{\\theta}(a_t|s_t) \\right) \\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Trust Region Policy Optimization (TRPO): $\\text{maximize } \\Delta L(\\theta) \\text{ subject to } KL(\\pi_\\theta | \\pi_{\\theta_\\text{old}}) \\leq \\delta$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Monte Carlo Policy Gradient: $\\nabla J(\\theta) = E_{\\tau \\sim \\pi_{\\theta}}[\\sum_{t=0}^T \\nabla_\\theta \\log \\pi_{\\theta}(a_t|s_t) R_t]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists REINFORCE: $\\theta \\leftarrow \\theta + \\alpha \\sum_{t=0}^T \\nabla_\\theta \\log \\pi_{\\theta}(a_t|s_t) (R_t - b)$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Natural Policy Gradient: $\\nabla_{\\theta} J(\\theta) = F^{-1}(\\theta) \\nabla_{\\theta} J(\\theta)$, Deterministic Policy Gradient\nReinforcement Learning For Games\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ TD-Gammon: $\\delta_t = r_{t+1} + \\gamma V(s_{t+1}; \\theta) - V(s_t; \\theta)$, Exploration Strategies\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ε-greedy exploration: $\\pi(a|s) = \\begin{cases} 1 - \\epsilon + \\frac{\\epsilon}{|A|} \u0026 \\text{if } a = \\arg\\max_{a'} Q(s, a') \\ \\frac{\\epsilon}{|A|} \u0026 \\text{otherwise} \\end{cases}$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Boltzmann exploration: $\\pi(a|s) = \\frac{\\exp(Q(s, a) / \\tau)}{\\sum_{a'} \\exp(Q(s, a') / \\tau)}$, Bandit Algorithms\nIn the Multi-Armed Bandit problem, $Q_t(a)$ is the estimated value of action $a$, $c$ is the exploration parameter, $t$ is the current time step, and $N_t(a)$ is the number of times action $a$ has been selected up to time $t$. The algorithm chooses the action that maximizes the sum of the estimated value and the exploration bonus. Click to expand 📊 Quants Multi-Armed Bandit problems are relevant in quantitative research for resource allocation and decision-making under uncertainty. 🤖 AI Researchers Multi-Armed Bandit problems are important in AI research, as they provide a simplified setting for studying exploration and exploitation trade-offs in reinforcement learning. 📈 Data Scientists Multi-Armed Bandit problems are sometimes discussed in data science interviews to test understanding of exploration-exploitation trade-offs. Tags: Multi-Armed Bandit, Exploration-Exploitation, Reinforcement Learning, Decision-Making Multi-Armed Bandit: $A_t = \\arg\\max_{a \\in A} \\left( Q_t(a) + c \\sqrt{\\frac{\\log t}{N_t(a)}} \\right)$, Upper Confidence Bound (UCB) is an algorithm for the Multi-Armed Bandit problem that chooses the action with the highest upper confidence bound on the mean reward. $\\hat{\\mu}a$ is the empirical mean reward of action $a$, $t$ is the current time step, and $n_a$ is the number of times action $a$ has been selected up to time $t$. Click to expand 📊 Quants UCB is used in quantitative research for resource allocation and decision-making under uncertainty, where confidence intervals are important. 🤖 AI Researchers UCB is relevant in AI research, as it provides a balance between exploration and exploitation in reinforcement learning. 📈 Data Scientists Understanding UCB is helpful for data science interviews, as it can be used to discuss exploration-exploitation trade-offs. Tags: Upper Confidence Bound, Multi-Armed Bandit, Exploration-Exploitation, Reinforcement Learning Upper Confidence Bound (UCB): $A_t = \\arg\\max{a \\in A} \\left( \\hat{\\mu}_a + \\sqrt{\\frac{2 \\log t}{n_a}} \\right)$, Thompson Sampling is a probabilistic algorithm for the Multi-Armed Bandit problem that selects actions based on samples from their posterior distributions. $\\theta^\\star_a$ is a sample from the Beta distribution with parameters $\\alpha_a$ and $\\beta_a$ for action $a$. Click to expand 📊 Quants Thompson Sampling is used in quantitative research for decision-making under uncertainty, incorporating prior knowledge and updating beliefs. 🤖 AI Researchers Thompson Sampling is relevant in AI research, as it provides a Bayesian approach to balancing exploration and exploitation in reinforcement learning. 📈 Data Scientists Understanding Thompson Sampling is helpful for data science interviews, as it can be used to discuss Bayesian methods and exploration-exploitation trade-offs. Tags: Thompson Sampling, Multi-Armed Bandit, Exploration-Exploitation, Reinforcement Learning Thompson Sampling: $A_t = \\arg\\max_a \\theta^\\star_a$, $\\theta^\\star_a \\sim \\text{Beta}(\\alpha_a, \\beta_a)$, In the Contextual Bandit problem, the algorithm chooses the action that maximizes the inner product of the context vector $x_{t, a}$ and the weight vector $\\theta$. This allows for better action selection by considering contextual information. Click to expand 📊 Quants Contextual Bandit problems are relevant in quantitative research for decision-making under uncertainty with contextual information. 🤖 AI Researchers Contextual Bandit problems are important in AI research, as they extend the Multi-Armed Bandit setting to include context in reinforcement learning. 📈 Data Scientists ⭐⭐⭐⭐⭐ Contextual Bandit problems may be discussed in data science interviews to test understanding of decision-making with contextual information. Tags: Contextual Bandit, Multi-Armed Bandit, Reinforcement Learning, Exploration-Exploitation Contextual Bandit: $A_t = \\arg\\max_{a \\in A} \\left( \\theta^T x_{t, a} \\right)$, Linear UCB is an algorithm for Contextual Bandit problem that selects actions based on a linear combination of the context vector $x_{t, a}$ and weight vector $\\theta$. The algorithm also considers exploration by incorporating a confidence term that depends on the context vector and a matrix $V$. Click to expand 📊 Quants Linear UCB is used in quantitative research for decision-making under uncertainty with contextual information and exploration. 🤖 AI Researchers Linear UCB is relevant in AI research, as it balances exploration and exploitation in reinforcement learning with contextual information. 📈 Data Scientists ⭐⭐⭐⭐⭐ Understanding Linear UCB is helpful for data science interviews, as it can be used to discuss exploration-exploitation trade-offs with contextual information. Tags: Linear UCB, Contextual Bandit, Exploration-Exploitation, Reinforcement Learning Linear UCB: $A_t = \\arg\\max_{a \\in A} \\left( \\theta^T x_{t, a} + \\alpha \\sqrt{x_{t, a}^T V^{-1} x_{t, a}} \\right)$, LinUCB is similar to Linear UCB but uses an individual matrix $A_a$ for each action $a$ instead of a shared matrix $V$. This allows for better exploration by considering the uncertainty associated with each action separately. Click to expand 📊 Quants LinUCB is relevant in quantitative research for decision-making under uncertainty with contextual information and individual action exploration. 🤖 AI Researchers LinUCB is important in AI research, as it provides a more fine-grained exploration and exploitation balance in reinforcement learning with contextual information. 📈 Data Scientists ⭐⭐⭐⭐⭐ Understanding LinUCB is helpful for data science interviews, as it can be used to discuss exploration-exploitation trade-offs with contextual information and individual action exploration. Tags: LinUCB, Linear UCB, Contextual Bandit, Exploration-Exploitation LinUCB: $A_t = \\arg\\max_{a \\in A} \\left( \\theta^T x_{t, a} + \\alpha \\sqrt{x_{t, a}^T A_a^{-1} x_{t, a}} \\right)$, Click to expand 📊 Quants ⭐⭐⭐⭐⭐ 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐ EXP3: $\\pi_t(a) = \\frac{(1 - \\gamma) \\hat{w}{t-1}(a) + \\gamma / K}{\\sum{a'=1}^K ((1 - \\gamma) \\hat{w}_{t-1}(a') + \\gamma / K)}$, Advanced RL Algorithms\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Entropy-regularized objective: $J(\\theta) = E_{\\tau \\sim \\pi_{\\theta}} \\left[ \\sum_{t=0}^T \\gamma^t \\left( r(s_t, a_t) + \\alpha H(\\pi_{\\theta}(\\cdot|s_t)) \\right) \\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists DDPG: $\\nabla_{\\theta^\\mu} J = \\mathbb{E}{s_t \\sim D} \\left[\\nabla{a} Q(s, a|\\theta^Q) \\nabla_{\\theta^\\mu} \\mu(s|\\theta^\\mu)\\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Monte Carlo Tree Search (MCTS): $Q(s, a) = \\frac{\\sum_{i=1}^n R_i(s, a)}{N(s, a)}$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Upper Confidence Bound for Trees (UCT): $a^* = \\arg\\max_a \\left( Q(s, a) + c \\sqrt{\\frac{\\log N(s)}{N(s, a)}} \\right)$, Temporal Difference Variants\nClick to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Expected SARSA: $Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} + \\gamma E_{\\pi}[Q(S_{t+1}, A_{t+1})] - Q(S_t, A_t) \\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Dyna-Q: $Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} + \\gamma \\max_a Q(S_{t+1}, a) - Q(S_t, A_t) \\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists ⭐⭐⭐⭐⭐ Model learning: $P(s'|s, a) \\leftarrow P(s'|s, a) + \\alpha \\left[ 1 - P(s'|s, a) \\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists R-learning: $\\rho \\leftarrow \\rho + \\beta \\left[ R_{t+1} - \\rho + \\gamma \\max_a Q(S_{t+1}, a) - Q(S_t, A_t) \\right]$, Click to expand 📊 Quants 🤖 AI Researchers 📈 Data Scientists Average Reward SARSA: $Q(S_t, A_t) \\leftarrow Q(S_t, A_t) + \\alpha \\left[ R_{t+1} - \\bar{R}t + Q(S{t+1}, A_{t+1}) - Q(S_t, A_t) \\right]$, Other\nOptimization Problems\nOptimization problem: Minimizing a function f(x) over a set X. Click to expand 📊 Quants Optimization problems are central in quantitative finance for portfolio construction, risk management, and asset pricing. 🤖 AI Researchers Optimization is a key concept in AI for training models, reinforcement learning, and decision-making. 📈 Data Scientists Optimization problems are common in data science for model fitting and parameter estimation. Tags: optimization, minimize, objective function Optimization problem: $\\min_{x \\in \\mathcal{X}} f(x)$ Feasible set: Represents the set of all possible solutions that satisfy the constraints of an optimization problem. Click to expand 📊 Quants ⭐⭐⭐⭐⭐ Feasible sets appear in finance for portfolio optimization and risk management, ensuring constraints like budget or exposure limits are met. 🤖 AI Researchers Feasible sets are used in AI for constraint satisfaction and ensuring models meet requirements. 📈 Data Scientists Understanding feasible sets is essential for solving optimization problems and meeting real-world constraints in data science. Tags: feasible set, constraints, solutions Feasible set: $\\mathcal{X} = \\{x \\in \\mathbb{R}^n : g_i(x) \\le 0, i = 1, \\ldots, m\\}$ Linear Programming: Optimization of a linear objective function subject to linear constraints. Click to expand 📊 Quants Linear programming is used in finance for portfolio optimization, resource allocation, and risk management. 🤖 AI Researchers Linear programming is important in AI for constraint satisfaction problems and planning. 📈 Data Scientists Linear programming is a fundamental optimization technique in data science, used for model fitting and parameter estimation. Tags: linear programming, LP, linear optimization Linear Programming: $\\min_{x \\in \\mathbb{R}^n} c^T x$ subject to $Ax \\le b$ Quadratic Programming: Optimization of a quadratic objective function subject to linear constraints. Click to expand 📊 Quants Quadratic programming is common in finance for portfolio optimization, specifically in mean-variance optimization and risk-adjusted performance measures. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Quadratic programming is used in AI for support vector machines and model training. 📈 Data Scientists Quadratic programming is essential in data science for quadratic loss minimization and model fitting. Tags: quadratic programming, QP, quadratic optimization Quadratic Programming: $\\min_{x \\in \\mathbb{R}^n} \\frac{1}{2} x^T Q x + c^T x$ subject to $Ax \\le b$ Constrained Optimization: Minimizing a function subject to inequality and equality constraints. Click to expand 📊 Quants Constrained optimization is widely used in finance for portfolio construction, risk management, and asset pricing under constraints. 🤖 AI Researchers Constrained optimization is prevalent in AI for model training, reinforcement learning, and planning. 📈 Data Scientists Constrained optimization problems are common in data science for model fitting and parameter estimation under real-world constraints. Tags: constrained optimization, constraints, optimization Constrained Optimization: $\\min_{x \\in X} f(x)$ subject to $g(x) \\le 0$ and $h(x) = 0$ Lagrangian and duality: Methods for solving constrained optimization problems Lagrangian and duality Click to expand Lagrangian and duality: Methods for solving constrained optimization problems Lagrangian: Combines the objective function and constraints into a single function. Click to expand 📊 Quants ⭐⭐⭐⭐ The Lagrangian is used in finance to solve constrained optimization problems like portfolio optimization and risk management. 🤖 AI Researchers ⭐⭐⭐⭐⭐ The Lagrangian is essential in AI for solving constrained optimization problems and duality theory. 📈 Data Scientists The Lagrangian is important in data science for solving optimization problems with constraints. Tags: Lagrangian, Lagrange multipliers, duality Lagrangian: $L(x, \\lambda, \\nu) = f(x) + \\sum_{i=1}^m \\lambda_i g_i(x) + \\sum_{j=1}^p \\nu_j h_j(x)$ Lagrange multipliers: Provide a method for finding extrema of a function subject to constraints. Click to expand 📊 Quants ⭐⭐⭐⭐ Lagrange multipliers are used in finance for portfolio optimization and risk management under constraints. 🤖 AI Researchers ⭐⭐⭐⭐ Lagrange multipliers are used in AI for solving constrained optimization problems and duality theory. 📈 Data Scientists ⭐⭐⭐⭐⭐ Lagrange multipliers are useful for data science when solving optimization problems with constraints. Tags: Lagrange multipliers, constrained optimization, extrema Lagrange multipliers: $\\lambda^\\star_i = -\\frac{\\partial f}{\\partial g_i}(x^\\star)$ Convexity: A property of functions and optimization problems that guarantees a unique global minimum Convexity Click to expand Convexity: A property of functions and optimization problems that guarantees a unique global minimum Convex function: A function whose line segment between any two points lies above the graph of the function. Click to expand 📊 Quants Convex functions are important in finance for portfolio optimization and risk management, ensuring unique minimum solutions. 🤖 AI Researchers Convex functions are crucial in AI for convex optimization, ensuring unique optimal solutions in learning algorithms. 📈 Data Scientists Convex functions are important in data science for model fitting and optimization, ensuring unique solutions. Tags: convex function, convexity, global minimum Convex function: $f(\\alpha x + (1-\\alpha)y) \\le \\alpha f(x) + (1-\\alpha) f(y)$ Concave function: A function whose line segment between any two points lies below the graph of the function. Click to expand 📊 Quants ⭐⭐⭐⭐ Concave functions are relevant in finance for utility maximization and risk-averse decision-making. 🤖 AI Researchers ⭐⭐⭐⭐ Concave functions are important in AI for maximizing rewards and risk-averse decision-making. 📈 Data Scientists ⭐⭐⭐⭐⭐ Concave functions are relevant in data science for maximizing utility and decision-making under uncertainty. Tags: concave function, concavity, global maximum Concave function: $f(\\alpha x + (1-\\alpha)y) \\ge \\alpha f(x) + (1-\\alpha) f(y)$ Optimality Conditions: Conditions that characterize the solution of an optimization problem Optimality Conditions Click to expand Optimality Conditions: Conditions that characterize the solution of an optimization problem First-order condition: The gradient of the function at the optimal point is zero. Click to expand 📊 Quants First-order conditions are used in finance to find optimal solutions for asset pricing and portfolio optimization. 🤖 AI Researchers ⭐⭐⭐⭐⭐ First-order conditions are essential in AI for gradient-based optimization and learning algorithms. 📈 Data Scientists First-order conditions are important in data science for model fitting and parameter estimation using gradient techniques. Tags: first-order condition, gradient, optimality First-order condition: $\\nabla f(x^\\star) = 0$ Second-order condition: The Hessian matrix at the optimal point is positive definite. Click to expand 📊 Quants ⭐⭐⭐⭐ Second-order conditions are used in finance to ensure local minima in optimization problems like portfolio optimization and risk management. 🤖 AI Researchers ⭐⭐⭐ Second-order conditions are used in AI to verify the convexity of optimization problems in learning algorithms. 📈 Data Scientists ⭐⭐⭐⭐ Second-order conditions are helpful in data science for model fitting and parameter estimation, ensuring local minima. Tags: second-order condition, Hessian, positive definite Second-order condition: $H(x^\\star) \\succ 0$ KKT conditions: Necessary and sufficient conditions for a constrained optimization problem to have an optimal solution. Click to expand 📊 Quants ⭐⭐⭐⭐ KKT conditions are used in finance to solve constrained optimization problems like portfolio optimization and risk management. 🤖 AI Researchers ⭐⭐⭐⭐⭐ KKT conditions are used in AI for solving constrained optimization problems and duality theory. 📈 Data Scientists KKT conditions are important in data science for solving constrained optimization problems and ensuring optimality. Tags: KKT conditions, Karush-Kuhn-Tucker, constrained optimization KKT conditions: $\\begin{cases} \\nabla f(x^\\star) + \\sum_{i=1}^m \\lambda_i^\\star \\nabla g_i(x^\\star) = 0 \\ g_i(x^\\star) \\le 0, \\lambda_i^\\star \\ge 0, \\lambda_i^\\star g_i(x^\\star) = 0, i=1,\\ldots,m \\ x^\\star \\in \\mathcal{X} \\end{cases}$ Gradient and Hessian Gradient and Hessian Click to expand Gradient and Hessian Gradient represents the first-order partial derivatives of a function, while Hessian is the matrix of second-order partial derivatives. They are useful in optimization problems. Click to expand 📊 Quants Gradients and Hessians are crucial for understanding the behavior of financial models, as they provide insights into the curvature and sensitivity of the models to various factors. 🤖 AI Researchers In artificial intelligence research, gradient-based methods like gradient descent are widely used for optimizing neural networks and other machine learning models. 📈 Data Scientists Gradients and Hessians are important for understanding the optimization techniques used in data science, which may come up in interviews. Tags: gradient, hessian, partial derivatives, optimization Gradient: $\\nabla f(x) = \\left(\\frac{\\partial f}{\\partial x_1}(x), \\ldots, \\frac{\\partial f}{\\partial x_n}(x)\\right)$, Hessian matrix: $H = \\begin{bmatrix} \\frac{\\partial^2 f}{\\partial x_1^2} \u0026 \\cdots \u0026 \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\ \\vdots \u0026 \\ddots \u0026 \\vdots \\ \\frac{\\partial^2 f}{\\partial x_n \\partial x_1} \u0026 \\cdots \u0026 \\frac{\\partial^2 f}{\\partial x_n^2} \\end{bmatrix}$, Optimization Algorithms Optimization Algorithms Click to expand Optimization Algorithms Newton\u0026#39;s method uses the inverse Hessian to update the solution iteratively, which can converge quickly for smooth functions. Click to expand 📊 Quants In quantitative finance research, Newton\u0026#39;s method can be used for portfolio optimization and calibration of financial models. 🤖 AI Researchers Newton\u0026#39;s method is used in AI research for optimizing smooth functions, but it may not be suitable for large-scale problems due to the need to compute the inverse Hessian. 📈 Data Scientists Newton\u0026#39;s method might come up in data science interviews when discussing optimization techniques. Tags: newton\u0026#39;s method, optimization, hessian Newton's method: $x^{(k+1)} = x^{(k)} - H^{-1}(x^{(k)})\\nabla f(x^{(k)})$, Quasi-Newton methods approximate the inverse Hessian using a matrix B_k, reducing computational complexity compared to Newton\u0026#39;s method. Click to expand 📊 Quants Quasi-Newton methods are used in finance for portfolio optimization and model calibration, where exact Hessian computation may be expensive. 🤖 AI Researchers In AI research, quasi-Newton methods like BFGS and L-BFGS are popular choices for optimizing smooth functions with lower computational complexity than Newton\u0026#39;s method. 📈 Data Scientists Quasi-Newton methods may come up in data science interviews when discussing optimization techniques with lower complexity than Newton\u0026#39;s method. Tags: quasi-newton, optimization, bfgs Quasi-Newton method: $x^{(k+1)} = x^{(k)} - B_k^{-1}\\nabla f(x^{(k)})$, Conjugate gradient is an iterative optimization algorithm that uses conjugate search directions to minimize a quadratic function efficiently. Click to expand 📊 Quants In quantitative finance research, conjugate gradient can be applied to solve linear systems arising from partial differential equations or portfolio optimization problems. 🤖 AI Researchers In AI research, conjugate gradient is used to solve linear systems arising from the optimization of quadratic functions, but it is less popular for deep learning due to its sensitivity to the choice of step size. 📈 Data Scientists Conjugate gradient may come up in data science interviews when discussing optimization techniques for quadratic functions. Tags: conjugate gradient, optimization, quadratic Conjugate gradient: $x^{(k+1)} = x^{(k)} + \\alpha_k p^{(k)}$, Descent and search methods Descent and search methods Click to expand Descent and search methods Steepest descent is an optimization algorithm that uses the negative gradient as the search direction, which is the direction of the fastest decrease in function value. Click to expand 📊 Quants In finance research, steepest descent can be used for simple optimization problems like mean-variance portfolio optimization or model calibration. 🤖 AI Researchers Steepest descent is widely used in AI research as the basis for gradient-based optimization algorithms like gradient descent and its variants. 📈 Data Scientists Steepest descent is important for understanding basic optimization techniques in data science and may come up in interviews. Tags: steepest descent, optimization, gradient descent Steepest descent: $p^{(k)} = -\\nabla f(x^{(k)})$, Line search aims to find an optimal step size that minimizes the function value along a given search direction. Click to expand 📊 Quants Line search is used in finance research as a component of various optimization algorithms like steepest descent or conjugate gradient. 🤖 AI Researchers In AI research, line search is often used in combination with other optimization algorithms to determine an appropriate step size for updating model parameters. 📈 Data Scientists Line search may come up in data science interviews when discussing optimization techniques and step size selection. Tags: line search, optimization, step size Line search: $\\alpha_k = \\arg\\min_{\\alpha \u003e 0} f(x^{(k)} + \\alpha p^{(k)})$, Armijo rule is a line search condition that ensures sufficient decrease in the function value along the search direction. Click to expand 📊 Quants In finance research, Armijo rule can be used as a line search condition in various optimization algorithms to ensure convergence. 🤖 AI Researchers In AI research, the Armijo rule can be used to determine step sizes in gradient-based optimization algorithms to ensure sufficient progress. 📈 Data Scientists Armijo rule may come up in data science interviews when discussing line search conditions and optimization techniques. Tags: armijo rule, line search, optimization Armijo rule: $f(x^{(k)} + \\alpha p^{(k)}) \\le f(x^{(k)}) + c\\alpha \\nabla f(x^{(k)})^T p^{(k)}$, Wolfe conditions combine the Armijo rule with a curvature condition to ensure both sufficient decrease and sufficient curvature in the function value along the search direction. Click to expand 📊 Quants Wolfe conditions are used in finance research as line search conditions in various optimization algorithms for better convergence properties. 🤖 AI Researchers In AI research, Wolfe conditions can be used to determine step sizes in gradient-based optimization algorithms for better convergence behavior. 📈 Data Scientists Wolfe conditions may come up in data science interviews when discussing line search conditions and optimization techniques. Tags: wolfe conditions, line search, optimization Wolfe conditions: $\\begin{cases} f(x^{(k)} + \\alpha p^{(k)}) \\le f(x^{(k)}) + c_1\\alpha \\nabla f(x^{(k)})^T p^{(k)} \\ \\nabla f(x^{(k)} + \\alpha p^{(k)})^T p^{(k)} \\ge c_2 \\nabla f(x^{(k)})^T p^{(k)} \\end{cases}$, Golden section search is an optimization method for unimodal functions that uses the golden ratio to divide the search interval. Click to expand 📊 Quants Golden section search can be used in finance research for simple unimodal optimization problems, but it is less popular than other methods like gradient-based algorithms. 🤖 AI Researchers In AI research, golden section search is not widely used due to its limited applicability to unimodal functions and the popularity of gradient-based methods. 📈 Data Scientists Golden section search might come up in data science interviews when discussing optimization techniques for unimodal functions. Tags: golden section search, optimization, unimodal Golden section search: $\\frac{a_{n+1} - a_n}{a_n - a_{n-1}} = \\frac{b_{n+1} - b_n}{b_n - b_{n-1}} = \\phi$, Bisection method is an optimization algorithm that iteratively divides the search interval in half to find the minimum of a unimodal function. Click to expand 📊 Quants Bisection method can be used in finance research for simple unimodal optimization problems, but it is less popular than other methods like gradient-based algorithms. 🤖 AI Researchers In AI research, bisection method is not widely used due to its limited applicability to unimodal functions and the popularity of gradient-based methods. 📈 Data Scientists Bisection method might come up in data science interviews when discussing optimization techniques for unimodal functions. Tags: bisection method, optimization, unimodal Bisection method: $x^{(k+1)} = \\frac{a^{(k)} + b^{(k)}}{2}$, Root-finding and fixed-point methods Root-finding and fixed-point methods Click to expand Root-finding and fixed-point methods Secant method iteratively refines the root approximation by using previous iterations\u0026#39; function values and approximations. Click to expand 📊 Quants Used for finding roots in option pricing models like Black-Scholes-Merton. 🤖 AI Researchers 3 📈 Data Scientists 5 Tags: Might be asked about numerical methods to solve equations in data science interviews. Secant method: $x^{(k+1)} = x^{(k)} - \\frac{f(x^{(k)}) (x^{(k)} - x^{(k-1)})}{f(x^{(k)}) - f(x^{(k-1)})}$ Fixed-point iteration converges to a solution when the function g has a fixed point for the given initial value. Click to expand 📊 Quants Used for solving nonlinear equations arising in various quantitative finance problems. 🤖 AI Researchers 4 📈 Data Scientists 6 Tags: Important for understanding convergence properties of iterative algorithms in data science interviews. Fixed-point iteration: $x^{(k+1)} = g(x^{(k)})$ Banach fixed-point theorem provides conditions for the existence and uniqueness of fixed points for contraction mappings. Click to expand 📊 Quants Useful for proving convergence of iterative algorithms in quantitative finance research. 🤖 AI Researchers 5 📈 Data Scientists 3 Tags: Less likely to be asked in data science interviews but useful for understanding convergence properties. Banach fixed-point theorem: $||g(x) - g(y)|| \\le L||x - y||$ Lipschitz constant measures the amount by which a function can stretch or compress distances between points. Click to expand 📊 Quants Helps to analyze stability and convergence of numerical algorithms in quantitative finance. 🤖 AI Researchers 5 📈 Data Scientists 4 Tags: Might be asked about Lipschitz continuity and its importance in optimization problems during data science interviews. Lipschitz constant: $L = \\sup_{x \\neq y} \\frac{||g(x) - g(y)||}{||x - y||}$ Iterative methods and approximations Iterative methods and approximations Click to expand Iterative methods and approximations Successive approximations method is an iterative way to refine an initial guess to find the solution of an equation. Click to expand 📊 Quants Used for solving differential equations or systems of equations arising in quantitative finance. 🤖 AI Researchers 4 📈 Data Scientists 5 Tags: Important for understanding how iterative algorithms work and might be asked during data science interviews. Successive approximations: $x^{(k)} = x^{(0)} + \\sum_{i=1}^k \\Delta x^{(i)}$ Perturbed optimization adds a small perturbation to the objective function to smoothen the optimization landscape. Click to expand 📊 Quants Used for improving robustness of optimization algorithms in quantitative finance models. 🤖 AI Researchers 6 📈 Data Scientists 5 Tags: Might be asked about regularization techniques and their importance in machine learning during data science interviews. Perturbed optimization: $\\min_{x \\in \\mathcal{X}} f(x) + \\epsilon g(x)$ Homotopy and Saddle Point methods Homotopy and Saddle Point methods Click to expand Homotopy and Saddle Point methods Homotopy method is a technique that deforms one optimization problem into another, making it easier to solve. Click to expand 📊 Quants Used for solving hard optimization problems arising in option pricing or portfolio optimization. 🤖 AI Researchers 5 📈 Data Scientists 4 Tags: Less likely to be asked in data science interviews but useful for understanding advanced optimization techniques. Homotopy method: $\\min_{x \\in \\mathcal{X}} (1 - \\lambda)f(x) + \\lambda g(x)$ Saddle point is a point where the gradient of the Lagrangian function with respect to primal and dual variables is zero. Click to expand 📊 Quants Crucial for solving constrained optimization problems in quantitative finance like portfolio optimization. 🤖 AI Researchers 7 📈 Data Scientists 6 Tags: Might be asked about constrained optimization and duality during data science interviews. Saddle point: $\\nabla_x L(x^\\star, \\lambda^\\star) = 0, \\nabla_\\lambda L(x^\\star, \\lambda^\\star) = 0$ Primal-dual method is an optimization algorithm that updates primal and dual variables iteratively to find the saddle point of the Lagrangian. Click to expand 📊 Quants Used for solving constrained optimization problems in quantitative finance like portfolio optimization. 🤖 AI Researchers 6 📈 Data Scientists 5 Tags: Might be asked about primal-dual methods and their importance in constrained optimization during data science interviews. Primal-dual method: $x^{(k+1)} = \\arg\\min_{x \\in \\mathcal{X}} L(x, \\lambda^{(k)})$ Penalty and Barrier Methods Penalty and Barrier Methods Click to expand Penalty and Barrier Methods Penalty function adds a penalty term to the objective function for constraint violations, making it easier to solve. Click to expand 📊 Quants Used for solving constrained optimization problems in quantitative finance like option pricing or risk management. 🤖 AI Researchers 5 📈 Data Scientists 5 Tags: Might be asked about penalty methods and their importance in constrained optimization during data science interviews. Penalty function: $P(x) = f(x) + \\sum_{i=1}^m \\phi(g_i(x))$ Barrier function adds a barrier term to the objective function, preventing the solution from crossing constraint boundaries. Click to expand 📊 Quants Used for solving constrained optimization problems in quantitative finance like option pricing or risk management. 🤖 AI Researchers 5 📈 Data Scientists 5 Tags: Might be asked about barrier methods and their importance in constrained optimization during data science interviews. Barrier function: $B(x) = f(x) - \\mu \\sum_{i=1}^m \\log(-g_i(x))$ ADMM ADMM Click to expand ADMM ADMM is an optimization algorithm that combines splitting and dual ascent methods to solve large-scale convex optimization problems. Click to expand 📊 Quants Used for solving large-scale optimization problems in quantitative finance like portfolio optimization or risk management. 🤖 AI Researchers 7 📈 Data Scientists 7 Tags: Likely to be asked about ADMM and its applications in large-scale optimization during data science interviews. ADMM update: $x^{(k+1)} = \\arg\\min_x \\mathcal{L}_\\rho(x, z^{(k)}, \\lambda^{(k)})$, $z^{(k+1)} = \\arg\\min_z \\mathcal{L}_\\rho(x^{(k+1)}, z, \\lambda^{(k)})$, $\\lambda^{(k+1)} = \\lambda^{(k)} + \\rho(g(x^{(k+1)}) - z^{(k+1)})$ Proximal Gradient Methods Proximal Gradient Methods Click to expand Proximal Gradient Methods Proximal gradient is an iterative optimization algorithm that finds the minimum of a function f(x) plus a regularization term h(x). Proximal operator finds the point y that minimizes the sum of h(y) and the squared distance to x. Click to expand 📊 Quants ⭐⭐⭐⭐ Used in sparse recovery problems, LASSO, and portfolio optimization. 🤖 AI Researchers Applied in regularized neural networks and sparse autoencoders. 📈 Data Scientists Important in solving optimization problems with non-differentiable functions. Tags: proximal gradient, optimization, regularization Proximal gradient: $x^{(k+1)} = \\text{prox}_{\\alpha h}(x^{(k)} - \\alpha \\nabla f(x^{(k)}))$, Proximal operator is used to find a point y that minimizes the sum of a function h(y) and the squared distance between y and x. Click to expand 📊 Quants ⭐⭐⭐⭐ Used in sparse recovery problems, LASSO, and portfolio optimization. 🤖 AI Researchers Applied in regularized neural networks and sparse autoencoders. 📈 Data Scientists Important in solving optimization problems with non-differentiable functions. Tags: proximal operator, optimization, regularization Proximal operator: $\\text{prox}_h(x) = \\arg\\min_y \\left(h(y) + \\frac{1}{2} ||y-x||^2\\right)$, FISTA update is part of the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), used for accelerated gradient descent with proximal operators. Click to expand 📊 Quants ⭐⭐⭐ Used in compressed sensing and LASSO problems in finance. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Applied in sparse coding and image reconstruction. 📈 Data Scientists ⭐⭐⭐⭐⭐ Relevant for optimization problems with non-differentiable functions. Tags: FISTA, optimization, gradient descent FISTA update: $y^{(k+1)} = x^{(k)} - \\alpha \\nabla f(x^{(k)})$, FISTA update is part of the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), used for accelerated gradient descent with proximal operators. Click to expand 📊 Quants ⭐⭐⭐ Used in compressed sensing and LASSO problems in finance. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Applied in sparse coding and image reconstruction. 📈 Data Scientists ⭐⭐⭐⭐⭐ Relevant for optimization problems with non-differentiable functions. Tags: FISTA, optimization, gradient descent FISTA update: $x^{(k+1)} = \\text{prox}_{\\alpha h}(y^{(k+1)})$, ISTA update is part of the Iterative Shrinkage-Thresholding Algorithm (ISTA), used for solving optimization problems with non-differentiable functions using proximal operators. Click to expand 📊 Quants ⭐⭐⭐ Used in compressed sensing and LASSO problems in finance. 🤖 AI Researchers Applied in sparse coding and image reconstruction. 📈 Data Scientists Important in solving optimization problems with non-differentiable functions. Tags: ISTA, optimization, regularization ISTA update: $x^{(k+1)} = \\text{prox}_{\\alpha h}(x^{(k)} - \\alpha \\nabla f(x^{(k)}))$, Nesterov acceleration improves the convergence rate of gradient-based optimization algorithms using a momentum term. Click to expand 📊 Quants ⭐⭐⭐⭐ Used to accelerate convergence in portfolio optimization and risk management. 🤖 AI Researchers Applied in deep learning and training neural networks. 📈 Data Scientists Important for improving optimization algorithms in data science problems. Tags: Nesterov, acceleration, optimization Nesterov acceleration: $x^{(k+1)} = \\text{prox}_{\\alpha h}(y^{(k)} - \\alpha \\nabla f(y^{(k)}))$, Nesterov momentum is a technique to improve the convergence rate of gradient-based optimization algorithms by incorporating a momentum term. Click to expand 📊 Quants ⭐⭐⭐⭐ Used to accelerate convergence in portfolio optimization and risk management. 🤖 AI Researchers Applied in deep learning and training neural networks. 📈 Data Scientists Important for improving optimization algorithms in data science problems. Tags: Nesterov, momentum, optimization Nesterov momentum: $y^{(k+1)} = x^{(k+1)} + \\frac{k}{k+3}(x^{(k+1)} - x^{(k)})$, Linear Minimization and Frank-Wolfe Method Linear Minimization and Frank-Wolfe Method Click to expand Linear Minimization and Frank-Wolfe Method Frank-Wolfe method is an iterative algorithm for solving constrained convex optimization problems by minimizing a linear approximation of the objective function at each step. Click to expand 📊 Quants ⭐⭐⭐ Used in portfolio optimization and solving linear programming problems in finance. 🤖 AI Researchers ⭐⭐⭐⭐ Applied in sparse coding and structured prediction. 📈 Data Scientists Important for solving constrained convex optimization problems. Tags: Frank-Wolfe, linear minimization, convex optimization Frank-Wolfe method: $s^{(k)} = \\arg\\min_{s \\in \\mathcal{X}} \\nabla f(x^{(k)})^T s$, Frank-Wolfe update is the step in the Frank-Wolfe method that updates the solution by combining the current solution and a step towards the linear minimizer. Click to expand 📊 Quants ⭐⭐⭐ Used in portfolio optimization and solving linear programming problems in finance. 🤖 AI Researchers ⭐⭐⭐⭐ Applied in sparse coding and structured prediction. 📈 Data Scientists Important for solving constrained convex optimization problems. Tags: Frank-Wolfe, update, convex optimization Frank-Wolfe update: $x^{(k+1)} = x^{(k)} + \\gamma_k(s^{(k)} - x^{(k)})$, Convergence and subdifferential calculus Convergence and subdifferential calculus Click to expand Convergence and subdifferential calculus Convergence rate measures how fast an iterative optimization algorithm approaches the optimal solution. Click to expand 📊 Quants ⭐⭐⭐⭐⭐ Important for analyzing the efficiency of optimization algorithms used in quantitative finance research. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Relevant for studying convergence properties of AI algorithms. 📈 Data Scientists Useful for understanding algorithm performance in data science interviews. Tags: convergence rate, optimization, efficiency Convergence rate: $\\frac{f(x^{(k)}) - f(x^*)}{f(x^0) - f(x^\\star)} \\le \\rho^k$, Subdifferential is a generalization of gradient for non-differentiable functions, containing all subgradients at a given point. Click to expand 📊 Quants ⭐⭐⭐ Used in portfolio optimization and risk management with non-differentiable functions. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Applied in subgradient-based learning algorithms and support vector machines. 📈 Data Scientists Important for understanding non-differentiable optimization problems. Tags: subdifferential, subgradient, optimization Subdifferential: $\\partial f(x) = \\{v \\in \\mathbb{R}^n : f(y) \\ge f(x) + v^T(y-x), \\forall y \\in \\mathbb{R}^n\\}$, Subgradient method is an iterative optimization algorithm for non-differentiable convex functions using subgradients instead of gradients. Click to expand 📊 Quants ⭐⭐⭐ Used in portfolio optimization and risk management with non-differentiable functions. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Applied in subgradient-based learning algorithms and support vector machines. 📈 Data Scientists Important for understanding non-differentiable optimization problems. Tags: subgradient method, optimization, convex functions Subgradient method: $x^{(k+1)} = x^{(k)} - \\alpha_k g^{(k)}$, Projected subgradient is a variant of the subgradient method that projects the updated solution back onto the feasible set at each iteration. Click to expand 📊 Quants ⭐⭐⭐ Used in portfolio optimization and risk management with non-differentiable functions and constraints. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Applied in constrained learning algorithms and support vector machines. 📈 Data Scientists Important for understanding non-differentiable optimization problems with constraints. Tags: projected subgradient, constrained optimization, convex functions Projected subgradient: $x^{(k+1)} = \\mathcal{P}_{\\mathcal{X}}(x^{(k)} - \\alpha_k g^{(k)})$, Concave-convex procedure is an iterative algorithm for solving non-convex optimization problems by linearizing the concave part of the objective function. Click to expand 📊 Quants ⭐⭐ Used in non-convex optimization problems in quantitative finance research. 🤖 AI Researchers ⭐⭐⭐⭐ Applied in non-convex learning algorithms and structured prediction. 📈 Data Scientists ⭐⭐⭐⭐⭐ Relevant for understanding non-convex optimization problems. Tags: concave-convex procedure, non-convex optimization, algorithm Concave-convex procedure: $x^{(k+1)} = \\arg\\min_x \\left(\\nabla f(x^{(k)})^T(x - x^{(k)}) + h(x)\\right)$, Smoothing approximation is a technique to approximate a non-differentiable function with a smooth function by minimizing the sum of the original function and a squared distance term. Click to expand 📊 Quants ⭐⭐⭐ Used in portfolio optimization and risk management with non-differentiable functions. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Applied in smooth optimization algorithms for AI research. 📈 Data Scientists Important for understanding non-differentiable optimization problems and their approximations. Tags: smoothing approximation, non-differentiable, optimization Smoothing approximation: $f_\\epsilon(x) = \\inf_{y \\in \\mathbb{R}^n} \\left(f(y) + \\frac{1}{2\\epsilon} ||x - y||^2\\right)$, Augmented Lagrangian is a technique for solving constrained optimization problems by adding a penalty term to the objective function that includes both Lagrange multipliers and constraint violation penalties. Click to expand 📊 Quants ⭐⭐⭐⭐ Used in portfolio optimization, risk management, and solving constrained optimization problems in finance. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Applied in constrained learning algorithms and support vector machines. 📈 Data Scientists Important for understanding constrained optimization problems and their solutions. Tags: augmented Lagrangian, constrained optimization, penalty method Augmented Lagrangian: $\\mathcal{L}_\\rho(x, \\lambda) = f(x) + \\sum_{i=1}^m \\lambda_i g_i(x) + \\frac{\\rho}{2} \\sum_{i=1}^m g_i(x)^2$, Projected gradient is an iterative algorithm for solving constrained optimization problems by projecting the updated solution back onto the feasible set at each iteration after applying a gradient step. Click to expand 📊 Quants ⭐⭐⭐⭐ Used in portfolio optimization, risk management, and solving constrained optimization problems in finance. 🤖 AI Researchers Applied in constrained learning algorithms and support vector machines. 📈 Data Scientists Important for understanding constrained optimization problems and their solutions. Tags: projected gradient, constrained optimization, projection Projected gradient: $x^{(k+1)} = \\mathcal{P}_{\\mathcal{X}}(x^{(k)} - \\alpha_k \\nabla f(x^{(k)}))$, The Time Value of money acknowledges that a dollar received today is worth more than a dollar received in the future due to its potential to earn interest. This concept helps evaluate the profitability of projects, and quantitatively assess the benefits and risks of different investment opportunities, leading to more informed financial decisions. Time Value Click to expand The Time Value of money acknowledges that a dollar received today is worth more than a dollar received in the future due to its potential to earn interest. This concept helps evaluate the profitability of projects, and quantitatively assess the benefits and risks of different investment opportunities, leading to more informed financial decisions. Compound interest formula calculates the total amount after a given time period, considering both principal and interest. Click to expand 📊 Quants Useful for estimating investment returns in quant finance, especially for fixed-income securities. 🤖 AI Researchers Not directly related to AI research but useful for understanding financial concepts. 📈 Data Scientists Commonly asked concept in finance-related data science interviews to assess understanding of time value of money. Tags: compound interest, time value of money, investment Compound interest: $A = P(1 + \\frac{r}{n})^{nt}$ Continuous compounding formula calculates the total amount after a given time period, assuming continuous interest compounding. Click to expand 📊 Quants Used in option pricing and other areas of quant finance where continuous compounding is assumed. 🤖 AI Researchers Limited use in AI research, mostly relevant for financial applications. 📈 Data Scientists Important concept for data scientists working with finance-related data or models, such as option pricing. Tags: continuous compounding, exponential growth, interest Continuous compounding: $A = Pe^{rt}$ Present value formula calculates the current worth of a future sum of money or cash flow, discounted by an interest rate. Click to expand 📊 Quants Essential concept for valuing cash flows and assets in quantitative finance research. 🤖 AI Researchers Not directly related to AI research but useful for understanding financial concepts. 📈 Data Scientists Commonly asked in data science interviews to assess understanding of discounting and valuation techniques. Tags: present value, discounting, time value of money Present value: $PV = \\frac{FV}{(1 + r)^n}$ Future value formula calculates the value of an investment at a specified date in the future, considering an interest rate. Click to expand 📊 Quants Used in quant finance for projecting investment returns and valuing assets. 🤖 AI Researchers Not directly related to AI research but useful for understanding financial concepts. 📈 Data Scientists Important concept in finance-related data science interviews to assess understanding of time value of money and valuation techniques. Tags: future value, investment, time value of money Future value: $FV = PV(1 + r)^n$ Simple interest formula calculates the interest earned on a principal amount over a specified time period at a given rate. Click to expand 📊 Quants Used in basic quant finance calculations where only simple interest is considered. 🤖 AI Researchers Limited use in AI research, mostly relevant for basic financial applications. 📈 Data Scientists May be asked in entry-level data science interviews to assess understanding of basic financial concepts. Tags: simple interest, principal, time value of money Simple interest: $I = Prt$ Annuity formula calculates the present value of a series of equal payments made at regular intervals, discounted by an interest rate. Click to expand 📊 Quants Used in quant finance for valuing bond payments, mortgages, and other cash flow streams with fixed periodic payments. 🤖 AI Researchers Not directly related to AI research but useful for understanding cash flow valuation concepts. 📈 Data Scientists Important concept in finance-related data science interviews to assess understanding of annuities and cash flow valuation techniques. Tags: annuity, present value, cash flow Annuity formula: $PV = \\frac{PMT}{r}(1 - (1 + r)^{-n})$ Perpetuity formula calculates the present value of an infinite series of equal payments made at regular intervals, discounted by an interest rate. Click to expand 📊 Quants Used in quant finance for valuing certain types of bonds and preferred stocks with perpetual cash flows. 🤖 AI Researchers Limited use in AI research, mostly relevant for financial applications involving valuation of perpetual cash flows. 📈 Data Scientists May be asked in finance-related data science interviews to assess understanding of perpetuities and cash flow valuation techniques. Tags: perpetuity, present value, infinite cash flow Perpetuity formula: $PV = \\frac{PMT}{r}$ Options pricing models and formulas used to estimate the fair value of options contracts. Options Click to expand Options pricing models and formulas used to estimate the fair value of options contracts. Black model is an option pricing model for futures options that uses a log-normal distribution assumption. Click to expand 📊 Quants Used in quant finance for pricing European options on futures contracts, especially interest rate futures. 🤖 AI Researchers Not directly related to AI research but useful for understanding option pricing models in finance applications. 📈 Data Scientists Important concept for data scientists working with derivatives pricing or risk management models. Tags: Black model, futures options, option pricing Black model: $C(F, K, T, r, \\sigma) = e^{-rT}[FN(d_1) - KN(d_2)]$ Real options valuation is a method for valuing investments with embedded real options by adapting option pricing models to account for uncertainty and flexibility. Click to expand 📊 Quants Used in quant finance for valuing investments with embedded real options such as natural resources projects or R\u0026amp;D investments. 🤖 AI Researchers Relevant for AI research when incorporating uncertainty and flexibility into decision-making processes or project valuations. 📈 Data Scientists May be asked in advanced data science interviews focused on finance or decision-making under uncertainty. Tags: real options valuation, investment valuation, flexibility Real options valuation: $\\text{ROV} = f(S, K, T, r, \\sigma, q)$ Black-Scholes-Merton model is an option pricing model for European options on stocks that pays dividends and uses a log-normal distribution assumption. Click to expand 📊 Quants Widely used in quant finance for pricing European options on dividend-paying stocks and as a basis for other option pricing models. 🤖 AI Researchers Relevant for AI research when incorporating financial option pricing models into decision-making or optimization algorithms. 📈 Data Scientists Commonly asked concept in finance-related data science interviews to assess understanding of option pricing and derivatives. Tags: Black-Scholes-Merton, option pricing, dividends Black-Scholes-Merton: $C(S, K, T, r, \\sigma, q) = Se^{-qT}N(d_1) - Ke^{-rT}N(d_2)$ Black-Scholes-Merton put formula calculates the fair value of a European put option on a stock that pays dividends using the Black-Scholes-Merton model. Click to expand 📊 Quants Used in quant finance for pricing European put options on dividend-paying stocks and as a basis for other put option pricing models. 🤖 AI Researchers Not directly related to AI research but useful for understanding put option pricing models in finance applications. 📈 Data Scientists Important concept for data scientists working with derivatives pricing or risk management models focused on put options. Tags: Black-Scholes-Merton put, put option pricing, dividends Black-Scholes-Merton put: $P(S, K, T, r, \\sigma, q) = Ke^{-rT}N(-d_2) - Se^{-qT}N(-d_1)$ Black-Scholes formula calculates the fair value of a European call option on a stock using the Black-Scholes model, assuming no dividends. Click to expand 📊 Quants Widely used in quant finance for pricing European options on non-dividend-paying stocks and as a basis for other option pricing models. 🤖 AI Researchers Relevant for AI research when incorporating financial option pricing models into decision-making or optimization algorithms. 📈 Data Scientists Commonly asked concept in finance-related data science interviews to assess understanding of option pricing and derivatives. Tags: Black-Scholes, call option pricing, no dividends Black-Scholes formula: $C(S, t) = SN(d_1) - Ke^{-r(T-t)}N(d_2)$ Black-Scholes model calculates the fair value of a European call option on a stock using the Black-Scholes model, assuming no dividends. Click to expand 📊 Quants Widely used in quant finance for pricing European options on non-dividend-paying stocks and as a basis for other option pricing models. 🤖 AI Researchers Relevant for AI research when incorporating financial option pricing models into decision-making or optimization algorithms. 📈 Data Scientists Commonly asked concept in finance-related data science interviews to assess understanding of option pricing and derivatives. Tags: Black-Scholes, call option pricing, no dividends Black-Scholes: $C(S, K, T, r, \\sigma) = SN(d_1) - Ke^{-rT}N(d_2)$ Black-Scholes put formula calculates the fair value of a European put option on a stock using the Black-Scholes model, assuming no dividends. Click to expand 📊 Quants Used in quant finance for pricing European put options on non-dividend-paying stocks and as a basis for other put option pricing models. 🤖 AI Researchers Not directly related to AI research but useful for understanding put option pricing models in finance applications. 📈 Data Scientists Important concept for data scientists working with derivatives pricing or risk management models focused on put options. Tags: Black-Scholes put, put option pricing, no dividends Black-Scholes put: $P(S, K, T, r, \\sigma) = Ke^{-rT}N(-d_2) - SN(-d_1)$ d_1 is a component of the Black-Scholes option pricing model, which represents the expected return on the option. Click to expand 📊 Quants Used in quant finance as part of the Black-Scholes model for pricing European options on stocks. 🤖 AI Researchers Not directly related to AI research but useful for understanding option pricing models in finance applications. 📈 Data Scientists Important component of the Black-Scholes model, often discussed in finance-related data science interviews. Tags: d_1, Black-Scholes, option pricing $d_1$: $d_1 = \\frac{1}{\\sigma \\sqrt{T}}\\left[\\ln\\left(\\frac{S}{K}\\right) + \\left(r + \\frac{\\sigma^2}{2}\\right)T\\right]$ d_2 is another component of the Black-Scholes option pricing model, representing the risk-adjusted probability that the option will be exercised. Click to expand 📊 Quants Used in quant finance as part of the Black-Scholes model for pricing European options on stocks. 🤖 AI Researchers Not directly related to AI research but useful for understanding option pricing models in finance applications. 📈 Data Scientists Important component of the Black-Scholes model, often discussed in finance-related data science interviews. Tags: d_2, Black-Scholes, option pricing $d_2$: $d_2 = d_1 - \\sigma \\sqrt{T}$ Greeks\nCall rho measures the sensitivity of a call option\u0026#39;s price to changes in interest rates. Click to expand 📊 Quants Used in quant finance for managing interest rate risk and understanding how call options are affected by interest rate changes. 🤖 AI Researchers Limited use in AI research, mostly relevant for financial applications involving options and interest rates. 📈 Data Scientists May be asked in finance-related data science interviews to assess understanding of option Greeks and interest rate risk. Tags: call rho, option Greeks, interest rate risk Call rho: $\\rho_C = KTe^{-rT}N(d_2)$ Put rho measures the sensitivity of a put option\u0026#39;s price to changes in interest rates. Click to expand 📊 Quants Used in quant finance for managing interest rate risk and understanding how put options are affected by interest rate changes. 🤖 AI Researchers Limited use in AI research, mostly relevant for financial applications involving options and interest rates. 📈 Data Scientists May be asked in finance-related data science interviews to assess understanding of option Greeks and interest rate risk. Tags: put rho, option Greeks, interest rate risk Put rho: $\\rho_P = -KTe^{-rT}N(-d_2)$ Put-call parity is a fundamental principle relating the prices of European call options and put options with the same strike price and expiration date. Click to expand 📊 Quants Essential concept in quant finance for understanding the relationship between call and put options, used for arbitrage strategies and option pricing consistency checks. 🤖 AI Researchers Not directly related to AI research but useful for understanding financial concepts related to options pricing models. 📈 Data Scientists Commonly asked concept in finance-related data science interviews to assess understanding of options pricing relationships. Tags: put-call parity, arbitrage, options pricing Put-call parity: $C - P = S - Ke^{-rT}$ Binomial option pricing model calculates the fair value of an option using a discrete-time binomial tree approach, modeling the possible future stock prices over time. Click to expand 📊 Quants Widely used in quant finance for pricing American options and as an alternative to the Black-Scholes model. 🤖 AI Researchers Relevant for AI research when incorporating financial option pricing models into decision-making or optimization algorithms. 📈 Data Scientists Important concept in finance-related data science interviews to assess understanding of alternative option pricing models. Tags: binomial option pricing, American options, discrete-time Binomial option pricing: $C_n = \\frac{1}{(1+r)^n} \\sum_{i=0}^n \\binom{n}{i} p^i (1-p)^{n-i} \\max(S(1+u)^i(1+d)^{n-i} - K, 0)$ Risk-neutral probability is the probability measure used in the binomial option pricing model to value options under the assumption of risk neutrality. Click to expand 📊 Quants Used in quant finance as part of the binomial option pricing model for valuing options under risk-neutral assumptions. 🤖 AI Researchers Not directly related to AI research but useful for understanding risk-neutral valuation concepts in finance applications. 📈 Data Scientists May be asked in finance-related data science interviews to assess understanding of risk-neutral valuation and binomial option pricing model. Tags: risk-neutral probability, binomial option pricing, risk neutrality Risk-neutral probability: $p = \\frac{1+r-d}{u-d}$ Implied volatility is the volatility implied by the market price of an option, calculated using an option pricing model such as Black-Scholes. Click to expand 📊 Quants Crucial concept in quant finance for understanding market expectations of future volatility and used for trading strategies based on volatility forecasts. 🤖 AI Researchers Relevant for AI research when incorporating financial market expectations into decision-making or optimization algorithms. 📈 Data Scientists Commonly asked concept in finance-related data science interviews to assess understanding of volatility and options pricing. Tags: implied volatility, option pricing, market expectations Implied volatility: $\\sigma_{\\text{implied}} = \\text{IV}(C, S, K, T, r)$ Option elasticity measures the sensitivity of an option\u0026#39;s price to changes in the underlying stock price, also known as the option\u0026#39;s leverage. Click to expand 📊 Quants Used in quant finance for understanding how much an option\u0026#39;s price will change relative to the underlying stock price and for managing risk exposure. 🤖 AI Researchers Limited use in AI research, mostly relevant for financial applications involving options and leverage. 📈 Data Scientists May be asked in finance-related data science interviews to assess understanding of option Greeks and risk management. Tags: option elasticity, leverage, risk exposure Option elasticity: $\\text{Elasticity} = \\frac{\\Delta_C \\cdot S}{C}$ Put-call ratio is a market sentiment indicator that compares the trading volume of put options to call options. Click to expand 📊 Quants Used in quant finance for gauging market sentiment and as a contrarian indicator for trading strategies. 🤖 AI Researchers Not directly related to AI research but useful for understanding market sentiment indicators in finance applications. 📈 Data Scientists May be asked in finance-related data science interviews to assess understanding of market sentiment indicators and options trading activity. Tags: put-call ratio, market sentiment, contrarian indicator Put-call ratio: $\\text{PCR} = \\frac{\\text{Volume}_\\text{Put}}{\\text{Volume}_\\text{Call}}$ Moneyness is a measure of how far an option is in or out of the money, calculated as the ratio of the underlying stock price to the option\u0026#39;s strike price. Click to expand 📊 Quants Used in quant finance for understanding option pricing and risk management, as well as for selecting appropriate options for trading strategies. 🤖 AI Researchers Limited use in AI research, mostly relevant for financial applications involving options pricing and risk management. 📈 Data Scientists May be asked in finance-related data science interviews to assess understanding of option moneyness and its impact on option pricing. Tags: moneyness, in-the-money, out-of-the-money Moneyness: $\\text{Moneyness} = \\frac{S}{K}$ Greeks neutralization is a risk management technique that involves offsetting the risk exposure of an options position by adjusting the position\u0026#39;s Greeks to zero or near-zero values. Click to expand 📊 Quants Used in quant finance for managing risk exposure in options trading and constructing delta-neutral, gamma-neutral, or other Greeks-neutral portfolios. 🤖 AI Researchers Not directly related to AI research but useful for understanding risk management techniques in finance applications involving options. 📈 Data Scientists May be asked in finance-related data science interviews to assess understanding of option Greeks and risk management techniques. Tags: Greeks neutralization, risk management, delta-neutral Greeks neutralization: $\\text{Neutralize} = -\\sum \\text{Greeks}$ Call delta measures the sensitivity of a call option\u0026#39;s price to changes in the underlying stock price. Click to expand 📊 Quants Used in quant finance for managing delta risk and understanding how call options are affected by stock price changes. 🤖 AI Researchers Not directly related to AI research but useful for understanding option pricing models and their sensitivities in finance applications. 📈 Data Scientists Important concept for data scientists working with derivatives pricing or risk management models focused on call options. Tags: call delta, option Greeks, delta risk Call delta: $\\Delta_C = N(d_1)$ Put delta represents the rate of change of a put option\u0026#39;s price with respect to the underlying asset\u0026#39;s price. It is useful for hedging and managing risk in options trading. Click to expand 📊 Quants ⭐⭐⭐⭐ Put delta is important in quantitative finance research for option pricing, risk management, and portfolio optimization. 🤖 AI Researchers ⭐⭐ Put delta is not directly related to AI research, but it could be used in financial applications within AI systems. 📈 Data Scientists Put delta may appear in data science interviews focused on finance, as it demonstrates understanding of options pricing and risk management. Tags: put delta, options trading, risk management Put delta: $\\Delta_P = -N(-d_1)$, Call gamma measures the rate of change of an option\u0026#39;s delta with respect to the underlying asset\u0026#39;s price. It helps traders manage risk and adjust their positions accordingly. Click to expand 📊 Quants ⭐⭐⭐⭐ Call gamma is crucial for understanding option greeks, which are essential for option pricing models and risk management in quantitative finance research. 🤖 AI Researchers ⭐⭐ Call gamma is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Call gamma may appear in data science interviews focused on finance, as it demonstrates understanding of options pricing and risk management. Tags: call gamma, option greeks, risk management Call gamma: $\\Gamma_C = \\frac{N'(d_1)}{S\\sigma\\sqrt{T}}$, Put gamma is equal to call gamma and represents the sensitivity of an option\u0026#39;s delta to changes in the underlying asset\u0026#39;s price. It is essential for managing risk in options trading. Click to expand 📊 Quants ⭐⭐⭐⭐ Put gamma is important for understanding option greeks, which are critical for option pricing models and risk management in quantitative finance research. 🤖 AI Researchers ⭐⭐ Put gamma is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Put gamma may appear in data science interviews focused on finance, as it demonstrates understanding of options pricing and risk management. Tags: put gamma, option greeks, risk management Put gamma: $\\Gamma_P = \\Gamma_C$, Call theta measures the rate of change of a call option\u0026#39;s price with respect to time. It is important for understanding time decay in options trading and managing risk. Click to expand 📊 Quants ⭐⭐⭐⭐ Call theta is crucial for understanding option greeks, which are essential for option pricing models and risk management in quantitative finance research. 🤖 AI Researchers ⭐⭐ Call theta is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Call theta may appear in data science interviews focused on finance, as it demonstrates understanding of options pricing and risk management. Tags: call theta, time decay, options trading Call theta: $\\Theta_C = -\\frac{S\\sigma N'(d_1)}{2\\sqrt{T}} - rKe^{-rT}N(d_2)$, Put theta measures the rate of change of a put option\u0026#39;s price with respect to time. It is important for understanding time decay in options trading and managing risk. Click to expand 📊 Quants ⭐⭐⭐⭐ Put theta is crucial for understanding option greeks, which are essential for option pricing models and risk management in quantitative finance research. 🤖 AI Researchers ⭐⭐ Put theta is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Put theta may appear in data science interviews focused on finance, as it demonstrates understanding of options pricing and risk management. Tags: put theta, time decay, options trading Put theta: $\\Theta_P = -\\frac{S\\sigma N'(-d_1)}{2\\sqrt{T}} + rKe^{-rT}N(-d_2)$, Call vega represents the sensitivity of an option\u0026#39;s price to changes in the underlying asset\u0026#39;s volatility. It is important for managing risk and adjusting positions in options trading. Click to expand 📊 Quants ⭐⭐⭐⭐ Call vega is crucial for understanding option greeks, which are essential for option pricing models and risk management in quantitative finance research. 🤖 AI Researchers ⭐⭐ Call vega is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Call vega may appear in data science interviews focused on finance, as it demonstrates understanding of options pricing and risk management. Tags: call vega, option greeks, volatility Call vega: $V_C = S\\sqrt{T} N'(d_1)$, Put vega is equal to call vega and represents the sensitivity of an option\u0026#39;s price to changes in the underlying asset\u0026#39;s volatility. It is important for managing risk and adjusting positions in options trading. Click to expand 📊 Quants ⭐⭐⭐⭐ Put vega is crucial for understanding option greeks, which are essential for option pricing models and risk management in quantitative finance research. 🤖 AI Researchers ⭐⭐ Put vega is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Put vega may appear in data science interviews focused on finance, as it demonstrates understanding of options pricing and risk management. Tags: put vega, option greeks, volatility Put vega: $V_P = V_C$, Risk Measures help identify and quantify the potential upsides and downsides of investments. By understanding the balance between risk and reward, investors can make informed decisions on which investments suit their risk tolerance and goals. These measures allow for better asset allocation and risk management, ultimately improving the overall performance of a portfolio. Risk Measures Click to expand Risk Measures help identify and quantify the potential upsides and downsides of investments. By understanding the balance between risk and reward, investors can make informed decisions on which investments suit their risk tolerance and goals. These measures allow for better asset allocation and risk management, ultimately improving the overall performance of a portfolio. The GARCH model estimates the volatility of financial assets and is useful for risk management, portfolio optimization, and option pricing. Click to expand 📊 Quants GARCH models are widely used in quantitative finance research for modeling time-varying volatility and managing risk in financial markets. 🤖 AI Researchers ⭐⭐⭐⭐ GARCH models can be used in AI research for time series analysis and prediction in finance-related applications. 📈 Data Scientists GARCH models may be discussed in data science interviews, as they demonstrate understanding of time series analysis and volatility modeling. Tags: GARCH, volatility, time series GARCH model: $\\sigma_t^2 = \\omega + \\alpha \\varepsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2$, The risk-adjusted return measures the excess return per unit of risk taken by an investor. It is useful for comparing investment opportunities with different levels of risk. Click to expand 📊 Quants Risk-adjusted return is important in quantitative finance research for portfolio optimization, performance evaluation, and asset allocation. 🤖 AI Researchers ⭐⭐⭐ Risk-adjusted return is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Risk-adjusted return may appear in data science interviews focused on finance, as it demonstrates understanding of performance measurement and risk management. Tags: risk-adjusted return, performance evaluation, portfolio optimization Risk-adjusted return: $\\text{RAR} = \\frac{\\text{Return} - r_f}{\\text{Volatility}}$, The Sharpe ratio measures the excess return per unit of risk (standard deviation) taken by an investor. It is widely used for comparing investment opportunities and evaluating portfolio performance. Click to expand 📊 Quants The Sharpe ratio is a key performance measure in quantitative finance research for portfolio optimization, risk management, and asset allocation. 🤖 AI Researchers ⭐⭐⭐ The Sharpe ratio is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists The Sharpe ratio may appear in data science interviews focused on finance, as it demonstrates understanding of performance measurement and risk management. Tags: Sharpe ratio, performance evaluation, portfolio optimization Sharpe ratio: $\\text{Sharpe} = \\frac{\\text{Return} - r_f}{\\text{StandardDeviation}}$, The Sortino ratio measures the excess return per unit of downside risk (downside deviation). It is useful for comparing investment opportunities with different levels of downside risk. Click to expand 📊 Quants The Sortino ratio is important in quantitative finance research for portfolio optimization, risk management, and asset allocation with a focus on downside risk. 🤖 AI Researchers ⭐⭐⭐ The Sortino ratio is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists The Sortino ratio may appear in data science interviews focused on finance, as it demonstrates understanding of performance measurement and downside risk management. Tags: Sortino ratio, downside risk, performance evaluation Sortino ratio: $\\text{Sortino} = \\frac{\\text{Return} - r_f}{\\text{DownsideDeviation}}$, The Treynor ratio measures the excess return per unit of systematic risk (beta) taken by an investor. It is useful for comparing investment opportunities with different levels of systematic risk. Click to expand 📊 Quants The Treynor ratio is important in quantitative finance research for portfolio optimization, performance evaluation, and asset allocation with a focus on systematic risk. 🤖 AI Researchers ⭐⭐⭐ The Treynor ratio is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists The Treynor ratio may appear in data science interviews focused on finance, as it demonstrates understanding of performance measurement and systematic risk management. Tags: Treynor ratio, systematic risk, performance evaluation Treynor ratio: $\\text{Treynor} = \\frac{\\text{Return} - r_f}{\\text{Beta}}$, The Information ratio measures the excess return of a portfolio relative to its benchmark, adjusted for tracking error. It helps evaluate the skill of active managers and compare investment strategies. Click to expand 📊 Quants Information ratio is important in quantitative finance research for evaluating active management strategies and comparing performance across different investment styles. 🤖 AI Researchers ⭐⭐⭐ Information ratio is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Information ratio may appear in data science interviews focused on finance, as it demonstrates understanding of performance measurement and active management evaluation. Tags: information ratio, active management, tracking error Information ratio: $\\text{IR} = \\frac{\\text{Return} - \\text{Benchmark}}{\\text{TrackingError}}$, Jensen\u0026#39;s alpha measures the abnormal return of a portfolio or security relative to its expected return based on CAPM. It helps evaluate the skill of active managers and identify outperforming investments. Click to expand 📊 Quants Jensen\u0026#39;s alpha is important in quantitative finance research for evaluating active management strategies and identifying securities with superior risk-adjusted performance. 🤖 AI Researchers ⭐⭐⭐ Jensen\u0026#39;s alpha is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Jensen\u0026#39;s alpha may appear in data science interviews focused on finance, as it demonstrates understanding of performance measurement and active management evaluation. Tags: Jensen\u0026#39;s alpha, abnormal return, CAPM Jensen's alpha: $\\text{Alpha} = \\text{Return} - [r_f + \\beta (\\text{MarketReturn} - r_f)]$, Portfolio Management concepts allow investors to understand how diversification reduces risk, and how different assets interact within a portfolio. By applying these concepts, investors can optimize their portfolios to achieve the best possible return for a given level of risk, leading to more efficient capital allocation and improved long-term financial performance. Portfolio Management Click to expand Portfolio Management concepts allow investors to understand how diversification reduces risk, and how different assets interact within a portfolio. By applying these concepts, investors can optimize their portfolios to achieve the best possible return for a given level of risk, leading to more efficient capital allocation and improved long-term financial performance. The CAPM formula estimates the expected return of an asset based on its beta and the expected market return. It is widely used for portfolio management, asset pricing, and risk management. Click to expand 📊 Quants CAPM is a fundamental model in quantitative finance research for estimating asset returns, assessing risk, and optimizing portfolios. 🤖 AI Researchers ⭐⭐⭐⭐ CAPM can be used in AI research for finance-related applications such as portfolio optimization and risk assessment. 📈 Data Scientists CAPM may appear in data science interviews focused on finance, as it demonstrates understanding of asset pricing theory and risk management. Tags: CAPM, expected return, beta CAPM formula: $E(R_i) = R_f + \\beta_i(E(R_m) - R_f)$, The Sharpe ratio measures the excess return per unit of risk (standard deviation) taken by an investor. It is widely used for comparing investment opportunities and evaluating portfolio performance. Click to expand 📊 Quants The Sharpe ratio is a key performance measure in quantitative finance research for portfolio optimization, risk management, and asset allocation. 🤖 AI Researchers ⭐⭐⭐ The Sharpe ratio is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists The Sharpe ratio may appear in data science interviews focused on finance, as it demonstrates understanding of performance measurement and risk management. Tags: Sharpe ratio, performance evaluation, portfolio optimization Sharpe ratio: $\\frac{E(R_p) - R_f}{\\sigma_p}$, The covariance of assets formula calculates the beta of an asset, which measures its sensitivity to market movements. It is important for understanding systematic risk and asset pricing. Click to expand 📊 Quants Covariance of assets is crucial in quantitative finance research for estimating systematic risk, asset pricing, and portfolio optimization. 🤖 AI Researchers ⭐⭐⭐ Covariance of assets is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Covariance of assets may appear in data science interviews focused on finance, as it demonstrates understanding of systematic risk and asset pricing theory. Tags: covariance of assets, beta, systematic risk Covariance of assets: $\\beta_i = \\frac{\\text{Cov}(R_i, R_m)}{\\text{Var}(R_m)}$, The efficient frontier represents the set of portfolios with the highest expected return for a given level of risk. It is essential for portfolio optimization and asset allocation decisions. Click to expand 📊 Quants The efficient frontier is a key concept in quantitative finance research for constructing optimal portfolios and making asset allocation decisions. 🤖 AI Researchers ⭐⭐⭐⭐ The efficient frontier can be used in AI research for finance-related applications such as portfolio optimization and risk assessment. 📈 Data Scientists The efficient frontier may appear in data science interviews focused on finance, as it demonstrates understanding of portfolio theory and risk management. Tags: efficient frontier, portfolio optimization, asset allocation Efficient frontier: $\\sigma_p = \\sqrt{w_1^2\\sigma_1^2 + w_2^2\\sigma_2^2 + 2w_1w_2\\rho_{12}\\sigma_1\\sigma_2}$, The Markowitz portfolio formula calculates the optimal weights for assets in a portfolio to maximize expected return for a given level of risk. It is fundamental for modern portfolio theory and asset allocation. Click to expand 📊 Quants Markowitz portfolio is a cornerstone of quantitative finance research for constructing optimal portfolios and making asset allocation decisions based on risk-return tradeoffs. 🤖 AI Researchers ⭐⭐⭐⭐ Markowitz portfolio can be used in AI research for finance-related applications such as portfolio optimization and risk assessment. 📈 Data Scientists Markowitz portfolio may appear in data science interviews focused on finance, as it demonstrates understanding of modern portfolio theory and asset allocation strategies. Tags: Markowitz portfolio, optimal weights, modern portfolio theory Markowitz portfolio: $w_i = \\sum_{j=1}^n \\frac{C_{ij}^{-1}(R_j - R_f)}{\\sum_{j=1}^n \\sum_{k=1}^n C_{jk}^{-1}(R_j - R_f)(R_k - R_f)}$, The covariance matrix represents the variances and covariances between assets in a portfolio. It is important for understanding the risk and diversification effects within a portfolio. Click to expand 📊 Quants Covariance matrix is crucial in quantitative finance research for estimating risk, evaluating diversification, and optimizing portfolios. 🤖 AI Researchers ⭐⭐⭐⭐ Covariance matrix can be used in AI research for finance-related applications such as portfolio optimization and risk assessment. 📈 Data Scientists Covariance matrix may appear in data science interviews focused on finance, as it demonstrates understanding of risk management and diversification benefits. Tags: covariance matrix, portfolio risk, diversification Covariance matrix: $\\Sigma = \\begin{bmatrix} \\sigma_1^2 \u0026 \\rho_{12}\\sigma_1\\sigma_2 \\\\ \\rho_{12}\\sigma_1\\sigma_2 \u0026 \\sigma_2^2 \\end{bmatrix}$, The Gordon growth model estimates the value of a stock based on its expected future dividends, assuming a constant growth rate. It is useful for stock valuation and investment decisions. Click to expand 📊 Quants Gordon growth model is important in quantitative finance research for estimating intrinsic stock values and making investment decisions based on dividend growth assumptions. 🤖 AI Researchers ⭐⭐⭐ Gordon growth model is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Gordon growth model may appear in data science interviews focused on finance, as it demonstrates understanding of stock valuation and dividend discount models. Tags: Gordon growth model, stock valuation, dividend discount Gordon growth model: $P_0 = \\frac{D_1}{r - g}$, Corporate Finance\nOther\nThe dividend discount model estimates the value of a stock based on the present value of its expected future dividends. It is useful for stock valuation and investment decisions. Click to expand 📊 Quants Dividend discount model is important in quantitative finance research for estimating intrinsic stock values and making investment decisions based on dividend expectations. 🤖 AI Researchers ⭐⭐⭐ Dividend discount model is not directly related to AI research but can be used in financial applications within AI systems. 📈 Data Scientists Dividend discount model may appear in data science interviews focused on finance, as it demonstrates understanding of stock valuation and present value concepts. Tags: dividend discount model, stock valuation, present value Dividend discount model: $P_0 = \\sum_{t=1}^{\\infty} \\frac{D_t}{(1 + r)^t}$, IRR computes the discount rate at which NPV equals zero. Click to expand 📊 Quants IRR is used to evaluate project profitability and to compare different investments in quant finance. 🤖 AI Researchers Although IRR is not directly related to AI research, it can be used in financial modeling within AI applications. 📈 Data Scientists IRR is a fundamental concept in finance and may be asked in data science interviews focused on finance domain knowledge. Tags: IRR, Internal Rate of Return, NPV, Net Present Value IRR formula: $NPV = \\sum_{t=0}^n \\frac{CF_t}{(1 + IRR)^t} = 0$, NPV calculates the present value of cash flows discounted at a given rate r. Click to expand 📊 Quants NPV is crucial for investment analysis and project valuation in quant finance research. 🤖 AI Researchers While not directly related to AI research, NPV can be used in financial modeling within AI applications. 📈 Data Scientists Understanding NPV is important for data scientists working in finance, as it\u0026#39;s a key metric for project valuation. Tags: NPV, Net Present Value, cash flows, discount rate NPV formula: $NPV = \\sum_{t=0}^n \\frac{CF_t}{(1 + r)^t}$, WACC calculates the weighted average cost of capital for a firm\u0026#39;s financing sources. Click to expand 📊 Quants WACC is essential in quant finance for determining a company\u0026#39;s cost of capital and evaluating investment decisions. 🤖 AI Researchers WACC is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with financial data should understand WACC as it\u0026#39;s a key metric for corporate finance analysis. Tags: WACC, Weighted Average Cost of Capital, finance WACC formula: $WACC = \\frac{E}{V}R_e + \\frac{D}{V}(1 - T_c)R_d$, Dividend payout ratio measures the proportion of net income paid out as dividends. Click to expand 📊 Quants Dividend payout ratio is useful in quant finance for analyzing a company\u0026#39;s dividend policy and its impact on stock prices. 🤖 AI Researchers It\u0026#39;s not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Dividend payout ratio may come up in data science interviews focused on finance domain knowledge. Tags: dividend payout ratio, dividends, net income Dividend payout ratio: $\\text{Payout Ratio} = \\frac{\\text{Dividends}}{\\text{Net Income}}$, Retention ratio calculates the proportion of net income retained by a company for reinvestment. Click to expand 📊 Quants Retention ratio is important in quant finance for understanding a company\u0026#39;s reinvestment strategy and its effect on stock prices. 🤖 AI Researchers Retention ratio is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Retention ratio may be asked in data science interviews focused on finance domain knowledge. Tags: retention ratio, reinvestment, net income Retention ratio: $\\text{Retention Ratio} = 1 - \\text{Payout Ratio}$, Merton\u0026#39;s model computes the distance to default for a firm using its asset value V, debt D, volatility σ_V, and time T. Click to expand 📊 Quants Merton\u0026#39;s model is widely used in quant finance for credit risk analysis and option pricing based on firm value. 🤖 AI Researchers Merton\u0026#39;s model can be applied in AI research for credit risk prediction and financial distress modeling. 📈 Data Scientists Data scientists working with credit risk may encounter Merton\u0026#39;s model in interviews or on the job. Tags: Merton\u0026#39;s model, distance to default, credit risk Merton's model: $\\text{DistanceToDefault} = \\frac{\\ln(\\frac{V}{D}) + (r + \\frac{\\sigma_V^2}{2})T}{\\sigma_V \\sqrt{T}}$, Risk-neutral density represents an asset\u0026#39;s probability distribution under risk-neutral pricing. Click to expand 📊 Quants Risk-neutral density is crucial for option pricing and hedging strategies in quant finance research. 🤖 AI Researchers Risk-neutral density can be used in AI research for option pricing and financial risk management applications. 📈 Data Scientists Data scientists working with derivative pricing may encounter risk-neutral density in interviews or on the job. Tags: risk-neutral density, option pricing, derivatives Risk-neutral density: $f^*(S_T) = \\frac{e^{rT}}{C'(S_T)}$, Bond Pricing and Duration Bond Pricing and Duration Click to expand Bond Pricing and Duration Effective duration measures bond price sensitivity to changes in yield, using the bond\u0026#39;s present value (V) and yield change (∆y). Click to expand 📊 Quants Effective duration is important in quant finance for managing interest rate risk and bond portfolio optimization. 🤖 AI Researchers Effective duration is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand effective duration as it helps assess interest rate risk. Tags: effective duration, bond price sensitivity, interest rate risk Effective duration: $\\text{Duration} = \\frac{V_+ - V_-}{2V \\Delta y}$, Effective convexity measures the curvature of the bond price-yield relationship, using the bond\u0026#39;s present value (V) and yield change (∆y). Click to expand 📊 Quants Effective convexity is important in quant finance for managing interest rate risk and bond portfolio optimization. 🤖 AI Researchers Effective convexity is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand effective convexity as it helps assess interest rate risk. Tags: effective convexity, bond price curvature, interest rate risk Effective convexity: $\\text{Convexity} = \\frac{V_+ + V_- - 2V}{V (\\Delta y)^2}$, Modified duration adjusts Macaulay duration for changes in yield to maturity (YTM) and compounding frequency (m). Click to expand 📊 Quants Modified duration is important in quant finance for managing interest rate risk and bond portfolio optimization. 🤖 AI Researchers Modified duration is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand modified duration as it helps assess interest rate risk. Tags: modified duration, Macaulay duration, yield to maturity Modified duration: $\\text{ModDuration} = \\frac{1}{1 + \\frac{YTM}{m}} \\cdot \\text{Duration}$, Macaulay duration calculates the weighted average time to receive a bond\u0026#39;s cash flows, using the present value of cash flows (PVCF) and bond value (V). Click to expand 📊 Quants Macaulay duration is important in quant finance for managing interest rate risk and bond portfolio optimization. 🤖 AI Researchers Macaulay duration is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand Macaulay duration as it helps assess interest rate risk. Tags: Macaulay duration, bond cash flows, interest rate risk Macaulay duration: $\\text{MacDuration} = \\frac{\\sum^n_{i=1} t_i PVCF_i}{V}$, DV01 measures a bond\u0026#39;s price change for a 1 basis point change in yield. Click to expand 📊 Quants DV01 is important in quant finance for managing interest rate risk and bond portfolio optimization. 🤖 AI Researchers DV01 is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand DV01 as it helps assess interest rate risk. Tags: DV01, basis point value, interest rate risk DV01: $\\text{DV01} = \\frac{\\Delta V}{\\Delta y}$, Convexity adjustment accounts for the curvature of the bond price-yield relationship when estimating price changes due to yield changes. Click to expand 📊 Quants Convexity adjustment is important in quant finance for managing interest rate risk and bond portfolio optimization. 🤖 AI Researchers Convexity adjustment is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand convexity adjustment as it helps assess interest rate risk. Tags: convexity adjustment, bond price curvature, interest rate risk Convexity adjustment: $\\text{ConvexityAdj} = \\frac{1}{2} \\cdot \\text{Convexity} \\cdot (\\Delta y)^2$, Bond pricing calculates the present value of a bond\u0026#39;s cash flows (CF) discounted at its yield to maturity (YTM). Click to expand 📊 Quants Bond pricing is crucial in quant finance for valuing bonds and managing fixed income portfolios. 🤖 AI Researchers Bond pricing is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand bond pricing as it\u0026#39;s essential for valuing bonds and fixed income securities. Tags: bond pricing, cash flows, yield to maturity Yield to maturity: $YTM = f(V, CF, t)$, Fixed Income Fixed Income Click to expand Fixed Income Option adjusted spread (OAS) measures the spread between a security\u0026#39;s yield and the risk-free rate, adjusted for embedded options. Click to expand 📊 Quants OAS is important in quant finance for comparing bonds with different embedded options and assessing relative value. 🤖 AI Researchers OAS is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand OAS as it helps assess relative value of bonds with embedded options. Tags: option adjusted spread, OAS, fixed income Option adjusted spread: $OAS = Z - q$, Z-spread measures the constant spread added to each point on the risk-free yield curve to match a bond\u0026#39;s present value with its market price. Click to expand 📊 Quants Z-spread is important in quant finance for comparing bonds with different credit risks and assessing relative value. 🤖 AI Researchers Z-spread is not directly related to AI research but can be used in financial modeling within AI applications. 📈 Data Scientists Data scientists working with fixed income data should understand Z-spread as it helps assess relative value of bonds with different credit risks. Tags: Z-spread, spread, fixed income Z-spread: $Z = \\text{Spread}(\\text{YTM})$, Forward rate calculates the interest rate for a future period based on current spot rates (P(t1), P(t2)). Click to expand 📊 Quants Forward rates are crucial in quant finance for interest rate modeling, derivative pricing, and risk management. 🤖 AI Researchers Forward rates can be used in AI research for interest rate prediction and financial risk management applications. 📈 Data Scientists Data scientists working with fixed income data should understand forward rates as they play a key role in interest rate modeling and derivative pricing. Tags: forward rate, interest rate, fixed income Forward rate: $f(t_1, t_2) = \\frac{1}{t_2 - t_1} \\left[\\left(\\frac{P(t_1)}{P(t_2)}\\right)^{\\frac{1}{t_2 - t_1}} - 1\\right]$, Swap rate calculates the fixed rate exchanged for a floating rate in an interest rate swap, using the present value of cash flows (L) and discount factors (P). Click to expand 📊 Quants Swap rates are important in quant finance for valuing interest rate swaps and managing interest rate risk. 🤖 AI Researchers Swap rates can be used in AI research for interest rate prediction and financial risk management applications. 📈 Data Scientists Data scientists working with fixed income data should understand swap rates as they are essential for valuing interest rate swaps and managing interest rate risk. Tags: swap rate, interest rate swap, fixed income Swap rate: $S_t = \\frac{\\sum_{i=1}^n L(t_i) \\Delta t}{\\sum_{i=1}^n P(t_i) \\Delta t}$, Futures price calculates the price of a futures contract based on the underlying asset\u0026#39;s price (S), risk-free rate (r), dividend yield (q), and time to maturity (T-t). Click to expand 📊 Quants Futures pricing is crucial in quant finance for valuing futures contracts and managing derivatives portfolios. 🤖 AI Researchers Futures pricing can be used in AI research for derivative pricing and financial risk management applications. 📈 Data Scientists Data scientists working with derivatives data should understand futures pricing as it\u0026#39;s essential for valuing futures contracts and managing derivatives portfolios. Tags: futures price, derivatives, fixed income Futures price: $F_t = Se^{(r - q)(T - t)}$, Caplet pricing calculates the value of an interest rate caplet using the zero-coupon bond prices (B), strike rate (K), and standard normal cumulative distribution function (N). Click to expand 📊 Quants Caplet pricing is important in quant finance for valuing interest rate options and managing interest rate risk. 🤖 AI Researchers Caplet pricing can be used in AI research for derivative pricing and financial risk management applications. 📈 Data Scientists Data scientists working with fixed income data should understand caplet pricing as it is essential for valuing interest rate options. Tags: caplet pricing, interest rate options, fixed income Caplet pricing: $C_{\\text{caplet}} = B(0, T)N(d_1) - KB(0, T_1)N(d_2)$, Floorlet pricing calculates the value of an interest rate floorlet using the zero-coupon bond prices (B), strike rate (K), and standard normal cumulative distribution function (N). Click to expand 📊 Quants Floorlet pricing is important in quant finance for valuing interest rate options and managing interest rate risk. 🤖 AI Researchers Floorlet pricing can be used in AI research for derivative pricing and financial risk management applications. 📈 Data Scientists Data scientists working with fixed income data should understand floorlet pricing as it is essential for valuing interest rate options. Tags: floorlet pricing, interest rate options, fixed income Floorlet pricing: $C_{\\text{floorlet}} = KB(0, T_1)N(-d_2) - B(0, T)N(-d_1)$, Swaption pricing calculates the value of a swaption using the swap rate (S), strike rate (K), and standard normal cumulative distribution function (N). Click to expand 📊 Quants Swaption pricing is important in quant finance for valuing swaptions and managing interest rate risk. 🤖 AI Researchers Swaption pricing can be used in AI research for derivative pricing and financial risk management applications. 📈 Data Scientists Data scientists working with fixed income data should understand swaption pricing as it is essential for valuing swaptions. Tags: swaption pricing, swaptions, fixed income Swaption pricing: $C_{\\text{swaption}} = N(d_1) - (K / S)N(d_2)$, CDS pricing calculates the ratio of present value of protection payments to present value of premium payments in a credit default swap. Click to expand 📊 Quants CDS pricing is important in quant finance for valuing credit default swaps and managing credit risk. 🤖 AI Researchers CDS pricing can be used in AI research for credit risk prediction and financial risk management applications. 📈 Data Scientists Data scientists working with credit risk data should understand CDS pricing as it\u0026#39;s essential for valuing credit default swaps. Tags: CDS pricing, credit default swap, fixed income CDS pricing: $\\text{CDS} = \\frac{\\text{PV}_\\text{Protection}}{\\text{PV}_\\text{Premium}}$, Derivative Pricing Models Derivative Pricing Models Click to expand Derivative Pricing Models Cox-Ingersoll-Ross model is a mean-reverting short rate model with stochastic volatility. Click to expand 📊 Quants The CIR model is used in quant finance for interest rate modeling, derivative pricing, and risk management. 🤖 AI Researchers CIR model can be applied in AI research for interest rate prediction and financial risk management applications. 📈 Data Scientists Data scientists working with interest rates and derivatives should understand the CIR model as it\u0026#39;s widely used in fixed income markets. Tags: Cox-Ingersoll-Ross, CIR model, interest rate Cox-Ingersoll-Ross model: $dr_t = a(b - r_t)dt + \\sigma\\sqrt{r_t}dW_t$, Vasicek model is a mean-reverting short rate model with constant volatility. Click to expand 📊 Quants Vasicek model is used in quant finance for interest rate modeling, derivative pricing, and risk management. 🤖 AI Researchers Vasicek model can be applied in AI research for interest rate prediction but its constant volatility assumption limits its applicability. 📈 Data Scientists Data scientists working with interest rates and derivatives should understand the Vasicek model as it\u0026#39;s a fundamental building block for more advanced models. Tags: Vasicek model, interest rate, mean-reversion Vasicek model: $dr_t = a(b - r_t)dt + \\sigma dW_t$, Hull-White model is a mean-reverting short rate model that allows time-varying mean reversion level. Click to expand 📊 Quants Hull-White model is widely used in quant finance for interest rate modeling, derivative pricing, and risk management. 🤖 AI Researchers Hull-White model can be applied in AI research for interest rate prediction and financial risk management applications. 📈 Data Scientists Data scientists working with interest rates and derivatives should understand the Hull-White model as it\u0026#39;s widely used in fixed income markets. Tags: Hull-White model, interest rate, mean-reversion Hull-White model: $dr_t = a(b(t) - r_t)dt + \\sigma dW_t$, Constant elasticity of variance (CEV) model is a stochastic volatility model where volatility is proportional to the asset price raised to a power γ. Click to expand 📊 Quants CEV model is used in quant finance for option pricing, derivative pricing, and risk management. 🤖 AI Researchers CEV model can be applied in AI research for option pricing and financial risk management applications. 📈 Data Scientists Data scientists working with options and derivatives should understand the CEV model as it\u0026#39;s widely used for option pricing with varying volatility. Tags: CEV model, constant elasticity of variance, stochastic volatility Constant elasticity of variance: $dS_t = \\mu S_t dt + \\sigma S_t^\\gamma dW_t$, Heston model is a stochastic volatility model that incorporates both asset price dynamics and volatility dynamics using two correlated Wiener processes (dWt^1, dWt^2). Click to expand 📊 Quants Heston model is widely used in quant finance for option pricing, derivative pricing, and risk management. 🤖 AI Researchers Heston model can be applied in AI research for option pricing and financial risk management applications. 📈 Data Scientists Data scientists working with options and derivatives should understand the Heston model as it\u0026#39;s widely used for option pricing with stochastic volatility. Tags: Heston model, stochastic volatility, option pricing Heston model: $dS_t = \\mu S_t dt + \\sqrt{\\nu_t} S_t dW_t^1$, $d\\nu_t = \\kappa(\\theta - \\nu_t) dt + \\xi \\sqrt{\\nu_t} dW_t^2$, Bachelier model is an option pricing model that assumes the underlying asset follows a normal distribution, with a standard normal cumulative distribution function (N). Click to expand 📊 Quants Bachelier model is used in quant finance for option pricing, particularly for short-term options and interest rate options. 🤖 AI Researchers Bachelier model can be applied in AI research for option pricing but its assumption of normal distribution limits its applicability. 📈 Data Scientists Data scientists working with options and derivatives should understand the Bachelier model as it\u0026#39;s a fundamental building block for more advanced models. Tags: Bachelier model, option pricing, normal distribution Bachelier model: $C(S, K, T, \\sigma) = (S - K)N(d) + \\sigma \\sqrt{T}N'(d)$, Chen model is a stochastic volatility model where volatility is proportional to the asset price raised to a power γ. Click to expand 📊 Quants Chen model is used in quant finance for option pricing, derivative pricing, and risk management. 🤖 AI Researchers Chen model can be applied in AI research for option pricing and financial risk management applications. 📈 Data Scientists Data scientists working with options and derivatives should understand the Chen model as it\u0026#39;s an alternative to the CEV model for varying volatility. Tags: Chen model, stochastic volatility, option pricing Chen model: $dS_t = \\mu S_t dt + \\sigma S_t^\\gamma dW_t$, Girsanov theorem is used to change the probability measure of a stochastic process, allowing for risk-neutral pricing of derivatives. Click to expand 📊 Quants Girsanov theorem is crucial in quant finance for option pricing, derivative pricing, and risk management. 🤖 AI Researchers Girsanov theorem can be applied in AI research for option pricing and financial risk management applications. 📈 Data Scientists Data scientists working with options and derivatives should understand the Girsanov theorem as it\u0026#39;s widely used for risk-neutral pricing. Tags: Girsanov theorem, change of measure, risk-neutral pricing Girsanov theorem: $\\frac{d\\mathbb{Q}^*}{d\\mathbb{Q}} = \\exp\\left(-\\int_0^T \\theta_t dW_t - \\frac{1}{2}\\int_0^T \\theta_t^2 dt\\right)$, Martingale pricing calculates the present value of a derivative under the risk-neutral measure (𝔼^𝕼) using the filtration 𝔽t. Click to expand 📊 Quants Martingale pricing is crucial in quant finance for option pricing, derivative pricing, and risk management. 🤖 AI Researchers Martingale pricing can be applied in AI research for option pricing and financial risk management applications. 📈 Data Scientists Data scientists working with options and derivatives should understand martingale pricing as it\u0026#39;s widely used for risk-neutral valuation of derivatives. Tags: martingale pricing, risk-neutral measure, option pricing Martingale pricing: $V_t = \\mathbb{E}^\\mathbb{Q}\\left[e^{-r(T-t)}V_T | \\mathcal{F}_t\\right]$, Breeden-Litzenberger formula relates the second derivative of an option price with respect to the strike price to the risk-neutral density of the underlying asset. Click to expand 📊 Quants Breeden-Litzenberger is important in quant finance for extracting risk-neutral densities from option prices and assessing market expectations. 🤖 AI Researchers Breeden-Litzenberger can be applied in AI research for option pricing and financial risk management applications. 📈 Data Scientists Data scientists working with options and derivatives should understand Breeden-Litzenberger as it\u0026#39;s widely used for extracting risk-neutral densities from option prices. Tags: Breeden-Litzenberger, risk-neutral density, option pricing Breeden-Litzenberger: $\\frac{\\partial^2 C}{\\partial K^2} = e^{rT}f^*(K)$, Basic counting principles are fundamental techniques in combinatorics for calculating the number of possible arrangements, selections, or combinations of objects. These principles include factorials, permutations, combinations, the binomial theorem, Pascal\u0026#39;s triangle, and Vandermonde\u0026#39;s identity. Basic counting principles have numerous applications across various fields, including computer science, cryptography, and statistical analysis. In machine learning, they are used for tasks such as feature selection, encoding categorical variables, and sampling methods. In finance, basic counting principles are applied in portfolio optimization, risk management, and the analysis of combinations of financial instruments. Basic Counting Principles Click to expand Basic counting principles are fundamental techniques in combinatorics for calculating the number of possible arrangements, selections, or combinations of objects. These principles include factorials, permutations, combinations, the binomial theorem, Pascal\u0026#39;s triangle, and Vandermonde\u0026#39;s identity. Basic counting principles have numerous applications across various fields, including computer science, cryptography, and statistical analysis. In machine learning, they are used for tasks such as feature selection, encoding categorical variables, and sampling methods. In finance, basic counting principles are applied in portfolio optimization, risk management, and the analysis of combinations of financial instruments. Factorial represents the product of all positive integers up to n. It is used in combinatorics, probability, and many mathematical formulas. For example, calculating the number of ways to arrange 5 books on a shelf: 5! = 5 × 4 × 3 × 2 × 1 = 120. Click to expand 📊 Quants Factorial is fundamental in quantitative finance research for combinatorics and probability calculations. 🤖 AI Researchers Factorial is important in AI research for combinatorial and probabilistic problems. 📈 Data Scientists Factorial is a basic concept frequently discussed in data science interviews to demonstrate understanding of combinatorics and probability. Tags: Factorial, Combinatorics, Probability, Discrete Mathematics, Arrangements Factorial: $n! = n(n-1)(n-2)\\dots1$, Permutations represent the number of ways to arrange r elements out of n. It is used to calculate order-sensitive arrangements. For example, finding the number of ways to arrange 3 letters out of 5: $_5P_3 = \\frac{5!}{(5-3)!} = 60$. Click to expand 📊 Quants Permutations are used in quantitative finance research for calculating order-sensitive arrangements and combinatorics. 🤖 AI Researchers Permutations are relevant in AI research for understanding order-sensitive arrangements in combinatorial problems. 📈 Data Scientists Permutations are a common topic in data science interviews to demonstrate understanding of combinatorics and arrangements. Tags: Permutations, Combinatorics, Arrangements, Order-Sensitive, Discrete Mathematics Permutations: $_nP_r = \\frac{n!}{(n-r)!}$, Combinations represent the number of ways to choose r elements from n without considering the order. It is used in combinatorics and probability theory. For example, finding the number of ways to choose 3 people from a group of 5: $_5C_3 = \\frac{5!}{3!(5-3)!} = 10$. Click to expand 📊 Quants Combinations are essential in quantitative finance research for combinatorics and probability calculations. 🤖 AI Researchers Combinations are relevant in AI research for understanding unordered arrangements in combinatorial problems. 📈 Data Scientists Combinations are a common topic in data science interviews to demonstrate understanding of combinatorics and selections. Tags: Combinations, Combinatorics, Selections, Order-Insensitive, Discrete Mathematics Combinations: $_nC_r = \\frac{n!}{r!(n-r)!}$, The Binomial theorem expresses the expansion of powers of a binomial. It is used in algebra, combinatorics, and probability theory. For example, expanding $(a\u0026#43;b)^3 = {3 \\choose 0}a^3b^0 \u0026#43; {3 \\choose 1}a^2b^1 \u0026#43; {3 \\choose 2}a^1b^2 \u0026#43; {3 \\choose 3}a^0b^3$. Click to expand 📊 Quants The Binomial theorem is relevant in quantitative finance research for algebraic manipulations and probability calculations. 🤖 AI Researchers The Binomial theorem is important in AI research for polynomial expansions and probability theory. 📈 Data Scientists The Binomial theorem is a useful concept for data science interviews to demonstrate understanding of algebra and probability. Tags: Binomial Theorem, Algebra, Combinatorics, Polynomial Expansion, Probability Binomial theorem: $(a+b)^n = \\sum_{k=0}^n {n \\choose k} a^{n-k}b^k$, Pascal\u0026#39;s triangle is a triangular array of binomial coefficients. Each number is the sum of the two numbers directly above it. It is used in combinatorics, algebra, and probability theory. For example, the 4th row of Pascal\u0026#39;s triangle is: 1, 4, 6, 4, 1. Click to expand 📊 Quants Pascal\u0026#39;s triangle is relevant in quantitative finance research for combinatorics and probability calculations. 🤖 AI Researchers Pascal\u0026#39;s triangle is important in AI research for understanding binomial coefficients and combinatorial problems. 📈 Data Scientists Pascal\u0026#39;s triangle is a helpful concept for data science interviews to demonstrate understanding of combinatorics and probability. Tags: Pascal\u0026#39;s Triangle, Combinatorics, Algebra, Binomial Coefficients, Probability Pascal's triangle: ${n \\choose k} = {n-1 \\choose k-1} + {n-1 \\choose k}$, Vandermonde\u0026#39;s identity is a combinatorial identity relating binomial coefficients. It is used in combinatorics, algebra, and probability theory. For example, Vandermonde\u0026#39;s identity for $m=3, n=2, r=3$ is: $\\sum_{k=0}^3 {3 \\choose k} {2 \\choose 3-k} = {5 \\choose 3}$. Click to expand 📊 Quants ⭐⭐⭐⭐⭐ Vandermonde\u0026#39;s identity is relevant in quantitative finance research for combinatorics and probability calculations. 🤖 AI Researchers ⭐⭐⭐⭐⭐ Vandermonde\u0026#39;s identity is important in AI research for understanding binomial coefficients and combinatorial problems. 📈 Data Scientists ⭐⭐⭐⭐⭐ Vandermonde\u0026#39;s identity is a useful concept for data science interviews to demonstrate understanding of combinatorics and probability. Tags: Vandermonde\u0026#39;s Identity, Combinatorics, Algebra, Binomial Coefficients, Probability Vandermonde's identity: $\\sum_{k=0}^r {m \\choose k} {n \\choose r-k} = {m+n \\choose r}$. Advanced Counting\nClick to expand 📊 Quants 🤖 AI Researchers ⭐⭐⭐⭐⭐ 📈 Data Scientists Inclusion-exclusion principle: $|A_1 \\cup A_2 \\cup \\dots \\cup A_n| = \\sum_{i} |A_i| - \\sum_{i","date":"4 April 2023","externalUrl":null,"permalink":"/other/the-wall/","section":"Others","summary":"","title":"CheatsheetGPT","type":"other"},{"content":"","date":"4 April 2023","externalUrl":null,"permalink":"/categories/experiments/","section":"Categories","summary":"","title":"Experiments","type":"categories"},{"content":"","date":"4 April 2023","externalUrl":null,"permalink":"/tags/finance-cheatsheat/","section":"Tags","summary":"","title":"Finance Cheatsheat","type":"tags"},{"content":"","date":"4 April 2023","externalUrl":null,"permalink":"/tags/machine-learning-cheatsheat/","section":"Tags","summary":"","title":"Machine Learning Cheatsheat","type":"tags"},{"content":"","date":"4 April 2023","externalUrl":null,"permalink":"/tags/math-cheatsheat/","section":"Tags","summary":"","title":"Math Cheatsheat","type":"tags"},{"content":"","date":"4 April 2023","externalUrl":null,"permalink":"/other/","section":"Others","summary":"","title":"Others","type":"other"},{"content":"","date":"3 March 2023","externalUrl":null,"permalink":"/tags/diffusion/","section":"Tags","summary":"","title":"Diffusion","type":"tags"},{"content":"","date":"3 March 2023","externalUrl":null,"permalink":"/tags/research/","section":"Tags","summary":"","title":"Research","type":"tags"},{"content":" How do humans make discoveries? Exploring the unknown and pushing the frontiers of knowledge? We offer a new perspective on human discoveries, based on a simple analogy: humans are particles diffusing out of a labyrinth. Imagine that each human is an explorer tryingt to find an exit from a maze-like environment. Every turn and step is a gamble. Some are more adventurous than others, some follow the crowd, some learn from their mistakes, some get lucky. As they explore, they reveal the structure and size of the labyrinth, reducing the fog of ignorance. On this intuition, we model discoveries as a stochastic process. We may use this model to derive insights into principles of scientific inquiry, the role of curiosity, collaboration, and diversity.\nThe diffusion process If you want to start from scratch, first, click the restart button. You can start by experimenting with the various controls.\nRestart Toggle Heatmap Toggle Particles Escapism: 0.0005\nResearchers: 100\nObstacles: 20\nChange Colors Enable Dark Mode Most of the parameters are fairly self-explanatory. Escapism is the parameter that deserves some explanation. It characterizes the tendency to go \u0026ldquo;outwards\u0026rdquo;. These can be thought of as the researchers that take the \u0026ldquo;straight logical path\u0026rdquo; to the solution. It often works, but not always. The path to greatness is not always just a straight line. How about the opposite of an escapist? Someone who has $0$ escapism can be though of as someone who really does not leverage any structure into their research. They just hope to randomly come across the solution. Although it technically can happen, any random researcher is less likely to make it this way. In the above simulation, the parameter of Escapism still creates a range of researchers, with a maximum escapism based on the selection (the actual escapism corresponds to the shade of the particle).\nInterpretations This Labyrinth can represent either one domain of research, or research as a whole. It matches simple phenomena one would qualitatively expect: more researchers result in a higher rate of discoveries.\nIf someone makes a discovery, there\u0026rsquo;s often someone quite close to making the same discovery. This is often observed in scientific literature, where e.g. similar results are produced at the same time by multiple scientists.\nSomeone might stray far away from the average, making a breakthrough discovery after a long time. The longer it takes for a discovery to happen, the more likely this someone will be far ahead from the others (intepreted as more novelty).\nAfter a big obstacle is overcome (the blue/grey arcs), there’s a lot of follow-up discovery that comes easily (but not always, depending on the next obstacle).\nObstacles researchers face have varying difficulty. Smaller opening of the arc means bigger the difficulty to overcome.\nYou might be at the frontier, but if you are working on the wrong problems or using the wrong approachs you will get stuck (far from the opening of the obstacle or heading the wrong way).\nImplications This model implies that someone making a discovery does not mean that without them the discovery would have never been made. This someone\u0026rsquo;s contribution lies in the reduction of the interdiscovery time. These implications are compatible with insights from books such as Outliers, Sapiens, and Fooled By Randomness. To state it in another way: a discovery is an accident waiting to happen.\nIf we are merely \u0026ldquo;particles\u0026rdquo; performing a random walk, then what control do we have? How can we have any merit in our discoveries and any credit for them? Controlling the properties of this biased random walk to perform a more intelligent \u0026ldquo;search\u0026rdquo; can be critical for discovery. This gives in reality more agency to a human, allowing them to modify their degree of escapism and its fine characteristics when they think this is appropriate. E.g., if you are stuck for a long time around the same problem, it is wise to switch things up. Take less of a biased walk if you don\u0026rsquo;t know any better.\nExtensions for more realism This model does not handle the fact that a discovery by one might bring related discoveries by others - it is only limited to the fact that a discovery by one will often lead to more follow-up discoveries by the same individual. This model can easily be modified to handle this however. Beyond escapism, we may add a parameter affecting the \"follower\" attribute of a researcher. The followers will try to catch up with the researcher, by performing a biased random walk towards the other researcher, sort of like a one-sided gravitational attractor. This can be implemented beautifully, by adding gravitational forces biasing the walk, with the \"discoverers\" having larger mass and therefore exerting greater force. The time it takes to catch up is then expected to be proportional to their distance and the obstacles in between.\nThis model does not model collaboration. This can also be modeled as a group of particles having a stronger gravitational pull on each other than average.\nAs mentioned in the implications, more realistically, humans perform an evolving random walk, whose biases are changing.\nAn interesting question is if adding dimensions would increase realism. Note that higher dimensions are characterized by various counter-intuitive phenomena.\n","date":"3 March 2023","externalUrl":null,"permalink":"/posts/the-diffusion-of-discovery/","section":"Posts","summary":"","title":"The diffusion of discovery","type":"posts"},{"content":"","date":"3 March 2023","externalUrl":null,"permalink":"/tags/brownian-motion/","section":"Tags","summary":"","title":"Brownian-Motion","type":"tags"},{"content":"","date":"3 March 2023","externalUrl":null,"permalink":"/categories/finance/","section":"Categories","summary":"","title":"Finance","type":"categories"},{"content":"","date":"3 March 2023","externalUrl":null,"permalink":"/tags/geometric-brownian-motion/","section":"Tags","summary":"","title":"Geometric-Brownian-Motion","type":"tags"},{"content":"","date":"3 March 2023","externalUrl":null,"permalink":"/tags/jump-diffusion/","section":"Tags","summary":"","title":"Jump-Diffusion","type":"tags"},{"content":" A common model for the evolution of the price of a financial security, such as a stock, is that it follows a brownian motion.\nArithmetic Brownian Motion $$ dS = \\mu dt + \\sigma dZ\\quad (ABM)$$Let\u0026rsquo;s look at our first few ABM. Use the following controls to interact with the simulation.\nRestart Increase Paths Decrease Paths Toggle Opacity Increase Drift Reduce Drift After you have experimented with the above, let\u0026rsquo;s make some additional observations.\nToggle Average Path Toggle Terminal Distribution Drift: Constant Sinusoidal Sinusoidal Sign Volatility: Constant Sinusoidal Sinusoidal Sign ABM, is not appropriate for modeling stocks. For example the price might evolve to negative values. This, along with other issues motivates the introduction of GBM.\nGeometric Brownian Motion The Geometric Brownian Motion is a stochastic process where the diffusion is proportional to the current price of the process (that is, the security). Moves are in percentage terms. Click to observe the evolution of geometric brownian motions. The terminal distribution in this case becomes a lognormal and the price never becomes 0.\n$$ \\frac{dS}{S}= \\mu dt + \\sigma dZ\\quad (GBM)$$ Jump Diffusion and Other Models There are numerous other models that one can adopt for stock prices. Stay tuned for the simulation of more models, including Jump Diffusion and Local Volatility models.\n","date":"3 March 2023","externalUrl":null,"permalink":"/posts/modeling-stock-prices/","section":"Posts","summary":"","title":"Modeling stock prices with stochastic processes","type":"posts"},{"content":"","date":"1 January 2023","externalUrl":null,"permalink":"/tags/equation/","section":"Tags","summary":"","title":"Equation","type":"tags"},{"content":"","date":"1 January 2023","externalUrl":null,"permalink":"/tags/math-exploration/","section":"Tags","summary":"","title":"Math Exploration","type":"tags"},{"content":" ","date":"1 January 2023","externalUrl":null,"permalink":"/other/mathematical-market/","section":"Others","summary":"","title":"Mathematical Parade","type":"other"},{"content":" ","date":"1 January 2023","externalUrl":null,"permalink":"/other/mathematical-river/","section":"Others","summary":"","title":"Mathematical River","type":"other"},{"content":" Enable Dark Mode ","date":"1 January 2023","externalUrl":null,"permalink":"/other/mathematical-tapestry/","section":"Others","summary":"","title":"Mathematical Tapestry","type":"other"},{"content":" The latent simplicity posits that our limited perception results in complicated models of a simple underlying reality. Many phenomena we encounter are simplified manifestations of general rules presented in specific contexts. By recognizing this principle and striving for the simplest possible explanation, we can avoid overfitting and develop more accurate models of the world around us.\nExample 1: The Two-Dimensional Plane Dwellers Imagine beings living in a two-dimensional plane, unaware of the three-dimensional world. When a three-dimensional sphere intersects their plane, they perceive it as a two-dimensional circle. As the sphere moves through the plane, they observe the circle appearing to grow and shrink, leading them to create complex models to explain the phenomenon. In reality, the circle\u0026rsquo;s size changes due to the motion of the sphere in the third dimension, which the two-dimensional beings cannot perceive.\nExample 2: Plato\u0026rsquo;s Allegory of the Cave Plato\u0026rsquo;s Allegory of the Cave is another illustration. In the allegory, a group of people have been chained inside a cave since birth, facing a blank wall. They cannot see the actual objects outside the cave, nor can they turn their heads to view the world behind them. A fire behind the prisoners casts shadows of various objects, such as animals and people, onto the wall, and these shadows become their only perception of reality.\nThe prisoners are unaware of the true nature of the objects and the world outside the cave. They observe the shadows and their movements, noticing patterns and creating meanings for them. For example, they may see a shadow of a tree swaying in the wind and believe that the shadow itself possesses some inherent power causing the movement, without realizing it\u0026rsquo;s merely a representation of a real tree outside the cave. They develop complex theories and beliefs to explain the behavior of the shadows, creating an elaborate understanding of a reality that is, in fact, much simpler than they perceive.\nExample 3: Euler\u0026rsquo;s Formula and its Special Cases Euler\u0026rsquo;s Formula can be expressed as follows:\n$$e^{ix} = \\cos(x) + i \\sin(x)$$This formula has several interesting special cases that showcase the Latent Simplicity in the context of mathematical relationships.\nEuler\u0026rsquo;s Formula simplifies trigonometric identities. For instance, the addition formulas for sine and cosine can be derived from Euler\u0026rsquo;s Formula:\n$$\\sin(x + y) = \\sin(x)\\cos(y) + \\cos(x)\\sin(y)$$$$\\cos(x + y) = \\cos(x)\\cos(y) - \\sin(x)\\sin(y)$$One can start assigning intuitions to all derived equations out of Euler\u0026rsquo;s formula, but there is one equation that drives them all.\nOn Overfitting Occam\u0026rsquo;s Razor suggests that out of all explanations, the simplest one should have the highest prior probability, i.e., it is the most likely one. In the context of the two-dimensional plane dwellers, if they were guided by Occam\u0026rsquo;s Razor, they might be more inclined to search for a simpler explanation for the circle\u0026rsquo;s behavior, rather than relying on elaborate theories about mysterious forces or expanding materials.\n","date":"7 May 2020","externalUrl":null,"permalink":"/posts/hidden-simplicity-principle/","section":"Posts","summary":"","title":"Latent simplicity in observable phenomena","type":"posts"},{"content":"","date":"7 May 2020","externalUrl":null,"permalink":"/tags/mental-models/","section":"Tags","summary":"","title":"Mental-Models","type":"tags"},{"content":"Adjust the Parameters below to explore the spread of the disease under different scenarios. Bear in Mind that some parameters might lead to poor performance depending on your device. If you don\u0026rsquo;t understand what is happening, there is an explanation below the simulation environment.\nWarning: It\u0026rsquo;s recommended to use a large enough screen (for example a tablet or a desktop). Some information is omitted in smaller screens.\nPopulation Density Town Size Connections Radius Connectivity Chance Infection Chance Mean Days Sick Can you get Reinfected? Days Before Reinfection How to use the Simulation Environment First click in the simulation environment to focus on it. Press h,j,k,l to move around the bigger map (the one at the top) or click in the mini map (which is also a heat map) to observe a different area. Press \u0026ldquo;I\u0026rdquo; or \u0026ldquo;O\u0026rdquo; to endorse people to stay in their homes or go out. Click at two end points in the bigger map to create a quarantine. Mouse over a certain house to inspect the state of the residents (displayed in bottom right).\nIntroduction In this blog post I attempt to model the spread and effects of a disease. This is a very timely topic with the emergence of COVID-19. Being able to simulate the disease is invaluable, particularly when combined with the simulation of mitigation approaches.\nModel Personal Networks Every person has a constant network (ego-network) of people they can potentially interact with. For example you can think of this network as all the people you have interacted with in the last 100 days (or some other time frame long enough so that the outcome of the disease have been determined). Denote the network of citizen $u$ as $N_u$. This model is household-based, i.e. we have families living in the same building (indicated with rectangles in the simulation above). Individuals in the same house are naturally in the network of each other.\nInteractions After fixing $N_u$, we have a dynamic network of temporary interactions. For example the daily interactions of a person. Denote this as $N_u(t) = \\{ v : v \\in N_u, v \\text{ interacted with u at time t} \\}$. To decide if $u,v$ interacted with each other during, say, a day we consider a few parameters: If any of the two are sick with symptoms - the severity of the symptoms, the social distancing parameter of the individual which is based on a biased random walk, and whether the two individuals live in the same building or not. The random walk can be adjusted depending on the governmental guidelines, i.e. whether the government is urging people to go out or stay at home (this is controlled by pressing \u0026ldquo;O\u0026rdquo; or \u0026ldquo;I\u0026rdquo; respectively in the simulation environment).\nDisease Evolution and Hospital capacity Once a person gets infected, their disease evolves according to a simple Markov Chain. Every person that gets infected starts with no symptoms. Every passing day the person has a chance of transitioning to the state of having symptoms. Similarly the disease can progress to other stages.\nWhen an infected person reaches a critical condition it requires hospitalization. If there is capacity the person is admitted to the hospital. Otherwise they are not admitted, and their chance of passing away increases. As you can see in the image below, in that case the hospital capacity was exceeded for a brief period, resulting in certain people not getting treatment.\nQuarantines The user can click at two points succesively in order to place a quarantine (rectangular in shape). People within the quarantine can not interact with people outside. Possibly in a future version it will be explored if an automatic quarantine scheme can lead to good control of the spread - relatively to some penalty term that prevents the overuse of quarantines.\n","date":"29 March 2020","externalUrl":null,"permalink":"/posts/modeling-and-simulating-a-pandemic/","section":"Posts","summary":"","title":"Modeling and simulating pandemic spread","type":"posts"},{"content":"","date":"4 February 2018","externalUrl":null,"permalink":"/tags/exploring/","section":"Tags","summary":"","title":"Exploring","type":"tags"},{"content":"","date":"4 February 2018","externalUrl":null,"permalink":"/tags/generalizing/","section":"Tags","summary":"","title":"Generalizing","type":"tags"},{"content":"","date":"4 February 2018","externalUrl":null,"permalink":"/tags/learning/","section":"Tags","summary":"","title":"Learning","type":"tags"},{"content":"In the pursuit of personal growth, it\u0026rsquo;s essential to develop an effective learning strategy to navigate the vast world of information and new concepts. This blog post will focus on three key principles for mastering learning: generalizing, exploring, and relating concepts. By employing these techniques, you can not only absorb more information but also apply it in practical and meaningful ways.\nGeneralizing, Exploring, and Relating Concepts Consider the following learning principles:\nGeneralizing what we learn, Exploring the concepts we learn, Naming things. Generalizing and exploring allow us to learn beyond what we are directly taught, while naming helps us recognize and apply our learnings to random occurrences in our lives [1]. When we encounter a new practical technique, we need to:\nUnderstand the technique or advice, Make it a habit (the challenging part). This post will present an approach to learning, and it\u0026rsquo;s up to you to adopt it if you believe in its validity.\nAn Example of Generalization Let\u0026rsquo;s examine a mathematical example. A friend recently asked me to compute the sum:\n$$ J = \\frac {1}{1 \\times 2} + \\frac {1}{2 \\times 3} + \\frac {1}{3 \\times 4} + ... $$To compute this infinite sum, we can rewrite it as:\n$$ \\sum_{n=1}^{\\infty} \\frac {1}{n (n+1)} $$The solution can be found by noticing that:\n$$ \\frac {1}{n(n+1)} \\equiv \\frac {A} {n} + \\frac {B}{n+1} $$Where $A=1, B=-1$, and thus we have:\n$$ J =\\sum_{n=1}^{\\infty} \\left(\\frac {1} {n} + \\frac {-1}{n+1}\\right) $$One could see that terms cancel with the next term in the sequence, and we are left with: $J=1$. [2]\nGeneralizing To generalize this idea, we must identify the precise structure that allowed us to perform the trick or combination of tricks. In this case, we used two major tricks: decomposition and cancellation. Let\u0026rsquo;s start by generalizing the cancellation part. We can agree that if $a_n = \\frac {1} {n}$, then:\n$$ J =\\sum _{n=1}^{\\infty} \\left( a _n - a _{n+1} \\right) $$We can observe that this could work similarly if we had:\n$$ J_1 = \\sum _{\\text{consecutive integers}}(a _n - a _{n+1}) $$Or for some integer $i$, we could have [2]:\n$$ J _2= \\sum _{\\text{consecutive integers}}(a _n - a _{n+i}) $$Where instead of the cancellation happening with the next term, it would happen after $i$ terms.\nCan we further generalize this? Let\u0026rsquo;s consider the intermediate general case:\n$$ J _3= \\sum _{\\text{consecutive integers}}( c_0 a_n - c_1 a _{n+i} - c_2 a _{n+i+j}) $$Where $(i, j)$ are positive integers. One instance of those general series could be:\n$$ J _3'= \\sum _{\\text{consecutive integers}}( a _n - 9 a _{n+2} + 3 a _{n+5}) $$Where $(i=2, j=3)$. Of course, this particular series might not have the cancellation property that we aspire to. To find out under which constraints there will be a cancellation (if there will be a cancellation at all), consider the following figure, where each row represents one term of the series, starting from $(i=1)$ and ending in a finite row-term $(i=k+i+j)$:\nWe can see that after a certain row, if there are sufficiently many rows, $a(1+i+j)$ appears in each column only once. The same is true for $a(k+i+j)$ and all the intermediary terms. Therefore, those terms will have a coefficient of $(c_0+c_1+c_2)$ in the final sum, and for them to be zero, we simply require that $c_0+c_1+c_2 = 0$.\nIf that\u0026rsquo;s true, then the dark-grey area in the figure will cancel out! As an interesting exercise, you could try to find other fractions with a similar cancellation property.\nExploring After writing that sum in this form, one could observe that the product of consecutive integers is \u0026ldquo;visually\u0026rdquo; similar to the left-hand side of:\n$$ \\frac {n(n+1)}{2} = \\sum_{k=1}^{n} k $$But they are not quite the same. That\u0026rsquo;s not a major problem, though, since we can simply rewrite this as:\n$$ n(n+1) = 2 \\sum _{k=1}^{n} k \\Rightarrow \\frac {1}{ n(n+1) } = 0.5 \\frac {1 } {\\sum _{k=1}^{n} k} $$Using this derived result in the original series, we get:\n$$ J = \\sum_{n=1}^{\\infty} \\frac {1}{n (n+1)} = 0.5 \\sum _{n=1}^{\\infty} \\frac 1 {\\sum _{k=1}^{n} k} $$By exploring this path, we (1) have fun, (2) become more familiar with manipulating series, and (3) capture the relationship between this special-looking series and the initial sum $J$. Even considering the existence of a correspondence between $J$ and the unusual inverse sum might help us, depending on whether that formula has a structure that emerges in many cases.\nOf course, we are humans, and unfortunately, this practice will not scale very well if abused. It is important to explore within your field of interest or around critical concepts to avoid getting lost. For instance, let\u0026rsquo;s say that your field of interest is Graph Theory. In that case, you would want to attempt to correlate the initial series with a graph-theoretic result. For instance, the formula $$\\frac {n(n-1)}{2}$$ describes the number of edges, $|E_n|$, in a complete graph $K_n$ with $n$-nodes. Thus:\n$$ \\frac 1 {n(n+1)} = \\frac {0.5} {|E_{n}|} $$This relationship may lead to a potential link with Graph Theory concepts or problems. Even though this example might not necessarily produce significant results, the exploration process itself will expand your knowledge and understanding of the domain.\nRelating Concepts When we learn about new concepts, it is important to relate them to what we already know. Connecting new concepts to existing knowledge strengthens our understanding and enables us to use them in practical applications.\nFor instance, let\u0026rsquo;s say you\u0026rsquo;re learning about Markov Chains. By relating it to your prior understanding of probability theory and statistics, you can establish a strong foundation for your learning. This way, you will have a better grasp of the new concept and recognize potential applications in your field of interest.\nConclusion By generalizing, exploring, and relating concepts, you can maximize your learning and boost your ability to apply new knowledge effectively. As you learn, actively seek out connections and patterns, and don\u0026rsquo;t be afraid to explore. This approach will help you develop a more profound understanding and navigate the vast world of information with ease.\n","date":"4 February 2018","externalUrl":null,"permalink":"/posts/learn-by-generalizing/","section":"Posts","summary":"","title":"Learning through generalization and exploration","type":"posts"},{"content":"","date":"4 February 2018","externalUrl":null,"permalink":"/tags/relating-concepts/","section":"Tags","summary":"","title":"Relating Concepts","type":"tags"},{"content":"","date":"4 February 2018","externalUrl":null,"permalink":"/tags/sequences/","section":"Tags","summary":"","title":"Sequences","type":"tags"},{"content":"","date":"22 December 2017","externalUrl":null,"permalink":"/tags/betting/","section":"Tags","summary":"","title":"Betting","type":"tags"},{"content":" I have already dedicated a previous post on the simulation of the doubling method. In this post I will walk you through steps that can be taken for the creation of a virtual betting game. In particular we will examine a football betting game, similar to one currently found in the market.\nDesign decisions Initially, before we develop the simulation, we can discuss two different possible methods to create such a game.\nSimulating a football game can be complicated depending on the method you adopt. But implementation complexity aside, design decisions can have a direct impact on the tractability of analysis of expected profits.\nLow Level simulator A low level method would simulate each football player of both teams as an independent agent, acting using local information in a realistic way.\nAs a betting company that type of approach although it could be far more interesting for clients, is much harder to first develop, and subsequently analyze, resulting in less control on the results.\nHigh Level simulator A high level approach can circumvent the aforementioned difficulties under a carefully designed model. In that method we do not simulate football players or the general mechanics of the game; instead, we simply generate a high level description of the game accompanied by a rich pool of graphics/videos to create the illusion of a \u0026ldquo;running\u0026rdquo; game.\nIn what follows, we adopt this method.\nOutline of the implementation Have virtual teams $A$ and $B$. Set betting odds (how much a user wins if they bet on the respective results for every dollar they bet), say $w _A,t,w _B$ for win of $A$, draw, or win of $B$ respectively. Generate game events from a Poisson Process for goal scoring opportunities (highlights). That's the same as having exponential distribution for the time between events. If the parameter of the exponential distribution is $T$ that would be the expected time between two highlights. Perform a Categorical distribution Trial to decide between 4 events, goal (g) or miss (m) for $A, \\text{ or } B$ with four, in general, different probabilities $p _{ga}, p _{ma}, p _{gb}, p _{mb}$. If the previous trial was successful, play a random scoring video for the corresponding team. Otherwise, play a random goal-missing video. Decision variables The betting company gets to decide variables $w _A,t,w _B$, $T$ (or $\\lambda$) and the four goal/miss probabilities in order to ascertain profits.\nThe employees of the company could then compute the expected profits with simulation (Monte Carlo methods) or even better through analytical calculations (if possible).\nAnalysis First of all we need to determine the probability of winning, drawing or loosing for team $A$. This is given by the following events\n$$\\mathbb P[Goals_A\u003eGoals_B] = \\sum _{k=1} ^{\\infty} \\sum _{j=0} ^{k-1} \\mathbb P[Goals_A=k,Goals_B = j]$$$$\\mathbb P[Goals_A=Goals_B] = \\sum _{k=0} ^{\\infty} \\mathbb P[Goals_A=k,Goals_B=k]$$and the third case is symmetrical to the first. Next, we need to evaluate the probability of a specific number of goals for each team, jointly:\n$$\\mathbb P[Goals_A=i,Goals_B=j]$$Those two events are of course not independent. There is an underlying variable, that of the number of highlights of the game $H$, that affects the outcome and knowing its value can simplify our work. We can therefore marginalize over the possible values of $H$\n$$\\mathbb P[Goals_A=i,Goals_B=j]=\\sum _{k=i+j}^{\\infty} \\mathbb P[H=k] \\cdot \\frac {k!} {i! j! (k-i-j)!} \\cdot {p _ {wA}^i p _ {wB} ^j (p _{mA} + p _{mB})^{k-i-j} }$$Where the probability mass function of the multinomial distribution was used for three events: goal for the first team, goal for the second, and miss for either.\nFinally we need to compute the probability for $k$ highlights. This can be computed by the fact that the number of highlights until time $t$ follows the Poisson distribution with parameter $\\lambda t$ [2], therefore $$\\mathbb P[H=k] = \\frac {(\\lambda \\cdot 90\\ min)^k e^{- \\lambda \\cdot 90\\ min}} {k!}$$Where \u0026ldquo;$90\\ min$\u0026rdquo; is the duration of a football game. The parameter $\\lambda$ can be set through the equation $\\lambda \\cdot 90 \\min = s$ if we expect an average of $s$ highlights per game. The term \u0026ldquo;highlight\u0026rdquo; is subjective in any case, and it is more precisely defined combined with goal-probabilities. Consequently we can define any expected number of events, and that decision will be meaningful or not depending on the subsequent definition of the goal-probabilities.\nFor simplification we set $s=10 \\Rightarrow \\lambda = \\frac {1} {9\\ min} $.\n$$\\mathbb P[H=k] = \\frac {10^k e^{- 10}} {k!}$$Now let\u0026rsquo;s assume that team $A$ is better and has probability $p_{ga}=0.2$. $B$ is slightly behind with a probability $p _{gb}=0.15$ when playing with $A$. Although the missing-probabilities are not important for the result, they do affect the Quality of Experience (QoE) [3]. A sensible option would be to set the probabilities proportional to the goal probabilities of the corresponding team. Thus they can be found using the following equations:\n$$ \\frac {p _{ga}} {p _{gb}} = \\frac {p _{ma}} {p _{mb}} = \\frac {1} {0.75}$$ $$ p _{ga} + p _{gb} + p _{ma} + p _{mb} = 1$$In this post it suffices to say: $$ p _{ma} + p _{mb} = 1-0.35 = 0.65$$resulting in the following:\n$$\\mathbb P[Goals_A=i,Goals_B=j]=\\sum _{k=i+j}^{\\infty} \\frac {10^k e^{- 10}} {k!} \\cdot \\frac {k!} {i! j! (k-i-j)!} \\cdot {0.2^i 0.15 ^j 0.65^{k-i-j} }$$furthermore we can ignore terms after a certain $k$, for instance $k=100$ since the probability for that many highlights is negligible. Of course we could do the same for the infinite sum of $\\mathbb P[Goals_A\u0026gt;Goals_B]$.\nBy truncating the series we can calculate the probabilities of the various game outcomes using a computer program easily and with good precision.\nExpected profit So far we haven\u0026rsquo;t talked about the betting odds. What we need is a positive expected profit for the betting company or negative for the client for every possible action of the client. If the client predicts that team $A$ will win, their expected winnings (per currency unit) will be:\n$$\\mathbb E[predict_A]= (w_A-1) \\mathbb P[Goal_A\u003eGoal_B] - (1-\\mathbb P[Goal_A\u003eGoal_B])$$ or simplified: $\\mathbb E[predict_A]= w_A \\mathbb P[Goal_A\u0026gt;Goal_B] - 1$\nIf the client predicts a draw their expected profit will be:\n$$ \\mathbb E[predict _{draw}]= (t-1) \\mathbb P[Goal _A=Goal _B] - (1-\\mathbb P[Goal _A=Goal _B])$$or simplified: $\\mathbb E[predict_{draw}]= t \\mathbb P[Goal_A=Goal_B] - 1$\nsimilarly: $\\mathbb E[predict_B]= w_B \\mathbb P[Goal_A\u0026lt;Goal_B] - 1$\nGiven that, the Betting company would have to set those odds so that the expected values will be negative but in a reasonable range. Additionally setting all the expected profits equal will make, in principle, every option equally enticing preventing imbalance in the number of bets in each option.\nExample I implement the analysis in Mathematica where we can skip the direct implementation of some parts since the language does that for you. The following function in Mathematica will compute the probability of team A winning, a tie, or team B winning.\nI truncate after 20 terms but this should depend on the mean number of events (or highlights). For example I get:\n$$computeProbability[10, 0.2, 0.15]=\\\\{0.492633, 0.215924, 0.289809\\\\}$$Changing $termsTrunc$ to $30$ results in very slightly modified probabilities, $\\{0.493562, 0.216138, 0.290255\\}$\nNow If we decide to target a specific expected loss for the players, say $0.25$ currency units per 1 currency unit bet, we would choose roughly the following odds as seen in the plot: $1.5$ for win of team A, $2.6$ for win of team B, $3.5$ for a tie. How high or low this target loss is another topic that deserves a seperate study.\nReferences \u0026amp; Links Multinomial Distribution Simulating the Poisson Process, PATRICK MCQUIGHAN Quality of Experience ","date":"22 December 2017","externalUrl":null,"permalink":"/posts/creating-a-football-betting-game/","section":"Posts","summary":"","title":"Creating a profitable football betting game","type":"posts"},{"content":"","date":"22 December 2017","externalUrl":null,"permalink":"/tags/odds/","section":"Tags","summary":"","title":"Odds","type":"tags"},{"content":"","date":"22 December 2017","externalUrl":null,"permalink":"/tags/poisson/","section":"Tags","summary":"","title":"Poisson","type":"tags"},{"content":"","date":"22 December 2017","externalUrl":null,"permalink":"/tags/probability/","section":"Tags","summary":"","title":"Probability","type":"tags"},{"content":"","date":"22 December 2017","externalUrl":null,"permalink":"/tags/simulation/","section":"Tags","summary":"","title":"Simulation","type":"tags"},{"content":"Solving or interpreting equations is a fundamental topic, usually taught in young ages, when students are not very eager to capture the essence of the equations or do not know some more advanced concepts that can reinforce their understanding of them.\nWhen students are presented with an equation $x+4=13$, usually they are asked about the value of $x$. As a student I was shown a number of manipulations that I had to learn in isolation, making the task cumbersome initially but then mechanic. Equations though have an underlying symmetry that allows you to infer most properties by intuition only.\nIn this post we explore equations and we will develop a different but useful perspective on the subject.\nAn initial clarification about \u0026ldquo;two types of equation\u0026rdquo; There are two cases which its critical to distinguish before we proceed\n$$ \\exists x \\in \\mathcal{D}: x+4=13$$ $$ \\forall x \\in \\mathcal{D}: x+4=13 \\Leftrightarrow x+4 \\equiv 13$$The first one corresponds to problems of the form \u0026ldquo;find $x$\u0026rdquo;. The question is: what is the value that satisfies the equation, that makes the two parts indeed equal.\nThe second, usually is a statement which helps you to reason about the set $\\mathcal{D}$ or other parameters that accompany the equivalence.\nIn this post we will only discuss the first case.\nDescribing the conventional solution of an example When you are given an equation, $9x+10=91$, you are told that the left side has the same value as the right side.\nSince those two parts have the same value, modifying them in the same way will maintain the equality. The fact that you don\u0026rsquo;t know the particular value of $x$ yet, is irrelevant.\nNow, let\u0026rsquo;s try to describe the steps involved in solving the equation.\nFirst we will subtract $10$ from each side. This is allowed since subtracting a number from two values that are equal, creates two new values that are also equal.\nThat step was useful since the two new values still contain $x$, but they are also simpler from the initial values.\nThen, we have $9x=81$. Since we need to isolate x, by dividing the two equal values ($9x$ and $81$) by the same number $9$, we end up with two new values, for which we have the information of being equal.\nThus $ x=9 $.\nA function-oriented approach Essentially what we have done before is applying transformations. In mathematics, we have a name for deterministic (same input same output) transformations. We call them functions. The need for a same-input, same-output mechanism asserts that since the left and the right part of the equation were initially the same (same input), after applying the function we will end up with equal values (same output), resulting recursively in a new equation.\nSuppose we have a function $f(x)=x-10$ at our disposal. This function performs a transformation. It takes a number and it reduces it by 10. Also consider another function $g(x)=x/9$. These two functions are one-to-one, they have the property that $f(x)=f(y) \\Rightarrow x=y$.\nReturning to our initial problem, we apply the two functions one by one:\n$9x+10=91 \\Rightarrow f(9x+10) = f(91) \\Rightarrow 9x+10-10=91-10 \\Rightarrow 9x = 81$.\nRepeating the same method:\n$9x=81 \\Rightarrow g(9x)=g(81) \\Rightarrow \\frac {9x} {9} = \\frac {81} {9} \\Rightarrow x = \\frac {81}{9}$\nInverse of a function In mathematics the inverse of a function $f_1$ is a function $f_2 \\equiv f_1^{-1}$ so that $f_1(f_2(x)) = x$. For instance the inverse of $f_1(x) = x/2$ is $f_2(x)=2x$ since $f_1(f_2(x)) = f_1(2x) = \\frac {2x}{2} = x$.\nInverse functions \u0026ldquo;cancel\u0026rdquo; the effect of the original function.\nEquation in terms of Inverse functions. In the equation $9x+10=91$, if we define $f(x)=9x+10$, then we essentially have to solve the equation $f(x)=91$, or to simply find the inverse of $f,\\ f^{-1}$ and apply it to both sides:\n$$f(x)=91 \\Rightarrow f^{-1}(f(x))=f^{-1}(91) \\Rightarrow x = f^{-1}(91)$$ Composability The fact that we can solve the equation the way we do (through a number of transformations) means that the function is decomposable into a few non-trivial functions.\nIndeed, in the case of $f(x)=9x+10$, we can decompose the function in two functions: $f_1(x)=9x$, $f_2(x)=x+10$: $f(x)=f_2(f_1(x))$\nThus we can simply find the inverse function of $f_2$ and then the inverse of $f_1$.\nThis process is like unwrapping a gift. First your friend wraps it into multiple layers, and then you will have to unwrap it, one layer at a time, in reverse order to recover it.\nNot every function has an inverse $f(x)=x^2$ doesn\u0026rsquo;t have a regular inverse. But we can partition the set of $x$ in which we are interested so that the individual sets give us invertible functions. For example if we are interested for solutions in $\\mathbb R$, partition that space to $(-\\infty,0], (0,\\infty)$. In these intervals the function $x^2$ has inverses.\nNot every function takes every value if you have the equation $f(x)=35$, $f$ doesn\u0026rsquo;t always take the value $35$. That means that the equation doesn\u0026rsquo;t have a solution; there is no $x$ that leads to that value.\nNot every function can be decomposed nicely If our function is $f(x)=e^x + lnx$, and we need to solve the equation $f(x)=e$, Can you find an obvious decomposition? There is no one. That means that we have to perform the task of inversion in one step instead of decomposing. Turns out the inverse of this function is not even expressed in terms of common functions.\nNot every decomposition is obvious If the equation in question is: $x^2+2x+3=0$\n$f(x)=x^2+2x+3 = x^2 + 2x +1 + 2 = (x+1)^2+2 =f_3(f_2(f_1(x)))$\nWhere\n$f_1(x)=x+1$,$f_2(x)=x^2$, $f_3(x)=x+2$.\nExtension to Inequalities This process extends naturally to inequalities, and we might explore this issue in the future.\n","date":"5 December 2017","externalUrl":null,"permalink":"/posts/functional-approach-for-solving-equations/","section":"Posts","summary":"","title":"Functional approach for solving equations","type":"posts"},{"content":"","date":"5 December 2017","externalUrl":null,"permalink":"/tags/mathematical-insights/","section":"Tags","summary":"","title":"Mathematical Insights","type":"tags"},{"content":"Counting elements in a sequence is a common problem in mathematics, computer science, and programming. Although this often appears tricky, there\u0026rsquo;s a simple method to make the task straightforward, requiring only basic math skills.\nExamples Before Theory We illustrate the method through examples.\nExample 1: {5, 6, 7, \u0026hellip;, 100} First, find a function that maps integers (ideally starting from 0) to the elements above. In this case, it\u0026rsquo;s easy to see that $f(n) = 5 + n$. Now, we look for the value of $k$ that maps to 100. Using an equation, we find:\n$$ f(k) = 100 \\Rightarrow 5 + k = 100 \\Rightarrow k = 95. $$Thus, the sequence {5, 6, 7, \u0026hellip;, 100} has 96 elements.\nExample 2: {36, 39, 42, \u0026hellip;, 141} This example is trickier than before, but the same technique applies. The function for this sequence is $f(n) = 36 + 3n$. We want to find the $k$ that maps to 141:\n$$ f(k) = 141 \\Rightarrow 36 + 3k = 141 \\Rightarrow k = 35 $$The sequence {36, 39, 42, \u0026hellip;, 141} has 36 elements.\nExample 3: {87.3, 86.2, 85.1, \u0026hellip;, -7.3} This example demonstrates that the method works for any set of objects or numbers, as long as there\u0026rsquo;s a function to track the sequence elements and solvable equations for the function:\n$$ f(n) = 87.3 - 1.1n $$Find the edge case:\n$$ f(k) = -7.3 \\Rightarrow 87.3 - 1.1k = -7.3 \\Rightarrow k = 86 $$The sequence {87.3, 86.2, 85.1, \u0026hellip;, -7.3} has 87 elements.\nThe Method Explained Here\u0026rsquo;s a summary of the method:\nIdentify the sequence $x_0, x_1, \\cdots, x_k$. Find a function $f$ that describes the sequence. This function should be relatively easy to find based on the sequence behavior. Find the independent variables for which your function produces the two edge values. Calculate the result: $\\text{final} - \\text{start} + 1$ In step 4, finding an integer solution is required; otherwise, the function won\u0026rsquo;t reach the final number, and your function won\u0026rsquo;t truly track the sequence.\nAlthough the examples above are linear, this method works for any bijection in the required range. Be cautious with more involved cases, as a non-bijective function can lead to double counting or missing numbers.\nIn essence, this approach condenses the sequence of interest into just two parameters: the function and the ending independent variable. The starting independent variable is also a parameter but can be inferred from the function.\nFor example, in the third case we have:\n$$\\\\{87.3, 86.2, 85.1, ..., -7.3\\\\} \\equiv (f(n) = 87.3 - 1.1n, 86)$$You can view this as a way of compressing the sequence.\n","date":"13 August 2017","externalUrl":null,"permalink":"/posts/counting-insight/","section":"Posts","summary":"","title":"Counting sequences through compression","type":"posts"},{"content":"","date":"13 August 2017","externalUrl":null,"permalink":"/tags/equations/","section":"Tags","summary":"","title":"Equations","type":"tags"},{"content":"","date":"13 August 2017","externalUrl":null,"permalink":"/tags/mathematics/","section":"Tags","summary":"","title":"Mathematics","type":"tags"},{"content":"","date":"13 August 2017","externalUrl":null,"permalink":"/tags/sets/","section":"Tags","summary":"","title":"Sets","type":"tags"},{"content":"","date":"13 August 2017","externalUrl":null,"permalink":"/tags/street-math/","section":"Tags","summary":"","title":"Street-Math","type":"tags"},{"content":"The process followed was the following:\nDownload data containing the addresses of 1404 mini markets in athens.\nUse google API to query the latitude and longitude of the addresses, given the information of the location (area and address).\nConvert latitude and longitude to cartesian coordinates, assuming linearity with small error due to the restricted range.\nUse google maps api to keep a white simplified map of Athens.\nCreate the voronoi diagram using the coordinates of the points.\nSuperimpose the results of 4,5 on a single image.\nResult ","date":"19 June 2017","externalUrl":null,"permalink":"/project/greek-mini-markets/","section":"Projects","summary":"","title":"Athens mini-markets Voronoi","type":"project"},{"content":"","date":"19 June 2017","externalUrl":null,"permalink":"/tags/data-gathering/","section":"Tags","summary":"","title":"Data Gathering","type":"tags"},{"content":"","date":"19 June 2017","externalUrl":null,"permalink":"/categories/data-visualization/","section":"Categories","summary":"","title":"Data Visualization","type":"categories"},{"content":"","date":"19 June 2017","externalUrl":null,"permalink":"/project/","section":"Projects","summary":"","title":"Projects","type":"project"},{"content":"","date":"19 June 2017","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":"","date":"19 June 2017","externalUrl":null,"permalink":"/tags/voronoi/","section":"Tags","summary":"","title":"Voronoi","type":"tags"},{"content":"","date":"27 May 2017","externalUrl":null,"permalink":"/tags/turkey/","section":"Tags","summary":"","title":"Turkey","type":"tags"},{"content":"It was announced in Greek media that Turkey achieved a new maximum range with modern missiles in its disposal. I was instantly curious: what targets in Greece can be hit by Turkey now?\nThis experiment is created for fun. The author is optimistic about the relations of the two countries.\nscroll down for the results to see the resulting images\nProblem Setting Hit Area Let $\\mathcal{T}$ be the set of points that are in Turkey. \\(\\mathcal{G}\\) the set of points in Greece. The range of the missile \\(R\\), then we are looking for:\n$$\\mathcal {Hit} = \\\\{ x \\in \\mathcal G\\ |\\ y \\in \\mathcal{T}: ||x-y|| \\leq R \\\\}$$ Accessibility of Targets It might be of interest to measure how easily a target can be hit, that is, how many points in Turkey\u0026rsquo;s territory have access to the target.\nThis can be computed by the area of the points that can reach the target:\n$$\\mathcal{Acc}(x) =area\\ \\\\{ y\\ |\\ y \\in \\mathcal{T}, ||x-y|| \\leq R \\\\} $$ Implementation There are many ways to implement this. Sophisticated solutions would yield a precise image of the targets that can be hit (computational geometry might be of use here).\nIn this project we are looking for simple Monte Carlo solutions. Consider this very direct approach: take random points in Turkey\u0026rsquo;s territory using rejection. For a random point in Turkey \\(p_t\\in \\mathcal T\\), take random points \\( \\{p_i\\} \\) within the range of the missile: \\( p_i \\in \\{ p\\ |\\ ||p-p_t|| \\leq R\\}\\). Keep the points that fall in Greek land \\( \\{p_i\\} \\cap \\mathcal G \\).\nLimitations of approach. This approach would not be as efficient for extremely small areas.\nOther Monte Carlo Methods. We don\u0026rsquo;t use domain knowledge in this approach. Countries tend to be concentrated in certain areas as opposed to be sets of arbitrary points. Smarter sampling would take advantage of structure like this to uncover better sample efficiency. The interested reader is referred to MCMC methods.\nFinal Image Two different pictures of two different ranges are shown. The second image depicts the random points from which we started in Turkey.\nThe side effect of this implementation is that density also illustrates the accessibility of an area.\n","date":"27 May 2017","externalUrl":null,"permalink":"/project/turkey-greece-range/","section":"Projects","summary":"","title":"Turkey to Greece missile range","type":"project"},{"content":"","date":"10 February 2017","externalUrl":null,"permalink":"/tags/hci/","section":"Tags","summary":"","title":"Hci","type":"tags"},{"content":"","date":"10 February 2017","externalUrl":null,"permalink":"/tags/library/","section":"Tags","summary":"","title":"Library","type":"tags"},{"content":"","date":"10 February 2017","externalUrl":null,"permalink":"/categories/proof-of-concept/","section":"Categories","summary":"","title":"Proof-of-Concept","type":"categories"},{"content":"","date":"10 February 2017","externalUrl":null,"permalink":"/tags/terminal/","section":"Tags","summary":"","title":"Terminal","type":"tags"},{"content":" Motivation In this page I am going to demonstrate an idea of a unified terminal experience. To substantiate it, I created an application for SQL, using ncurses and python, but the concept is to apply the same principle in any hierarchical tree structure, aiding the development by an underlying library.\nThe interaction we have each day with computers varies from application to application. This is also the case for terminal experience. The problem that obviously arises is, each time, the user has to learn again the UI and its shortcuts, making the learning curve steeper. Although for most non-terminal applications the learning curve is approachable, we frequently settle for suboptimal use, since it\u0026rsquo;s not worth it to spend much time in learning the various shortcuts available. The situation is exacerbated for the more obscure but frequently very uesful terminal apps.\nThe ideal experience of course, would have been, to make the learning the UI/shortcuts effort barely noticeable.\nWith that goal in mind, here\u0026rsquo;s bacu, an early incarnation of a unified experience.\nStructure The idea is to decouple KEY BINDINGS (or shortcuts) from ACTIONS.\nThe user will initially select a preferred KEY BINDING set that maps KEY BINDGINGS to generic actions.\nAs an example, In vim key bindings, \u0026lsquo;dd\u0026rsquo; would denote a generic call of a deletion of a line. Afterwards, depending on the context (in this case, if we act on tables or databases), a different delete function will be called (deleteTable, deleteDatabase etc.).\nDemonstration A demonstration of the idea follows. This is an incomplete application. The source code will be released in github.\n","date":"10 February 2017","externalUrl":null,"permalink":"/project/bacu/","section":"Projects","summary":"","title":"Unified Terminal Experience, BACU","type":"project"},{"content":"Suppose you are a hunter that doesn\u0026rsquo;t have information about the distance from the prey. For instance a blind dog with very precise smelling which can be mapped to a distance from the potential prey. How can this dog locate and eventually reach its prey?\nThe algorithms are not documented yet, but a simulation is provided. If you are interested contact me for more information.\nDemo simulation parameters:\n\\( V_{prey} \\approx V_{predator} \\) Prey changes direction with small probability Predator adopts the strategy we have assigned it (not explained here). Web simulation found online\nPrevious attempts A less sophisticated approach and its results web simulation\nResults for multiple predators starting from the same location, with varying initial velocity angles:\nFor varying distances and varying angles:\nRandom shifts web simulation\n","date":"6 November 2016","externalUrl":null,"permalink":"/project/blind-hunter/","section":"Projects","summary":"","title":"Blind Hunter","type":"project"},{"content":"","date":"6 November 2016","externalUrl":null,"permalink":"/categories/differential-game-theory/","section":"Categories","summary":"","title":"Differential Game Theory","type":"categories"},{"content":"","date":"6 November 2016","externalUrl":null,"permalink":"/tags/game-theory/","section":"Tags","summary":"","title":"Game Theory","type":"tags"},{"content":"","date":"6 November 2016","externalUrl":null,"permalink":"/tags/pursuit-evasion/","section":"Tags","summary":"","title":"Pursuit-Evasion","type":"tags"},{"content":"","date":"6 November 2016","externalUrl":null,"permalink":"/tags/zero-sum-game/","section":"Tags","summary":"","title":"Zero-Sum Game","type":"tags"},{"content":" Demonstration ","date":"19 February 2016","externalUrl":null,"permalink":"/project/black-scholes/","section":"Projects","summary":"","title":"Black Scholes","type":"project"},{"content":"","date":"19 February 2016","externalUrl":null,"permalink":"/tags/heat-equation/","section":"Tags","summary":"","title":"Heat Equation","type":"tags"},{"content":" Heat equation The heat equation is a partial differential equation, that is, it involves both derivatives of the time and of spatial variables.\n$$\\frac {\\partial u} {\\partial t} - \\alpha \\frac {\\partial^2 u}{\\partial x^2} = 0 $$Where the parameter \\(\\alpha\\) determines how much conductive the material is.\nThis is the case for one variable, and thus one dimension. You can imagine that as a long but very thin wire. Of course in reality there is no such thing as 1 Dimension material, but from physicists and mostly engineers we know that this can be approximated when the long side is much bigger than the radius of the wire.\nIn our simulation we set the right boundary\u0026rsquo;s temperature to be changing sinusoidally its temperature, while the left boundary\u0026rsquo;s temperature is defined by the user.\nNumerical Method The typical finite difference method was used in order to perform the simulation. The parameter \\(\\alpha\\) was selected appropriately for the illustration purposes.\nSimulation Click here to experiment yourself\nDemonstration ","date":"19 February 2016","externalUrl":null,"permalink":"/project/heat-equation/","section":"Projects","summary":"","title":"Heat Equation PDE Simulation","type":"project"},{"content":"","date":"19 February 2016","externalUrl":null,"permalink":"/tags/interactive-app/","section":"Tags","summary":"","title":"Interactive App","type":"tags"},{"content":"","date":"19 February 2016","externalUrl":null,"permalink":"/categories/numerical-methods/","section":"Categories","summary":"","title":"Numerical Methods","type":"categories"},{"content":"","date":"19 February 2016","externalUrl":null,"permalink":"/tags/visualization/","section":"Tags","summary":"","title":"Visualization","type":"tags"},{"content":"","date":"2 January 2016","externalUrl":null,"permalink":"/tags/human-limits/","section":"Tags","summary":"","title":"Human-Limits","type":"tags"},{"content":"Consider the problem of counting a large number of objects by a human.\nHumans excel in recognizing specific patterns, those connected to our evolutionary past. For example, in the past we didn\u0026rsquo;t quite need to know precise counts of objects. It makes a difference if we have one or three predators chasing us, but the difference between ten and fifteen is clearly not as significant (the impact of different counts, in some sense, has a logarithmic shape). Our ability to quickly enumerate even small sets of objects is therefore quite limited.\nAs numbers grow, enumeration becomes increasingly error-prone and tedious. We can fix this by dividing objects into groups, creating a one-level hierarchy.\nThis is helpful but clearly starts suffering from the same issue. Recursion becomes necessary. Within the constraints of practical two-dimensional media, we can design multi-layered hierarchies.\nIn the example above, a 5-5-4-5 hierarchy is depicted. Each row (level 2) contains 25 objects, each block (level-2) has 100 objects, and each row of blocks holds 500 objects (level-3). This spatial arrangement leads to recursion, with level-4 forming a block of blocks.\nHowever, hierarchies come with trade-offs. Spatial efficiency is sacrificed compared to a dense packed arrangement.\nOur choice of 4 or 5 objects per level is intentional. Humans can count 1-5 objects almost instantaneously, an $\\mathcal O(1)$ operation. Beyond that, we resort to linear counting, an $\\mathcal O(n)$ process. By implementing a logarithmic hierarchy, we create a counting system better suited to our cognitive strengths.\nBy utilizing 5 meta-items per level, a capacity of $5^n$ items can be achieved with $n$ levels, requiring roughly $n$ operations. This is the essence of logarithmic counting.\nConclusion This thought experiment on logarithmic hierarchies provides an opportunity to reflect on human cognition and consider how we can adapt methods to accommodate our limitations. While not directly applicable to everyday life, it offers insights into potential ways of handling complex tasks. The exploration of human capabilities through such thought experiments can pave the way for innovative solutions and inspire new approaches to task execution.\n","date":"2 January 2016","externalUrl":null,"permalink":"/posts/hierarchies/","section":"Posts","summary":"","title":"Logarithmic counting","type":"posts"},{"content":"","date":"2 January 2016","externalUrl":null,"permalink":"/tags/logarithms/","section":"Tags","summary":"","title":"Logarithms","type":"tags"},{"content":"","date":"2 January 2016","externalUrl":null,"permalink":"/tags/scalability/","section":"Tags","summary":"","title":"Scalability","type":"tags"},{"content":"","date":"2 January 2016","externalUrl":null,"permalink":"/tags/thought-experiment/","section":"Tags","summary":"","title":"Thought-Experiment","type":"tags"},{"content":"","date":"23 November 2015","externalUrl":null,"permalink":"/categories/art/","section":"Categories","summary":"","title":"Art","type":"categories"},{"content":" Concept The concept is the following: Drop $N$ mice randomly in a rectangular area. Each mouse targets exactly one other mouse forming a circle of targets.\n$$M_1 \\rightarrow M_2 \\rightarrow ... \\rightarrow M_N \\rightarrow M_1$$All mice have equal velocity. The simulation follows. After clicking on the simulation, press (i) to increase the number of mice, and press (d) to decrease it.\nSimulation Emerging Behaviors Each mouse \\(M_i\\) is confined in the rectangular area. This is due to the fact that every mouse targets a point within the rectangular area at any point.\nEach mouse gets very close to its target mouse. Since the rectangular area is limited, a mouse has to change direction at some point. During this change, the pursuing mouse reduces the distance from its target (since they have equal magnitude of velocity). This is true until a lower-bound distance is reached, after which \u0026ldquo;the reaction time\u0026rdquo; (alternatively, due to the discreteness of the simulation) of the mouse is slow and the distance can not be further reduced.\nThe mice reach a steady state behavior, circulating on a path.\nUsually a loop of mice emerges. The more the mice deployed, the bigger the length of the curve.\nExample Instances The results below depict various realizations for different number of mice. Use the simulation above to get your own art!\n","date":"23 November 2015","externalUrl":null,"permalink":"/project/mice-make-art/","section":"Projects","summary":"","title":"Mice Make Art!","type":"project"},{"content":"","date":"23 November 2015","externalUrl":null,"permalink":"/tags/pursuit/","section":"Tags","summary":"","title":"Pursuit","type":"tags"},{"content":"","date":"9 March 2014","externalUrl":null,"permalink":"/categories/educational-platform/","section":"Categories","summary":"","title":"Educational Platform","type":"categories"},{"content":"This is an experimenting platform I\u0026rsquo;ve created for people who are learning regular expressions. Javascript Regular Expressions are used.\nThe platform allows you to experiment by entering a regular expression, and then highlighting the matching parts. Match and replace is also available, with special regex replacing syntax available. You can either use the reload button or edit the text yourself in the platform.\nExperiment with the platform yourself\nDemonstration ","date":"9 March 2014","externalUrl":null,"permalink":"/project/regex-experimenter/","section":"Projects","summary":"","title":"Regex Experimenting Platform","type":"project"},{"content":"","date":"9 March 2014","externalUrl":null,"permalink":"/tags/regular-expressions/","section":"Tags","summary":"","title":"Regular Expressions","type":"tags"},{"content":"","date":"10 June 2009","externalUrl":null,"permalink":"/categories/game/","section":"Categories","summary":"","title":"Game","type":"categories"},{"content":"","date":"10 June 2009","externalUrl":null,"permalink":"/tags/games/","section":"Tags","summary":"","title":"Games","type":"tags"},{"content":"","date":"10 June 2009","externalUrl":null,"permalink":"/tags/pimp-my-peon/","section":"Tags","summary":"","title":"Pimp My Peon","type":"tags"},{"content":"","date":"10 June 2009","externalUrl":null,"permalink":"/tags/warcraft-3/","section":"Tags","summary":"","title":"Warcraft 3","type":"tags"},{"content":"Pimp my Peon was the first contact I had with programming at the age of 15-16 and very influential to the later developed interests. Alternatively you might consider it as an early indication of an innate fascination for the art of \u0026ldquo;creation\u0026rdquo; using technology.\nIt is documented here for historical reasons.\nIt was a mod for Warcraft 3, like the famous Dota 1, which had begun as an open source project and was then \u0026ldquo;forked\u0026rdquo; by young me. The programming involved was through \u0026ldquo;Warcraft 3 World Editor\u0026rdquo;, an editor for creating custom warcraft maps.\nThe game had impressive influence on the genre witnessed in games by other developers.\nInitial Version The initial fork end up being very popular with more than 100,000 downloads despite having several flaws that can be seen in the enjoyable video below by youtuber \u0026ldquo;wtiiwarcraft\u0026rdquo;.\nTo this day this map is in top warcraft 3 maps in EpicWar database.\nSecond Version The subsequent version was much more mature (but still imperfect) than the first one.\n","date":"10 June 2009","externalUrl":null,"permalink":"/project/warcraft-game/","section":"Projects","summary":"","title":"Warcraft 3 Mod - Pimp my Peon","type":"project"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]